{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2627,
     "status": "ok",
     "timestamp": 1627961145914,
     "user": {
      "displayName": "이훈민",
      "photoUrl": "",
      "userId": "00157268181097362793"
     },
     "user_tz": 240
    },
    "id": "cg7gm5FVyA3r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "#from tensorflow.keras.datasets import cifar10 \n",
    "from keras.datasets import fashion_mnist \n",
    "#from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "mod = sys.modules[__name__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1627961145917,
     "user": {
      "displayName": "이훈민",
      "photoUrl": "",
      "userId": "00157268181097362793"
     },
     "user_tz": 240
    },
    "id": "-gn3HoNnyGdo"
   },
   "outputs": [],
   "source": [
    "def distribution_check(dataset):\n",
    "        #분포가 다름;\n",
    "    one,two,three,four,five,six,seven,eight,nine,ten=0,0,0,0,0,0,0,0,0,0\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        if(dataset[i]==1):    one+=1\n",
    "        elif(dataset[i]==2):  two+=1\n",
    "        elif(dataset[i]==3):  three+=1\n",
    "        elif(dataset[i]==4):  four+=1\n",
    "        elif(dataset[i]==5):  five+=1\n",
    "        elif(dataset[i]==6):  six+=1\n",
    "        elif(dataset[i]==7):  seven+=1\n",
    "        elif(dataset[i]==8):  eight+=1\n",
    "        elif(dataset[i]==9):  nine+=1\n",
    "        elif(dataset[i]==0):  ten+=1\n",
    "\n",
    "    #print(one,two,three,four,five,six,seven,eight,nine,ten)\n",
    "    #print(\"Sum : \", one+two+three+four+five+six+seven+eight+nine+ten)\n",
    "    sums = one+two+three+four+five+six+seven+eight+nine+ten\n",
    "    for_graph=[one,two,three,four,five,six,seven,eight,nine,ten]\n",
    "    \n",
    "    return for_graph, sums\n",
    "\n",
    "def local_model_generate(model): #초기 모델 생성\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def step_function(data):\n",
    "    if data > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def sigmoid(data):\n",
    "    return 1/(1+np.exp(-data))\n",
    "\n",
    "def relu(data):\n",
    "    return np.maximum(0,data)\n",
    "\n",
    "def random_check(local, train_data, test_data):\n",
    "    check_distribution_train_data, check_distribution_test_data, y_train_tmp, y_test_tmp = [], [], [], []\n",
    "    sum1, sum2, data_index = 0,0, np.arange(0,10)\n",
    "\n",
    "    for j in range(len(train_data)):\n",
    "        y_train_tmp.append(np.argmax(train_data[j])) #원핫인코딩에서 다시 0~9 레이블로 변환\n",
    "\n",
    "    for j in range(len(test_data)):\n",
    "        y_test_tmp.append(np.argmax(test_data[j]))\n",
    "\n",
    "    check_distribution_train_data, sum_train = distribution_check(y_train_tmp) #한번 밖에 실행 못함\n",
    "    check_distribution_test_data, sum_test = distribution_check(y_test_tmp)\n",
    "    sum1, sum2 = (sum1 + sum_train), (sum2 + sum_test)\n",
    "    \n",
    "    return check_distribution_train_data, check_distribution_test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1027,
     "status": "ok",
     "timestamp": 1627961146931,
     "user": {
      "displayName": "이훈민",
      "photoUrl": "",
      "userId": "00157268181097362793"
     },
     "user_tz": 240
    },
    "id": "i7g0ECm9tiiT",
    "outputId": "02794b3b-bd62-4fcd-bf51-7ea7f2176df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "print(x_train.shape, x_test.shape)\n",
    "num_train, num_test = len(x_train),  len(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1627961146932,
     "user": {
      "displayName": "이훈민",
      "photoUrl": "",
      "userId": "00157268181097362793"
     },
     "user_tz": 240
    },
    "id": "XkIYZrvplXU0"
   },
   "outputs": [],
   "source": [
    "local = 21 # 10개 : 1~10 => 11은 포함 안됨\n",
    "batch_size, epochs = 32, 5\n",
    "global_epoch = 0\n",
    "num_layers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1627961147087,
     "user": {
      "displayName": "이훈민",
      "photoUrl": "",
      "userId": "00157268181097362793"
     },
     "user_tz": 240
    },
    "id": "h3lM8ImZlYqW",
    "outputId": "6084b4fd-5e9c-4c13-97b6-cb990c9c4fbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 x_train shape: (60000, 28, 28)\n",
      "Step 2 x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "print(\"Step 1 x_train shape:\", x_train.shape)\n",
    "\n",
    "x_train = x_train.reshape((num_train, 28, 28, 1))\n",
    "x_test = x_test.reshape((num_test, 28, 28, 1))\n",
    "\n",
    "print(\"Step 2 x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "# convert class vectors to binary class matrices => one hot encoding 지금은 [3,6,2,5,4,8..] 섞여있음 \n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1627961148196,
     "user": {
      "displayName": "이훈민",
      "photoUrl": "",
      "userId": "00157268181097362793"
     },
     "user_tz": 240
    },
    "id": "xiMagvhYlZ_B",
    "outputId": "81821dd3-5c4e-465e-a050-de9a177c60f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3515    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2783    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1131    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  1646    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1764    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4534    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1045    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1886    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3820    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2127    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  4802    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2348    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  2782    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2099    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4479    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3214    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1766    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2960    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2538    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1944    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "0  번째 global_epoch 데이터 랜덤 준비완료!!\n"
     ]
    }
   ],
   "source": [
    "global_epoch = 0\n",
    "\n",
    "print(global_epoch, \" 번째 global_epoch 데이터 랜덤하게 준비!!\")\n",
    "\n",
    "for i in range(1,local): #데이터 변수 선언, 빈 리스트로 초기화\n",
    "    globals()['L{}_x_train'.format(i)], globals()['L{}_x_test'.format(i)] = [],[]  \n",
    "    globals()['L{}_y_train'.format(i)], globals()['L{}_y_test'.format(i)] = [],[]  \n",
    "\n",
    "\n",
    "for n in range(1,local): #x_train_range, 잘 작동함 => 확인 완료\n",
    "\n",
    "    x_train_range = list(np.arange(0,len(x_train)))  #0~59,999\n",
    "    x_test_range = list(np.arange(0,len(x_test)))  #0~9,999\n",
    "\n",
    "    tmp, tmp2 = [], []\n",
    "\n",
    "    num_pick = random.randint(1000, 5000) #변동 사항 #int(len(list(x_train_range))/local)\n",
    "    num_pick2 = int(len(x_test_range)/local) #test 데이터는 원래대로 항상 일정한 비율로 주면 될듯 => 어느정도 분량 이상 있어야 함\n",
    "    \n",
    "    tmp = random.sample(list(x_train_range), num_pick)  #1/10개 만큼 인덱스 랜덤 비복원 추출 => 랜덤으로 해야함\n",
    "    tmp2 = random.sample(list(x_test_range), num_pick2)\n",
    "\n",
    "    for i in range(len(tmp)):\n",
    "        globals()['L{}_x_train'.format(n)].append(x_train[tmp[i]])  #n번째 Cluster에 분할한 실제 x_train 데이터 저장\n",
    "        globals()['L{}_y_train'.format(n)].append(y_train[tmp[i]]) \n",
    "        #x_train_range.remove(tmp[i])  #랜덤 하게 뽑힌 원소갯수들 추출했으니 안에서 삭제  => 오래걸림\n",
    "\n",
    "    for j in range(len(tmp2)):\n",
    "        globals()['L{}_x_test'.format(n)].append(x_test[tmp2[j]])\n",
    "        globals()['L{}_y_test'.format(n)].append(y_test[tmp2[j]])\n",
    "        #x_test_range.remove(tmp2[j])  #랜덤 하게 뽑힌 원소 1000개 추출했으니 안에서 삭제  => 오래걸림\n",
    "    \n",
    "    print(\"CHECK :\", n,\" 번째 로컬 클라이언트 Number of Training sets : \", len(globals()['L{}_x_train'.format(n)]), \"   Number of Training sets : \", len(globals()['L{}_x_test'.format(n)]))\n",
    "\n",
    "print(\"check=>: should be 0 == \", len(x_train_range))  #원소 하나도 없어야 함. 확인.\n",
    "print(global_epoch, \" 번째 global_epoch 데이터 랜덤 준비완료!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67644,
     "status": "ok",
     "timestamp": 1627961238422,
     "user": {
      "displayName": "이훈민",
      "photoUrl": "",
      "userId": "00157268181097362793"
     },
     "user_tz": 240
    },
    "id": "gmU6gEQ3lbpD",
    "outputId": "e26b51c2-494f-4adb-a1e4-752768d7e81c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 0 번째 global epoch에서 로컬 클라이언트 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4909 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.5019 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.6966 - accuracy: 0.7437\n",
      "15/15 - 0s - loss: 0.6632 - accuracy: 0.7500\n",
      "15/15 - 0s - loss: 0.5980 - accuracy: 0.7836\n",
      "15/15 - 0s - loss: 0.4776 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.7936 - accuracy: 0.6828\n",
      "15/15 - 0s - loss: 0.7310 - accuracy: 0.7458\n",
      "15/15 - 0s - loss: 0.6247 - accuracy: 0.7668\n",
      "15/15 - 0s - loss: 0.6341 - accuracy: 0.7542\n",
      "15/15 - 0s - loss: 0.5184 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 0.5756 - accuracy: 0.7752\n",
      "15/15 - 0s - loss: 0.5529 - accuracy: 0.7983\n",
      "15/15 - 0s - loss: 0.5987 - accuracy: 0.7878\n",
      "15/15 - 0s - loss: 0.5794 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.6173 - accuracy: 0.7815\n",
      "15/15 - 0s - loss: 0.7882 - accuracy: 0.6954\n",
      "15/15 - 0s - loss: 0.5515 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.5407 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.5522 - accuracy: 0.7815\n",
      "0 번째 global epoch 로컬 클라이언트 학습완료!,  Total Training time :  104.4558334350586 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-9423f5a6d053>:64: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  globals()['G{}_w_layer{}'.format(global_epoch, layer_index)] = globals()['G{}_w_layer{}'.format(global_epoch, layer_index)] + (np.array(globals()['L{}_layer{}_w'.format(i,layer_index)]) * w_scaler)\n"
     ]
    }
   ],
   "source": [
    "#준비된 데이터 (IID / NON-IID) np.array로\n",
    "\n",
    "local = 21\n",
    "\n",
    "global_epoch = 0\n",
    "FedAvg_ACC, FedAvg_LOSS, fedavg_acc, fedavg_loss, acc, loss = [], [], [], [], 0, 0\n",
    "num_layers_list = [0,2,4,6,7]\n",
    "label_list = []\n",
    "\n",
    "VAR_final_list_w, VAR_final_list_b = [], []\n",
    "\n",
    "\n",
    "for i in range(1,local):\n",
    "    globals()['L{}_x_train'.format(i)] = np.array(globals()['L{}_x_train'.format(i)])\n",
    "    globals()['L{}_x_test'.format(i)] = np.array(globals()['L{}_x_test'.format(i)])\n",
    "    globals()['L{}_y_train'.format(i)] = np.array(globals()['L{}_y_train'.format(i)])\n",
    "    globals()['L{}_y_test'.format(i)] = np.array(globals()['L{}_y_test'.format(i)])\n",
    "\n",
    "\n",
    "print(\"\\n\\n\",global_epoch, \"번째 global epoch에서 로컬 클라이언트 학습시작!\\n\\n학습 중 ...\\n\")\n",
    "now = time.time()\n",
    "\n",
    "for i in range(1,local):\n",
    "    globals()['FedAvg_L{}_iter{}_model'.format(i, global_epoch)] = models.Sequential()  ##!!!!!!! 이게 글로벌 epoch에서는 2번째 부터 들어가면 안됨\n",
    "    globals()['FedAvg_L{}_iter{}_model'.format(i, global_epoch)] = local_model_generate(globals()['FedAvg_L{}_iter{}_model'.format(i, global_epoch)])      # initialize 필요 => 모델 프레임 구축\n",
    "\n",
    "    globals()['FedAvg_L{}_iter{}_model'.format(i, global_epoch)].compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    globals()['FedAvg_L{}_iter{}_model'.format(i, global_epoch)].fit(globals()['L{}_x_train'.format(i)], globals()['L{}_y_train'.format(i)], batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=0)\n",
    "\n",
    "    loss, acc = globals()['FedAvg_L{}_iter{}_model'.format(i, global_epoch)].evaluate(globals()['L{}_x_test'.format(i,global_epoch)], globals()['L{}_y_test'.format(i)], verbose=2)\n",
    "    \n",
    "    fedavg_acc.append(acc)  #acc 넣기\n",
    "    fedavg_loss.append(loss)  #loss 넣기\n",
    "\n",
    "\n",
    "print(global_epoch, \"번째 global epoch 로컬 클라이언트 학습완료!,  Total Training time : \", time.time()-now,\"\\n\\n\")\n",
    "\n",
    "# 로컬 모델들 학습 완료하였고 로컬모델에서 weight, bias 추출 -------------------------------------------------------------------------------------\n",
    "\n",
    "for i in range(1, local):\n",
    "    for layer_index in num_layers_list:\n",
    "        w = globals()['FedAvg_L{}_iter{}_model'.format(i, global_epoch)].layers[layer_index].get_weights() #get_weights = w[0],b[1]로 구성\n",
    "\n",
    "        globals()['L{}_layer{}_w_tmp'.format(i,layer_index)] = w      # 클러스터링 용도\n",
    "        globals()['L{}_layer{}_w'.format(i,layer_index)] = w          # weight aggregation 용도\n",
    "            \n",
    "\n",
    "for layer_index in num_layers_list:\n",
    "\n",
    "    globals()['layer{}_W_tmp'.format(layer_index)] = []\n",
    "    globals()['G{}_w_layer{}'.format(global_epoch, layer_index)] = 0  #FedAvg 용도\n",
    "    \n",
    "    globals()['var_list_layer{}_w'.format(layer_index)] = []\n",
    "    globals()['var_list_layer{}_b'.format(layer_index)] = []\n",
    "  \n",
    "    w_scaler = 0\n",
    "    #------------------------------------------------FedAvg--------------------------------------------------------\n",
    "    for i in range(1, local):\n",
    "        globals()['var_list_layer{}_w'.format(layer_index)].append(np.var(globals()['L{}_layer{}_w'.format(i,layer_index)][0]))\n",
    "        globals()['var_list_layer{}_b'.format(layer_index)].append(np.var(globals()['L{}_layer{}_w'.format(i,layer_index)][1]))\n",
    "      \n",
    "        w_scaler = len(globals()['L{}_x_train'.format(i)]) / 60000\n",
    "        globals()['G{}_w_layer{}'.format(global_epoch, layer_index)] = globals()['G{}_w_layer{}'.format(global_epoch, layer_index)] + (np.array(globals()['L{}_layer{}_w'.format(i,layer_index)]) * w_scaler)\n",
    "    \n",
    "    globals()['G{}_w_layer{}'.format(global_epoch, layer_index)] = np.array(globals()['G{}_w_layer{}'.format(global_epoch, layer_index)]) / (local-1)   #np.array로 변함\n",
    "    \n",
    "    VAR_final_list_w.append(globals()['var_list_layer{}_w'.format(layer_index)])\n",
    "    VAR_final_list_b.append(globals()['var_list_layer{}_b'.format(layer_index)])\n",
    "    \n",
    "#---------------------------------------------------------메모리 삭제-------------------------------------------------------------------\n",
    "\n",
    "\n",
    "FedAvg_ACC.append(fedavg_acc)\n",
    "FedAvg_LOSS.append(fedavg_loss)\n",
    "\n",
    "## G{}_num_clusters_in_layer{}_w 에 속하는 거 말고 삭제 = 메모리 낭비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2085753,
     "status": "error",
     "timestamp": 1627963324991,
     "user": {
      "displayName": "이훈민",
      "photoUrl": "",
      "userId": "00157268181097362793"
     },
     "user_tz": 240
    },
    "id": "fGKddODnldWw",
    "outputId": "c00992a4-1c62-4a97-8848-e58f5dc36e8c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2634    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4625    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3068    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  1684    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4072    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  3545    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1843    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4736    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3705    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3671    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  2980    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2452    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  2917    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  1860    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4538    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3273    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4178    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  3201    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1643    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1684    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "1  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "1  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "1  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 2.3026 - accuracy: 0.0966\n",
      "15/15 - 0s - loss: 2.3026 - accuracy: 0.0966\n",
      "15/15 - 0s - loss: 2.3041 - accuracy: 0.0819\n",
      "15/15 - 0s - loss: 2.3025 - accuracy: 0.0966\n",
      "15/15 - 0s - loss: 2.3033 - accuracy: 0.0924\n",
      "15/15 - 0s - loss: 2.3033 - accuracy: 0.0966\n",
      "15/15 - 0s - loss: 2.3051 - accuracy: 0.0924\n",
      "15/15 - 0s - loss: 2.3031 - accuracy: 0.0903\n",
      "15/15 - 0s - loss: 2.3018 - accuracy: 0.1134\n",
      "15/15 - 0s - loss: 2.3033 - accuracy: 0.0945\n",
      "15/15 - 0s - loss: 2.3040 - accuracy: 0.0945\n",
      "15/15 - 0s - loss: 2.3028 - accuracy: 0.0945\n",
      "15/15 - 0s - loss: 2.3021 - accuracy: 0.0966\n",
      "15/15 - 0s - loss: 1.1107 - accuracy: 0.6303\n",
      "15/15 - 0s - loss: 2.3032 - accuracy: 0.1008\n",
      "15/15 - 0s - loss: 2.3021 - accuracy: 0.0966\n",
      "15/15 - 0s - loss: 2.3039 - accuracy: 0.0903\n",
      "15/15 - 0s - loss: 2.3029 - accuracy: 0.1092\n",
      "15/15 - 0s - loss: 2.3042 - accuracy: 0.0819\n",
      "15/15 - 0s - loss: 2.3127 - accuracy: 0.0840\n",
      "------------    1  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  142.96009874343872 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "2  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2651    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2006    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3333    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4504    Number of Training sets :  476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-e58c13c18cea>:98: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  globals()['G{}_w_layer{}'.format(global_epoch, layer_index)] = globals()['G{}_w_layer{}'.format(global_epoch, layer_index)] + (np.array(globals()['L{}_layer{}_w_tmp'.format(i,layer_index)])*w_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  3475    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2001    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1951    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4101    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3246    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3464    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  4849    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2912    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4875    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3145    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4881    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2301    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4714    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4602    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  3568    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1788    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "2  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "2  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "2  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 1.0504 - accuracy: 0.6239\n",
      "15/15 - 0s - loss: 1.0459 - accuracy: 0.6029\n",
      "15/15 - 0s - loss: 0.8581 - accuracy: 0.6786\n",
      "15/15 - 0s - loss: 0.8466 - accuracy: 0.6807\n",
      "15/15 - 0s - loss: 0.8962 - accuracy: 0.6534\n",
      "15/15 - 0s - loss: 0.9973 - accuracy: 0.6429\n",
      "15/15 - 0s - loss: 0.8979 - accuracy: 0.6345\n",
      "15/15 - 0s - loss: 2.2991 - accuracy: 0.1261\n",
      "15/15 - 0s - loss: 0.8813 - accuracy: 0.6492\n",
      "15/15 - 0s - loss: 0.7864 - accuracy: 0.7143\n",
      "15/15 - 0s - loss: 0.7554 - accuracy: 0.6807\n",
      "15/15 - 0s - loss: 0.9106 - accuracy: 0.6408\n",
      "15/15 - 0s - loss: 0.7653 - accuracy: 0.7248\n",
      "15/15 - 0s - loss: 0.9948 - accuracy: 0.6092\n",
      "15/15 - 0s - loss: 0.8796 - accuracy: 0.6261\n",
      "15/15 - 0s - loss: 0.9673 - accuracy: 0.6261\n",
      "15/15 - 0s - loss: 0.8404 - accuracy: 0.6828\n",
      "15/15 - 0s - loss: 0.8182 - accuracy: 0.7059\n",
      "15/15 - 0s - loss: 0.9872 - accuracy: 0.6534\n",
      "15/15 - 0s - loss: 1.0453 - accuracy: 0.5777\n",
      "------------    2  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  190.09693837165833 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "3  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3435    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2435    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1794    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  2172    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1728    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2025    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1011    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3087    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3644    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3363    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  4160    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2579    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4971    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4897    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3865    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2511    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  3565    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  3657    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  3158    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3959    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "3  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "3  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "3  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.8216 - accuracy: 0.6513\n",
      "15/15 - 0s - loss: 0.8083 - accuracy: 0.7017\n",
      "15/15 - 0s - loss: 0.7914 - accuracy: 0.7206\n",
      "15/15 - 0s - loss: 0.9320 - accuracy: 0.6282\n",
      "15/15 - 0s - loss: 0.6937 - accuracy: 0.7395\n",
      "15/15 - 0s - loss: 0.8132 - accuracy: 0.6660\n",
      "15/15 - 0s - loss: 0.8959 - accuracy: 0.6891\n",
      "15/15 - 0s - loss: 0.7484 - accuracy: 0.7143\n",
      "15/15 - 0s - loss: 0.7656 - accuracy: 0.6828\n",
      "15/15 - 0s - loss: 0.7093 - accuracy: 0.7416\n",
      "15/15 - 0s - loss: 0.6497 - accuracy: 0.7479\n",
      "15/15 - 0s - loss: 0.7251 - accuracy: 0.7458\n",
      "15/15 - 0s - loss: 0.6852 - accuracy: 0.7374\n",
      "15/15 - 0s - loss: 0.6425 - accuracy: 0.7899\n",
      "15/15 - 0s - loss: 0.7128 - accuracy: 0.7206\n",
      "15/15 - 0s - loss: 0.7493 - accuracy: 0.7269\n",
      "15/15 - 0s - loss: 0.7139 - accuracy: 0.7059\n",
      "15/15 - 0s - loss: 0.7571 - accuracy: 0.7269\n",
      "15/15 - 0s - loss: 0.7293 - accuracy: 0.7500\n",
      "15/15 - 0s - loss: 0.6401 - accuracy: 0.7458\n",
      "------------    3  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  175.67342567443848 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "4  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4695    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2759    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  4672    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  2971    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4602    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4152    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  4926    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3745    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3026    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2953    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1377    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  4755    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1269    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4383    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3558    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  4340    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1757    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1660    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2328    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2348    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "4  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "4  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "4  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.6533 - accuracy: 0.7500\n",
      "15/15 - 0s - loss: 0.6399 - accuracy: 0.7563\n",
      "15/15 - 0s - loss: 0.6153 - accuracy: 0.7815\n",
      "15/15 - 0s - loss: 0.6532 - accuracy: 0.7311\n",
      "15/15 - 0s - loss: 0.5411 - accuracy: 0.7962\n",
      "15/15 - 1s - loss: 0.6153 - accuracy: 0.7731\n",
      "15/15 - 0s - loss: 0.5864 - accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - loss: 0.6505 - accuracy: 0.7437\n",
      "15/15 - 0s - loss: 0.6509 - accuracy: 0.7731\n",
      "15/15 - 0s - loss: 0.6973 - accuracy: 0.7038\n",
      "15/15 - 0s - loss: 0.6525 - accuracy: 0.7563\n",
      "15/15 - 0s - loss: 0.7114 - accuracy: 0.7374\n",
      "15/15 - 0s - loss: 0.6586 - accuracy: 0.7668\n",
      "15/15 - 0s - loss: 0.5859 - accuracy: 0.7878\n",
      "15/15 - 0s - loss: 0.6180 - accuracy: 0.7689\n",
      "15/15 - 0s - loss: 0.6750 - accuracy: 0.7773\n",
      "15/15 - 0s - loss: 0.6440 - accuracy: 0.7521\n",
      "15/15 - 0s - loss: 0.7074 - accuracy: 0.7248\n",
      "15/15 - 0s - loss: 0.6653 - accuracy: 0.7500\n",
      "15/15 - 0s - loss: 0.8396 - accuracy: 0.7059\n",
      "------------    4  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  196.46766877174377 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "5  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4176    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  1699    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1166    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  1974    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  3187    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  3312    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  4554    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4027    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3275    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  4301    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  2515    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  4405    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4482    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3856    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4772    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3315    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1214    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  3070    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1895    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2284    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "5  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "5  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "5  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.6049 - accuracy: 0.7563\n",
      "15/15 - 0s - loss: 0.6050 - accuracy: 0.7941\n",
      "15/15 - 0s - loss: 0.6778 - accuracy: 0.7479\n",
      "15/15 - 0s - loss: 0.7323 - accuracy: 0.7080\n",
      "15/15 - 0s - loss: 0.5984 - accuracy: 0.7731\n",
      "15/15 - 0s - loss: 0.6655 - accuracy: 0.7374\n",
      "15/15 - 0s - loss: 0.6494 - accuracy: 0.7647\n",
      "15/15 - 0s - loss: 0.6076 - accuracy: 0.7773\n",
      "15/15 - 0s - loss: 0.6299 - accuracy: 0.7584\n",
      "15/15 - 0s - loss: 0.6186 - accuracy: 0.7710\n",
      "15/15 - 0s - loss: 0.6982 - accuracy: 0.7290\n",
      "15/15 - 0s - loss: 0.6205 - accuracy: 0.7857\n",
      "15/15 - 0s - loss: 0.5675 - accuracy: 0.7941\n",
      "15/15 - 0s - loss: 0.5989 - accuracy: 0.7773\n",
      "15/15 - 0s - loss: 0.5303 - accuracy: 0.8130\n",
      "15/15 - 0s - loss: 0.6084 - accuracy: 0.7731\n",
      "15/15 - 0s - loss: 0.6221 - accuracy: 0.7731\n",
      "15/15 - 0s - loss: 0.5971 - accuracy: 0.7878\n",
      "15/15 - 0s - loss: 0.6091 - accuracy: 0.7710\n",
      "15/15 - 0s - loss: 0.6501 - accuracy: 0.7563\n",
      "------------    5  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  194.76434874534607 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "6  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1875    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2599    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3546    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3096    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4042    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  3110    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  2918    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  2254    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  2682    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3252    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1624    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1000    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4806    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4301    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  1695    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2621    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  2697    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2238    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4255    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2717    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "6  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "6  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "6  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.6268 - accuracy: 0.7710\n",
      "15/15 - 0s - loss: 0.6467 - accuracy: 0.7647\n",
      "15/15 - 0s - loss: 0.4681 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.5445 - accuracy: 0.7857\n",
      "15/15 - 0s - loss: 0.5257 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.5993 - accuracy: 0.7836\n",
      "15/15 - 0s - loss: 0.5733 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.5113 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.5786 - accuracy: 0.7794\n",
      "15/15 - 0s - loss: 0.5787 - accuracy: 0.7752\n",
      "15/15 - 0s - loss: 0.5759 - accuracy: 0.7773\n",
      "15/15 - 0s - loss: 0.7075 - accuracy: 0.7521\n",
      "15/15 - 0s - loss: 0.4943 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.5705 - accuracy: 0.7899\n",
      "15/15 - 0s - loss: 0.5850 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.6441 - accuracy: 0.7794\n",
      "15/15 - 0s - loss: 0.5616 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 0.6456 - accuracy: 0.7584\n",
      "15/15 - 0s - loss: 0.5101 - accuracy: 0.7920\n",
      "15/15 - 0s - loss: 0.5579 - accuracy: 0.8025\n",
      "------------    6  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  184.90630841255188 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "7  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2910    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4736    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1516    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4127    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1270    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2272    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3343    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  2972    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3079    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2870    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  2196    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2680    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  2392    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  1628    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2175    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2954    Number of Training sets :  476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1228    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  3973    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1081    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2864    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "7  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "7  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "7  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.5252 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.6454 - accuracy: 0.7542\n",
      "15/15 - 0s - loss: 0.4957 - accuracy: 0.8046\n",
      "15/15 - 0s - loss: 0.5409 - accuracy: 0.7983\n",
      "15/15 - 0s - loss: 0.5647 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.4803 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.4774 - accuracy: 0.8130\n",
      "15/15 - 0s - loss: 0.5326 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.6173 - accuracy: 0.7899\n",
      "15/15 - 0s - loss: 0.5540 - accuracy: 0.7941\n",
      "15/15 - 0s - loss: 0.6168 - accuracy: 0.7647\n",
      "15/15 - 0s - loss: 0.6174 - accuracy: 0.7773\n",
      "15/15 - 0s - loss: 0.5878 - accuracy: 0.7731\n",
      "15/15 - 0s - loss: 0.6654 - accuracy: 0.7773\n",
      "15/15 - 0s - loss: 0.5922 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.5599 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.6025 - accuracy: 0.7773\n",
      "15/15 - 0s - loss: 0.5751 - accuracy: 0.7815\n",
      "15/15 - 0s - loss: 0.6419 - accuracy: 0.7605\n",
      "15/15 - 0s - loss: 0.5955 - accuracy: 0.7878\n",
      "------------    7  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  177.21564149856567 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "8  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1970    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4849    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2808    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  1387    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4629    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  1692    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  4758    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1299    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3497    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2200    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3603    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  4035    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4182    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4961    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  1785    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  4570    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4133    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1322    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  3005    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2339    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "8  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "8  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "8  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4873 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 0.4774 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.5531 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.6192 - accuracy: 0.7899\n",
      "15/15 - 0s - loss: 0.4750 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.5692 - accuracy: 0.8046\n",
      "15/15 - 0s - loss: 0.6383 - accuracy: 0.7668\n",
      "15/15 - 0s - loss: 0.5267 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.5485 - accuracy: 0.7983\n",
      "15/15 - 0s - loss: 0.4478 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.6668 - accuracy: 0.7584\n",
      "15/15 - 0s - loss: 0.5460 - accuracy: 0.7857\n",
      "15/15 - 0s - loss: 0.5613 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.5554 - accuracy: 0.7920\n",
      "15/15 - 0s - loss: 0.5076 - accuracy: 0.7962\n",
      "15/15 - 0s - loss: 0.5477 - accuracy: 0.8130\n",
      "15/15 - 0s - loss: 0.5787 - accuracy: 0.7752\n",
      "15/15 - 0s - loss: 0.5390 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.4577 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.5335 - accuracy: 0.8172\n",
      "------------    8  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  195.4270191192627 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "9  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4463    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4785    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3806    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  2655    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2684    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  3344    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  4251    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3731    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  2818    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  4713    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3384    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1288    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1308    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2071    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  1343    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3844    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  2866    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2593    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4872    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3365    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "9  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "9  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "9  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.5009 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.6540 - accuracy: 0.7374\n",
      "15/15 - 0s - loss: 0.5796 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.5259 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 0.4796 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.5940 - accuracy: 0.7794\n",
      "15/15 - 0s - loss: 0.5514 - accuracy: 0.7878\n",
      "15/15 - 0s - loss: 0.5169 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.5660 - accuracy: 0.7962\n",
      "15/15 - 0s - loss: 0.4764 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.4913 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4475 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.5543 - accuracy: 0.7857\n",
      "15/15 - 0s - loss: 0.5431 - accuracy: 0.7752\n",
      "15/15 - 0s - loss: 0.4619 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4748 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.5387 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.4923 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.4162 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.5297 - accuracy: 0.7920\n",
      "------------    9  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  199.35673999786377 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "10  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2261    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4355    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1981    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3073    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2165    Number of Training sets :  476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  3451    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1904    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3725    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3034    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  4249    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  2058    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2511    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1720    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2856    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3278    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3548    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1674    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  3664    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1653    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1730    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "10  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "10  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "10  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.5222 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.4490 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4951 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.5238 - accuracy: 0.8046\n",
      "15/15 - 0s - loss: 0.4906 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.5792 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.4089 - accuracy: 0.8782\n",
      "15/15 - 0s - loss: 0.4527 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.5839 - accuracy: 0.7920\n",
      "15/15 - 0s - loss: 0.4377 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.5216 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.4582 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.5213 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.5326 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.5126 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.4088 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.5339 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.4989 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.4929 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4540 - accuracy: 0.8319\n",
      "------------    10  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  177.40459156036377 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "11  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2856    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  3752    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3098    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  2031    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2729    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2728    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3804    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1005    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3356    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2942    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3889    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  3844    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4385    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4175    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3940    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  1735    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4391    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4128    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2878    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3682    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "11  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "11  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "11  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.5100 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.4653 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.5304 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 0.5127 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.5600 - accuracy: 0.7983\n",
      "15/15 - 0s - loss: 0.4946 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.5221 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.4795 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.5178 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.5136 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.4716 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.5520 - accuracy: 0.7878\n",
      "15/15 - 0s - loss: 0.5277 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.5549 - accuracy: 0.7899\n",
      "15/15 - 0s - loss: 0.5038 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 0.4922 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.5014 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.4762 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.4672 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.6287 - accuracy: 0.7794\n",
      "------------    11  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  191.02143096923828 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "12  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3660    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4564    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3498    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  1808    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1393    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  1825    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1476    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4110    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  2175    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  4378    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1730    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2838    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1554    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3647    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3675    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  4574    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  2350    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4009    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2282    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3762    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "12  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "12  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "12  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4559 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.4392 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.4846 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.4766 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4539 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.5265 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.5265 - accuracy: 0.7962\n",
      "15/15 - 0s - loss: 0.4512 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.5190 - accuracy: 0.8088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - loss: 0.4784 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4384 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4592 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.5202 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.4849 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.4841 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.5830 - accuracy: 0.8046\n",
      "15/15 - 0s - loss: 0.5147 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 0.4261 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4741 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.5206 - accuracy: 0.8046\n",
      "------------    12  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  189.08674502372742 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "13  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1690    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  1444    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2378    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4781    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4172    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  1713    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3475    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  2998    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3129    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  4949    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  2344    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2425    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4269    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2252    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  1592    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2213    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4410    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4733    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4601    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1407    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "13  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "13  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "13  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.3959 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.5255 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.5534 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 0.4582 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4781 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4341 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4516 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4372 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.5255 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.3717 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4886 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.5377 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.3694 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4528 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.5348 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.4706 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4378 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4693 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.3983 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.4794 - accuracy: 0.8529\n",
      "------------    13  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  163.95550417900085 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "14  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2923    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  1992    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3537    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3055    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1064    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4727    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1757    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4138    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  2403    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3391    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3472    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1434    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  3199    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2939    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  1166    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3504    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1803    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  3035    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2574    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2283    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "14  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "14  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "14  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4471 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.4418 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4906 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.5344 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.4878 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.4603 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.5728 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.3302 - accuracy: 0.8908\n",
      "15/15 - 0s - loss: 0.5249 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.5061 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.5085 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4737 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.5288 - accuracy: 0.7899\n",
      "15/15 - 0s - loss: 0.5368 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 0.6158 - accuracy: 0.7794\n",
      "15/15 - 0s - loss: 0.4275 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.5007 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.5339 - accuracy: 0.8130\n",
      "15/15 - 0s - loss: 0.4782 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.4465 - accuracy: 0.8319\n",
      "------------    14  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  151.69571495056152 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "15  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3920    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4781    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1630    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  1277    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4943    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4948    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1850    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4145    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  4866    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3017    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  4295    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  3646    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  2191    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2014    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2754    Number of Training sets :  476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  1550    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1364    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1759    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4259    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1811    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "15  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "15  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "15  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4537 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4443 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.4929 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.5503 - accuracy: 0.7962\n",
      "15/15 - 0s - loss: 0.4365 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.4831 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.5930 - accuracy: 0.7773\n",
      "15/15 - 0s - loss: 0.5213 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.4589 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4383 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4898 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.4214 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.5176 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4552 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4734 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.5116 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.5531 - accuracy: 0.8130\n",
      "15/15 - 0s - loss: 0.5443 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.4762 - accuracy: 0.8046\n",
      "15/15 - 0s - loss: 0.5138 - accuracy: 0.8193\n",
      "------------    15  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  160.10689616203308 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "16  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1241    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2595    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  4278    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  2957    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  3482    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4755    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3040    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4661    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  4212    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  4113    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3486    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  3873    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4286    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3039    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3831    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2000    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1990    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4491    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4712    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3276    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "16  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "16  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "16  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4231 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.4445 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.4159 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4514 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.5059 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.4601 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.4544 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.5086 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.4797 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.5475 - accuracy: 0.7815\n",
      "15/15 - 0s - loss: 0.4735 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.5030 - accuracy: 0.8130\n",
      "15/15 - 0s - loss: 0.4702 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.5690 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.4209 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4670 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.5688 - accuracy: 0.7962\n",
      "15/15 - 0s - loss: 0.4376 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.5128 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.4452 - accuracy: 0.8382\n",
      "------------    16  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  177.675035238266 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "17  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4152    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4378    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  4164    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3022    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2470    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2628    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1822    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1487    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3037    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  1888    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3612    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  3451    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1518    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3659    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2911    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  1091    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1969    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2699    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4046    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2483    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "17  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "17  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "17  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4909 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.4638 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.3574 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.4174 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.5255 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.5332 - accuracy: 0.7941\n",
      "15/15 - 0s - loss: 0.4687 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4914 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.4575 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4235 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.6106 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.4682 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.4805 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.5223 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4666 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.5244 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.5488 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.4700 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.3869 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.5119 - accuracy: 0.8193\n",
      "------------    17  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  154.3623504638672 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "18  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1215    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2205    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3359    Number of Training sets :  476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3556    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2266    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  1516    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  2973    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3460    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3472    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  1880    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3861    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1854    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  3519    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3741    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3798    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  1934    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4401    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  3426    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  3026    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  4206    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "18  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "18  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "18  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4596 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.5292 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.4792 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.4775 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.4015 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4247 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4328 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4631 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.5129 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.5642 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.4600 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.3727 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.4508 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.4767 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.5103 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4778 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.4116 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.4655 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.5566 - accuracy: 0.7962\n",
      "15/15 - 0s - loss: 0.4171 - accuracy: 0.8319\n",
      "------------    18  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  158.84911012649536 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "19  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4728    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  1016    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2037    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  1723    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4311    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4909    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3846    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4908    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3197    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2712    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1190    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1089    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  3433    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4015    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  1801    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  1180    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1197    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4963    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4860    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  4451    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "19  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "19  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "19  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.3862 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.5374 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4868 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.4438 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4962 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4123 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.4422 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.4386 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4645 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4556 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.4036 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.6303 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4372 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.3852 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.4742 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.6085 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.4640 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4267 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.3853 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.4272 - accuracy: 0.8403\n",
      "------------    19  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  162.67650079727173 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "20  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3444    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2997    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2607    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4783    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2792    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4806    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1261    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4091    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  4309    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3836    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1525    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1400    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  3262    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3690    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4685    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  4357    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  3104    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2332    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2354    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2627    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "20  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "20  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "20  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.5154 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.6792 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.5838 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4671 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.5388 - accuracy: 0.8340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - loss: 0.5253 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.5934 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4118 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.5672 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.4874 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.6227 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.7179 - accuracy: 0.7983\n",
      "15/15 - 0s - loss: 0.5912 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4388 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.4036 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4461 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.5038 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4240 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.5479 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.5725 - accuracy: 0.8340\n",
      "------------    20  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  178.2028889656067 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "21  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1313    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4521    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3726    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  2477    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4329    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4473    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  2434    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1703    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  2874    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  1411    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  2601    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1443    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  2642    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4849    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2759    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2786    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1903    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2766    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1747    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1426    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "21  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "21  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "21  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4528 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.3624 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.4596 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4419 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.3645 - accuracy: 0.8761\n",
      "15/15 - 0s - loss: 0.5970 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.4883 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4532 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.5119 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.5563 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.5329 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.4663 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4631 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.3873 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4635 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4765 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4310 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.4707 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.5452 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.5401 - accuracy: 0.8319\n",
      "------------    21  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  152.42118525505066 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "22  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3385    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  3653    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2899    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  2298    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1657    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  3919    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  2206    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  2099    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  1861    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2022    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1338    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  4420    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  2833    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2638    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4664    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2718    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1439    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2689    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1757    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3066    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "22  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "22  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "22  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4441 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.4188 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4664 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.5263 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.3705 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.4086 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4575 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4694 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4053 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.5081 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.3919 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.5213 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.3983 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4828 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4196 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.5150 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.4475 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.3260 - accuracy: 0.8929\n",
      "15/15 - 0s - loss: 0.4771 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.3357 - accuracy: 0.8761\n",
      "------------    22  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  149.13060021400452 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "23  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4563    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  3326    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3670    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4416    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  3533    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2463    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  2408    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3709    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  4365    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  4620    Number of Training sets :  476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3893    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1160    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4461    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2447    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  1635    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2920    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  3818    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4386    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2168    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2369    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "23  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "23  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "23  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.3897 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4025 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4035 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.3998 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4000 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.4258 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.4473 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4481 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4432 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4158 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.3257 - accuracy: 0.8824\n",
      "15/15 - 0s - loss: 0.4429 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4775 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4043 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.3565 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.3979 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4521 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.4146 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4156 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4416 - accuracy: 0.8466\n",
      "------------    23  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  179.20360779762268 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "24  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1307    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4445    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  4816    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4234    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  3113    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2150    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  4784    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  2776    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3949    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  4837    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  2207    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2638    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  3425    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4183    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3174    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  4195    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  3968    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1604    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1174    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3163    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "24  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "24  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "24  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.3675 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.3708 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.3364 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.3312 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.4787 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.4393 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4254 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4429 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4028 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4245 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4035 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.4990 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.4277 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.4053 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.3845 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4306 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.3742 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.3209 - accuracy: 0.8908\n",
      "15/15 - 0s - loss: 0.3969 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.3412 - accuracy: 0.8929\n",
      "------------    24  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  181.2615487575531 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "25  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3163    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2948    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  4507    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4628    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1202    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2137    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1286    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1478    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  2828    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  4979    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3523    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  4826    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1024    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2630    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2117    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2881    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4506    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2061    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1519    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2878    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "25  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "25  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "25  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4959 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.3631 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.3827 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.3949 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4578 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.5325 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.3630 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4270 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.4502 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.5000 - accuracy: 0.8109\n",
      "15/15 - 0s - loss: 0.4966 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4602 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.4415 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.4218 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4449 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4482 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.4396 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.3640 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.4823 - accuracy: 0.8445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - loss: 0.3892 - accuracy: 0.8634\n",
      "------------    25  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  174.911315202713 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "26  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1819    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  1689    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  4213    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4224    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2457    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2225    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1396    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4190    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3208    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  1960    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3989    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  4289    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4884    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  1146    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  1954    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3908    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4669    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2777    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4597    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  4710    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "26  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "26  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "26  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4271 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.3066 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.4485 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4018 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.4310 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4085 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.3825 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.4649 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.3379 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.3889 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4455 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.4035 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.3405 - accuracy: 0.8761\n",
      "15/15 - 0s - loss: 0.4816 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4405 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.3519 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.2992 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.4424 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.3754 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.3618 - accuracy: 0.8718\n",
      "------------    26  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  190.85407757759094 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "27  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1641    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  1381    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1799    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3211    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2700    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4745    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3853    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1704    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  2768    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3128    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  2526    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  4098    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  3083    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4372    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2266    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  4513    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1359    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1826    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  3267    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3608    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "27  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "27  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "27  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4315 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.4139 - accuracy: 0.8761\n",
      "15/15 - 0s - loss: 0.4561 - accuracy: 0.8929\n",
      "15/15 - 0s - loss: 0.5485 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.5241 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4066 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.5316 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.6097 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4558 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.5475 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.5448 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.3899 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4239 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4492 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.6104 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.5920 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.8293 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.6357 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.3469 - accuracy: 0.8929\n",
      "15/15 - 0s - loss: 0.3471 - accuracy: 0.8824\n",
      "------------    27  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  180.04615473747253 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "28  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2114    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  1008    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3335    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  1337    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  3750    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4832    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  4885    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3329    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  1989    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  1436    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1656    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2236    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4669    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2432    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3789    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2605    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4728    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2151    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4692    Number of Training sets :  476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  4715    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "28  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "28  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "28  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.6337 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.7450 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.5861 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.6461 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4482 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.4223 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.6393 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.6599 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.4532 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.6859 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.5409 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4581 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.3723 - accuracy: 0.8845\n",
      "15/15 - 0s - loss: 0.6869 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4409 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.5689 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4459 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.6237 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4187 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.4549 - accuracy: 0.8571\n",
      "------------    28  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  189.65479946136475 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "29  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4289    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4773    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2702    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4667    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4029    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2789    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  2151    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4204    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3539    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2723    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  4764    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1729    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4074    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2170    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2482    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  4466    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  3772    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1698    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4712    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1299    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "29  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "29  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "29  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.7723 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.7286 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 1.1016 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 1.0006 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.8454 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 1.1577 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 1.0390 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.7936 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.9114 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.9537 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 1.0669 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 1.4666 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 1.2737 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 1.4414 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 1.4175 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 1.4218 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 1.2890 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 1.5476 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 1.0244 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 1.8179 - accuracy: 0.8571\n",
      "------------    29  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  213.26705193519592 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "30  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4056    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  3133    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  4380    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4009    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4927    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4917    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  2449    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1733    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  1817    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3246    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1125    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1691    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1691    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3583    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2384    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  1448    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  2851    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1304    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4968    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  4761    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "30  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "30  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "30  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4173 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.4401 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.3987 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4163 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.3684 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.3932 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4526 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.3715 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.3798 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.4238 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4251 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4453 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.3738 - accuracy: 0.8782\n",
      "15/15 - 0s - loss: 0.4110 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.3265 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.5277 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.3880 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.3772 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.3060 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.4190 - accuracy: 0.8613\n",
      "------------    30  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  221.94807934761047 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "31  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2596    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  1990    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1230    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  2011    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2645    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4392    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1283    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3871    Number of Training sets :  476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  1263    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  1033    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3550    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  3028    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1026    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3033    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4590    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3403    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1391    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4331    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4498    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  4899    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "31  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "31  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "31  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4349 - accuracy: 0.8908\n",
      "15/15 - 0s - loss: 0.4247 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.8397 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.7911 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.5472 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.5226 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 1.0050 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.5536 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.8386 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.9221 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.5335 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.5225 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.7325 - accuracy: 0.8845\n",
      "15/15 - 0s - loss: 0.5579 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4591 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.3622 - accuracy: 0.8866\n",
      "15/15 - 0s - loss: 0.6942 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.4056 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.4856 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4599 - accuracy: 0.8634\n",
      "------------    31  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  237.54120802879333 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "32  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1326    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2627    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  4041    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  2212    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4641    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  3597    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  2680    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3821    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3602    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  1817    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  4086    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2598    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  3922    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4254    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3662    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  4502    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  3921    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4984    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4529    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3182    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "32  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "32  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "32  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 1.7237 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 1.6289 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.9491 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 2.2529 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.8128 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.9836 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 1.3335 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.9832 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 1.2924 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 2.5717 - accuracy: 0.8130\n",
      "15/15 - 0s - loss: 1.0193 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 1.4725 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 1.1332 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.8215 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.7856 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.7590 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 1.3992 - accuracy: 0.8046\n",
      "15/15 - 0s - loss: 0.6383 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.6357 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 1.0625 - accuracy: 0.8214\n",
      "------------    32  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  297.16575384140015 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "33  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2799    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4499    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  4909    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  1365    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1963    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2777    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  4652    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  2965    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  1030    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  4252    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3492    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  4276    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1304    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3663    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4011    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2864    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4435    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4238    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4182    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3603    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "33  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "33  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "33  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 1.7564 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 1.0424 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.7055 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 1.6725 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 1.3146 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 1.1415 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 1.2068 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.8408 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.8082 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 1.0981 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.9178 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.7591 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.7153 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 1.2630 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.9077 - accuracy: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - loss: 1.0058 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.8062 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 1.3359 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.8499 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.8722 - accuracy: 0.8319\n",
      "------------    33  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  297.7523407936096 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "34  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3358    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  3565    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2761    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3948    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2546    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  3744    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3187    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1896    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3409    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  4022    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3274    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2364    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  3439    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3142    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2815    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3889    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  2256    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  3587    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2867    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3872    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "34  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "34  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "34  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 2.1010 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.8176 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 1.5701 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 1.1459 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.7849 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 1.1259 - accuracy: 0.7626\n",
      "15/15 - 0s - loss: 1.3296 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.8796 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.9757 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 1.0362 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.9694 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 1.0339 - accuracy: 0.7983\n",
      "15/15 - 0s - loss: 0.8877 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 2.1395 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 1.3147 - accuracy: 0.7983\n",
      "15/15 - 0s - loss: 1.2204 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 1.4035 - accuracy: 0.7941\n",
      "15/15 - 0s - loss: 1.1428 - accuracy: 0.7794\n",
      "15/15 - 0s - loss: 1.4577 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 1.1364 - accuracy: 0.8445\n",
      "------------    34  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  286.47221088409424 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "35  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3340    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2391    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3654    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3106    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4742    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4951    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3146    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1617    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3726    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2170    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  2728    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1821    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1613    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2637    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3900    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3206    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4331    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2464    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  3681    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1106    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "35  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "35  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "35  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 1.1776 - accuracy: 0.7584\n",
      "15/15 - 0s - loss: 1.8522 - accuracy: 0.7500\n",
      "15/15 - 0s - loss: 2.6545 - accuracy: 0.7563\n",
      "15/15 - 0s - loss: 1.5188 - accuracy: 0.7437\n",
      "15/15 - 0s - loss: 1.5397 - accuracy: 0.7605\n",
      "15/15 - 0s - loss: 1.8847 - accuracy: 0.7668\n",
      "15/15 - 0s - loss: 1.3538 - accuracy: 0.7185\n",
      "15/15 - 0s - loss: 1.1944 - accuracy: 0.7647\n",
      "15/15 - 0s - loss: 1.7324 - accuracy: 0.7584\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.7899\n",
      "15/15 - 0s - loss: 1.3050 - accuracy: 0.7248\n",
      "15/15 - 0s - loss: 1.2788 - accuracy: 0.7899\n",
      "15/15 - 0s - loss: 1.4546 - accuracy: 0.7647\n",
      "15/15 - 0s - loss: 3.9540 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 2.5822 - accuracy: 0.7500\n",
      "15/15 - 0s - loss: 2.2339 - accuracy: 0.7353\n",
      "15/15 - 0s - loss: 1.1359 - accuracy: 0.7395\n",
      "15/15 - 0s - loss: 2.0747 - accuracy: 0.7668\n",
      "15/15 - 0s - loss: 1.3558 - accuracy: 0.7521\n",
      "15/15 - 0s - loss: 2.3138 - accuracy: 0.7836\n",
      "------------    35  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  279.816522359848 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "36  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3669    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  3702    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2970    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4766    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1281    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  1175    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3241    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1802    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  2208    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3168    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3077    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2016    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4482    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2375    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2359    Number of Training sets :  476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3846    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4004    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  3317    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1700    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2418    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "36  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "36  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "36  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4572 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4168 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.5690 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.5223 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.6341 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.5520 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.5014 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.3979 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.3795 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.4353 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.3196 - accuracy: 0.8887\n",
      "15/15 - 0s - loss: 0.6268 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.5154 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.4857 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.3633 - accuracy: 0.8845\n",
      "15/15 - 0s - loss: 0.5587 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.3105 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4197 - accuracy: 0.8908\n",
      "15/15 - 0s - loss: 0.4905 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4170 - accuracy: 0.8634\n",
      "------------    36  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  297.6750783920288 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "37  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4219    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  3386    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  4183    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4814    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4730    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2507    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  2159    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1200    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3277    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  1069    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1213    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  3130    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1567    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  1255    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4317    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3938    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4071    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1480    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2262    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3724    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "37  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "37  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "37  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4005 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.3739 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4221 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.4417 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.4098 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.5077 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.4443 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.4325 - accuracy: 0.8782\n",
      "15/15 - 0s - loss: 0.3324 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4978 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.4066 - accuracy: 0.8782\n",
      "15/15 - 0s - loss: 0.4681 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4737 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.5274 - accuracy: 0.8761\n",
      "15/15 - 0s - loss: 0.4097 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.4833 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.3977 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4316 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.4394 - accuracy: 0.8761\n",
      "15/15 - 0s - loss: 0.4057 - accuracy: 0.8592\n",
      "------------    37  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  314.2718312740326 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "38  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1981    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2015    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2844    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3315    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2958    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4736    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  4391    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3591    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  2731    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2229    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  4264    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1514    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4367    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3903    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3247    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  4649    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  2868    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4851    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1307    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  4049    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "38  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "38  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "38  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.5092 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4401 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.3980 - accuracy: 0.8866\n",
      "15/15 - 0s - loss: 0.4114 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.4091 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.3978 - accuracy: 0.8887\n",
      "15/15 - 0s - loss: 0.5642 - accuracy: 0.8382\n",
      "15/15 - 0s - loss: 0.3345 - accuracy: 0.8845\n",
      "15/15 - 0s - loss: 0.3426 - accuracy: 0.8761\n",
      "15/15 - 0s - loss: 0.4077 - accuracy: 0.8845\n",
      "15/15 - 0s - loss: 0.3227 - accuracy: 0.8887\n",
      "15/15 - 0s - loss: 0.4170 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.3589 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4585 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.4220 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4604 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4627 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.4207 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.4648 - accuracy: 0.8782\n",
      "15/15 - 0s - loss: 0.5356 - accuracy: 0.8550\n",
      "------------    38  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  362.60040831565857 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "39  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2272    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2233    Number of Training sets :  476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3106    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4036    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1081    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4640    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3835    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4489    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  1614    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3776    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  4444    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1136    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1970    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4506    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3452    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2713    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4684    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  3858    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2548    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1675    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "39  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "39  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "39  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.7335 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.6016 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.6117 - accuracy: 0.8845\n",
      "15/15 - 0s - loss: 0.5665 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.5673 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.5222 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.4600 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.4099 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.6894 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.6058 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.5523 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.5376 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.5574 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4793 - accuracy: 0.8782\n",
      "15/15 - 0s - loss: 0.5245 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.7806 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.5440 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.4190 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.5670 - accuracy: 0.8782\n",
      "15/15 - 0s - loss: 0.9396 - accuracy: 0.8487\n",
      "------------    39  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  352.94005370140076 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "40  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2131    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  3525    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1481    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3347    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1042    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  3258    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  2204    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1682    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  4295    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3411    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  5000    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1188    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  2342    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2298    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3397    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  1718    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  1790    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  4470    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1075    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1890    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "40  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "40  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "40  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.3580 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4229 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.4503 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4009 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.3610 - accuracy: 0.8971\n",
      "15/15 - 0s - loss: 0.3549 - accuracy: 0.8845\n",
      "15/15 - 0s - loss: 0.4538 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.4637 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.3847 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.3220 - accuracy: 0.8845\n",
      "15/15 - 0s - loss: 0.4282 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.4333 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4236 - accuracy: 0.8887\n",
      "15/15 - 0s - loss: 0.3057 - accuracy: 0.8929\n",
      "15/15 - 0s - loss: 0.4216 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.3644 - accuracy: 0.8761\n",
      "15/15 - 0s - loss: 0.4451 - accuracy: 0.8824\n",
      "15/15 - 0s - loss: 0.3330 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.4326 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4080 - accuracy: 0.8613\n",
      "------------    40  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  304.71727299690247 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "41  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4114    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  1632    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1600    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  1712    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1263    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  3937    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1057    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  2952    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  1975    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3898    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1646    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2877    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  4530    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4850    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2874    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  4683    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4700    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2210    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  3412    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1982    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "41  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "41  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "41  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.3301 - accuracy: 0.8866\n",
      "15/15 - 0s - loss: 0.5166 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.4205 - accuracy: 0.8592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - loss: 0.3649 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.5112 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.3889 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.3889 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.4238 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.3961 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.3316 - accuracy: 0.8866\n",
      "15/15 - 0s - loss: 0.4903 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.3485 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.4287 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.3182 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.4210 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.3735 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.3594 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4489 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.3919 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.3788 - accuracy: 0.8634\n",
      "------------    41  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  352.4990577697754 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "42  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1818    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  3174    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3614    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3784    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  3711    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  1007    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  2334    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3661    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3542    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2096    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3294    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  4405    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1851    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  2546    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  3933    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  1923    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4592    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1859    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2766    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1864    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "42  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "42  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "42  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4059 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4410 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.3799 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4268 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4912 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.3485 - accuracy: 0.8824\n",
      "15/15 - 0s - loss: 0.4681 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.3835 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.3844 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4513 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.3294 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.3722 - accuracy: 0.8718\n",
      "15/15 - 0s - loss: 0.4524 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4297 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.3273 - accuracy: 0.8950\n",
      "15/15 - 0s - loss: 0.4299 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.3886 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4226 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.3582 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.5142 - accuracy: 0.8130\n",
      "------------    42  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  364.7892882823944 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "43  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3675    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2470    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1713    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3233    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  1565    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  3312    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3010    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4227    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  2982    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2139    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  2614    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  3355    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1539    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4050    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4254    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  1954    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  2778    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1413    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  3511    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2484    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "43  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "43  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "43  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4522 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.3909 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4754 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.4035 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.4707 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4036 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4871 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.4490 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.3932 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.4782 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.3794 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.5007 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4272 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.3891 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.4142 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.4113 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.5185 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.3944 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4602 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4265 - accuracy: 0.8340\n",
      "------------    43  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  376.308767080307 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "44  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4827    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2595    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  3671    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  2317    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2574    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  1776    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3235    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1436    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3301    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  1817    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3893    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2679    Number of Training sets :  476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1491    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3541    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2389    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2959    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  2435    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1199    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1641    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1564    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "44  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "44  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "44  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.3951 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4722 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.5146 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.3428 - accuracy: 0.8803\n",
      "15/15 - 0s - loss: 0.3813 - accuracy: 0.8655\n",
      "15/15 - 0s - loss: 0.4266 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.3376 - accuracy: 0.8845\n",
      "15/15 - 0s - loss: 0.4940 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4765 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.3849 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.4208 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.4047 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.4948 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.3653 - accuracy: 0.8634\n",
      "15/15 - 0s - loss: 0.4729 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4015 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.3890 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.5158 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.5015 - accuracy: 0.8277\n",
      "15/15 - 0s - loss: 0.3737 - accuracy: 0.8634\n",
      "------------    44  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  473.89113330841064 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "45  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  4161    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  2120    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2383    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3008    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4051    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2828    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  4639    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  4985    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  2114    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2907    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1706    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1051    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1824    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  1361    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  1580    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3786    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  3480    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1364    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1061    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2143    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "45  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "45  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "45  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4101 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.5326 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.4500 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4242 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.4427 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4715 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4740 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.4207 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.5493 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.4758 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4430 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.5627 - accuracy: 0.7983\n",
      "15/15 - 0s - loss: 0.5313 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.4767 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.5572 - accuracy: 0.7941\n",
      "15/15 - 0s - loss: 0.4206 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4179 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.5189 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.5538 - accuracy: 0.7962\n",
      "15/15 - 0s - loss: 0.6564 - accuracy: 0.7668\n",
      "------------    45  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  402.219363451004 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "46  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3596    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4538    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2207    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  1803    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  2481    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4989    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1044    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1497    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  3268    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  1018    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  2298    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  3455    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  1483    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  1452    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4228    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3717    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4110    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1600    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  1613    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  1006    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "46  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "46  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "46  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4808 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.4188 - accuracy: 0.8466\n",
      "15/15 - 0s - loss: 0.4319 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.5027 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.4483 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4370 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.5353 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.4873 - accuracy: 0.7983\n",
      "15/15 - 0s - loss: 0.5215 - accuracy: 0.8193\n",
      "15/15 - 0s - loss: 0.4863 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.4329 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.4732 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.5862 - accuracy: 0.7857\n",
      "15/15 - 0s - loss: 0.4635 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.4205 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4928 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 0.4184 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.5447 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.4470 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.5646 - accuracy: 0.7962\n",
      "------------    46  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  416.64915800094604 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1701    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4986    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  1554    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3397    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  3737    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4990    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  4397    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3178    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  1212    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2825    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  4762    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  1916    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  3234    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3754    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2607    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  2089    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  3559    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1424    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  3090    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  4369    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "47  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "47  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "47  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.5870 - accuracy: 0.7605\n",
      "15/15 - 0s - loss: 0.5643 - accuracy: 0.7983\n",
      "15/15 - 0s - loss: 0.5534 - accuracy: 0.7941\n",
      "15/15 - 0s - loss: 0.5081 - accuracy: 0.8046\n",
      "15/15 - 0s - loss: 0.5662 - accuracy: 0.7962\n",
      "15/15 - 0s - loss: 0.5651 - accuracy: 0.7773\n",
      "15/15 - 0s - loss: 0.4744 - accuracy: 0.8025\n",
      "15/15 - 0s - loss: 0.4890 - accuracy: 0.8004\n",
      "15/15 - 0s - loss: 0.6950 - accuracy: 0.7332\n",
      "15/15 - 0s - loss: 0.5177 - accuracy: 0.7878\n",
      "15/15 - 0s - loss: 0.4954 - accuracy: 0.8256\n",
      "15/15 - 1s - loss: 0.6399 - accuracy: 0.7479\n",
      "15/15 - 0s - loss: 0.5813 - accuracy: 0.7731\n",
      "15/15 - 0s - loss: 0.4949 - accuracy: 0.8046\n",
      "15/15 - 0s - loss: 0.5699 - accuracy: 0.8046\n",
      "15/15 - 0s - loss: 0.6552 - accuracy: 0.7458\n",
      "15/15 - 0s - loss: 0.5047 - accuracy: 0.8088\n",
      "15/15 - 0s - loss: 0.7141 - accuracy: 0.7332\n",
      "15/15 - 0s - loss: 0.5185 - accuracy: 0.7983\n",
      "15/15 - 0s - loss: 0.5487 - accuracy: 0.8109\n",
      "------------    47  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  519.5816078186035 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "48  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  2663    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  4049    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2213    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  3373    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4900    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  1500    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  3826    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  3566    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  4623    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  2512    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1676    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  4905    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  2541    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  3200    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  4427    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3500    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4419    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  3623    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  4363    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  4813    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "48  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "48  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "48  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4243 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.5372 - accuracy: 0.8130\n",
      "15/15 - 0s - loss: 0.4502 - accuracy: 0.8319\n",
      "15/15 - 0s - loss: 0.3896 - accuracy: 0.8550\n",
      "15/15 - 0s - loss: 0.4521 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.5355 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.4572 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.5136 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.3925 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.4607 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.5153 - accuracy: 0.8214\n",
      "15/15 - 0s - loss: 0.4868 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.4401 - accuracy: 0.8424\n",
      "15/15 - 1s - loss: 0.4102 - accuracy: 0.8529\n",
      "15/15 - 0s - loss: 0.3839 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.5536 - accuracy: 0.8172\n",
      "15/15 - 0s - loss: 0.5131 - accuracy: 0.7941\n",
      "15/15 - 0s - loss: 0.4596 - accuracy: 0.8151\n",
      "15/15 - 0s - loss: 0.4729 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4183 - accuracy: 0.8571\n",
      "------------    48  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  587.2941246032715 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "49  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  3036    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  1976    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  4378    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  2747    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4177    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  4429    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  1746    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  2767    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  1894    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  3431    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  1091    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2769    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  3502    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  1908    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  1866    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  3214    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  2155    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  2195    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2937    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  2056    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "49  번째 global_epoch 데이터 랜덤 준비완료!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "49  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4063 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.5075 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4907 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.5811 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4352 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.4977 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.4855 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4887 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.6718 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.3886 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.6390 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.4332 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.5020 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.5748 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.4879 - accuracy: 0.8508\n",
      "15/15 - 0s - loss: 0.5080 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.3842 - accuracy: 0.8676\n",
      "15/15 - 0s - loss: 0.4712 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.5853 - accuracy: 0.8445\n",
      "15/15 - 0s - loss: 0.5223 - accuracy: 0.8382\n",
      "------------    49  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  445.316792011261 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n",
      "50  번째 global_epoch 데이터 랜덤하게 준비!!\n",
      "CHECK : 1  번째 로컬 클라이언트 Number of Training sets :  1473    Number of Training sets :  476\n",
      "CHECK : 2  번째 로컬 클라이언트 Number of Training sets :  1890    Number of Training sets :  476\n",
      "CHECK : 3  번째 로컬 클라이언트 Number of Training sets :  2005    Number of Training sets :  476\n",
      "CHECK : 4  번째 로컬 클라이언트 Number of Training sets :  4161    Number of Training sets :  476\n",
      "CHECK : 5  번째 로컬 클라이언트 Number of Training sets :  4941    Number of Training sets :  476\n",
      "CHECK : 6  번째 로컬 클라이언트 Number of Training sets :  2611    Number of Training sets :  476\n",
      "CHECK : 7  번째 로컬 클라이언트 Number of Training sets :  4006    Number of Training sets :  476\n",
      "CHECK : 8  번째 로컬 클라이언트 Number of Training sets :  1936    Number of Training sets :  476\n",
      "CHECK : 9  번째 로컬 클라이언트 Number of Training sets :  1972    Number of Training sets :  476\n",
      "CHECK : 10  번째 로컬 클라이언트 Number of Training sets :  1316    Number of Training sets :  476\n",
      "CHECK : 11  번째 로컬 클라이언트 Number of Training sets :  3734    Number of Training sets :  476\n",
      "CHECK : 12  번째 로컬 클라이언트 Number of Training sets :  2846    Number of Training sets :  476\n",
      "CHECK : 13  번째 로컬 클라이언트 Number of Training sets :  2806    Number of Training sets :  476\n",
      "CHECK : 14  번째 로컬 클라이언트 Number of Training sets :  4322    Number of Training sets :  476\n",
      "CHECK : 15  번째 로컬 클라이언트 Number of Training sets :  2276    Number of Training sets :  476\n",
      "CHECK : 16  번째 로컬 클라이언트 Number of Training sets :  4479    Number of Training sets :  476\n",
      "CHECK : 17  번째 로컬 클라이언트 Number of Training sets :  4472    Number of Training sets :  476\n",
      "CHECK : 18  번째 로컬 클라이언트 Number of Training sets :  1217    Number of Training sets :  476\n",
      "CHECK : 19  번째 로컬 클라이언트 Number of Training sets :  2403    Number of Training sets :  476\n",
      "CHECK : 20  번째 로컬 클라이언트 Number of Training sets :  3672    Number of Training sets :  476\n",
      "check=>: should be 0 ==  60000\n",
      "50  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "50  번째 global_epoch 데이터 랜덤 준비완료!!\n",
      "\n",
      "\n",
      "50  번째 global epoch에서 로컬 클라이언트 들 학습시작!\n",
      "\n",
      "학습 중 ...\n",
      "\n",
      "15/15 - 0s - loss: 0.4442 - accuracy: 0.8403\n",
      "15/15 - 0s - loss: 0.4022 - accuracy: 0.8697\n",
      "15/15 - 0s - loss: 0.4417 - accuracy: 0.8571\n",
      "15/15 - 0s - loss: 0.3929 - accuracy: 0.8613\n",
      "15/15 - 0s - loss: 0.4273 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.4253 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.3833 - accuracy: 0.8592\n",
      "15/15 - 0s - loss: 0.5345 - accuracy: 0.8067\n",
      "15/15 - 0s - loss: 0.4730 - accuracy: 0.8340\n",
      "15/15 - 0s - loss: 0.5410 - accuracy: 0.8298\n",
      "15/15 - 0s - loss: 0.3714 - accuracy: 0.8739\n",
      "15/15 - 0s - loss: 0.4456 - accuracy: 0.8487\n",
      "15/15 - 0s - loss: 0.4137 - accuracy: 0.8256\n",
      "15/15 - 0s - loss: 0.3805 - accuracy: 0.8424\n",
      "15/15 - 0s - loss: 0.4878 - accuracy: 0.8361\n",
      "15/15 - 1s - loss: 0.4126 - accuracy: 0.8382\n",
      "15/15 - 1s - loss: 0.4614 - accuracy: 0.8361\n",
      "15/15 - 0s - loss: 0.5702 - accuracy: 0.7920\n",
      "15/15 - 0s - loss: 0.4722 - accuracy: 0.8235\n",
      "15/15 - 0s - loss: 0.4098 - accuracy: 0.8676\n",
      "------------    50  번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time :  524.8919160366058 ---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====================================================== One Global Epoch =====================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "G_epoch = 51\n",
    "\n",
    "for global_epoch in range(1, G_epoch):\n",
    "\n",
    "    for layer_index in num_layers_list:\n",
    "        for i in range(1, local):  #FedAvg\n",
    "            globals()['FedAvg_L{}_iter{}_model'.format(i,global_epoch)] = globals()['FedAvg_L{}_iter{}_model'.format(i,global_epoch-1)]   #구조만 필요\n",
    "\n",
    "            globals()['FedAvg_L{}_iter{}_model'.format(i,global_epoch)].layers[layer_index].set_weights(globals()['G{}_w_layer{}'.format(global_epoch-1, layer_index)])  #set_weights\n",
    "        \n",
    "  \n",
    "    #----------------------------------------------------------------데이터 새로 준비----------------------------------------------------------------------------------\n",
    "    print(global_epoch, \" 번째 global_epoch 데이터 랜덤하게 준비!!\")\n",
    "\n",
    "    for i in range(1,local): #데이터 변수 선언, 빈 리스트로 초기화\n",
    "        globals()['L{}_x_train'.format(i)], globals()['L{}_x_test'.format(i)] = [],[]  \n",
    "        globals()['L{}_y_train'.format(i)], globals()['L{}_y_test'.format(i)] = [],[]  \n",
    "\n",
    "\n",
    "    for n in range(1,local): #x_train_range, 잘 작동함 => 확인 완료\n",
    "\n",
    "        x_train_range = list(np.arange(0,len(x_train)))  #0~59,999\n",
    "        x_test_range = list(np.arange(0,len(x_test)))  #0~9,999\n",
    "\n",
    "        tmp, tmp2 = [], []\n",
    "\n",
    "        num_pick = random.randint(1000, 5000) #변동 사항 #int(len(list(x_train_range))/local)\n",
    "        num_pick2 = int(len(x_test_range)/local) #test 데이터는 원래대로 항상 일정한 비율로 주면 될듯 => 어느정도 분량 이상 있어야 함\n",
    "        \n",
    "        tmp = random.sample(list(x_train_range), num_pick)  #1/10개 만큼 인덱스 랜덤 비복원 추출 => 랜덤으로 해야함\n",
    "        tmp2 = random.sample(list(x_test_range), num_pick2)\n",
    "\n",
    "        for i in range(len(tmp)):\n",
    "            globals()['L{}_x_train'.format(n)].append(x_train[tmp[i]])  #n번째 Cluster에 분할한 실제 x_train 데이터 저장\n",
    "            globals()['L{}_y_train'.format(n)].append(y_train[tmp[i]]) \n",
    "            #x_train_range.remove(tmp[i])  #랜덤 하게 뽑힌 원소갯수들 추출했으니 안에서 삭제  => 오래걸림\n",
    "\n",
    "        for j in range(len(tmp2)):\n",
    "            globals()['L{}_x_test'.format(n)].append(x_test[tmp2[j]])\n",
    "            globals()['L{}_y_test'.format(n)].append(y_test[tmp2[j]])\n",
    "            #x_test_range.remove(tmp2[j])  #랜덤 하게 뽑힌 원소 1000개 추출했으니 안에서 삭제  => 오래걸림\n",
    "        \n",
    "        print(\"CHECK :\", n,\" 번째 로컬 클라이언트 Number of Training sets : \", len(globals()['L{}_x_train'.format(n)]), \"   Number of Training sets : \", len(globals()['L{}_x_test'.format(n)]))\n",
    "\n",
    "    print(\"check=>: should be 0 == \", len(x_train_range))  #원소 하나도 없어야 함. 확인.\n",
    "    print(global_epoch, \" 번째 global_epoch 데이터 랜덤 준비완료!!\")\n",
    "\n",
    "    for i in range(1,local):\n",
    "        globals()['L{}_x_train'.format(i)] = np.array(globals()['L{}_x_train'.format(i)])\n",
    "        globals()['L{}_x_test'.format(i)] = np.array(globals()['L{}_x_test'.format(i)])\n",
    "        globals()['L{}_y_train'.format(i)] = np.array(globals()['L{}_y_train'.format(i)])\n",
    "        globals()['L{}_y_test'.format(i)] = np.array(globals()['L{}_y_test'.format(i)])\n",
    "\n",
    "\n",
    "    print(global_epoch, \" 번째 global_epoch 데이터 랜덤 준비완료!!\\n\\n\")\n",
    "\n",
    "    print(global_epoch, \" 번째 global epoch에서 로컬 클라이언트 들 학습시작!\\n\\n학습 중 ...\\n\")\n",
    "    \n",
    "\n",
    "    #-------------------------------------------------------------------여기가 핵심, 알고리즘 3개 따로 학습시켜야 함--------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    #======================================================================== FedAvg ========================================================================\n",
    "\n",
    "    fedavg_acc, fedavg_loss, now = [],[], time.time()\n",
    "\n",
    "    for i in range(1,local):\n",
    "        # 아까 옮겨줘서 모델 그대로 compile, train 시키면 됨      \n",
    "        globals()['FedAvg_L{}_iter{}_model'.format(i, global_epoch)].compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "        globals()['FedAvg_L{}_iter{}_model'.format(i, global_epoch)].fit(globals()['L{}_x_train'.format(i)], globals()['L{}_y_train'.format(i)], batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=0)\n",
    "\n",
    "        loss, acc = globals()['FedAvg_L{}_iter{}_model'.format(i, global_epoch)].evaluate(globals()['L{}_x_test'.format(i)], globals()['L{}_y_test'.format(i)], verbose=2)\n",
    "        \n",
    "        fedavg_acc.append(acc)  #acc 넣기\n",
    "        fedavg_loss.append(loss)  #loss 넣기\n",
    "\n",
    "    print(\"------------   \", global_epoch, \" 번째 global epoch < FedAVG > 로컬 클라이언트 학습 완료!,  Total Training time : \", time.time()-now,\"---------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# 로컬 모델들 학습 완료, 로컬모델에서 weight, bias 추출 -------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    for i in range(1, local):        \n",
    "        for layer_index in num_layers_list:\n",
    "            globals()['L{}_layer{}_w_tmp'.format(i,layer_index)] = globals()['FedAvg_L{}_iter{}_model'.format(i, global_epoch)].layers[layer_index].get_weights() #get_weights = w[0],b[1]로 구성, FedAvg\n",
    "            \n",
    "    #------------------------------------------------FedAvg--------------------------------------------------------바로 Fedavg 시키기\n",
    "    \n",
    "    for layer_index in num_layers_list:\n",
    "        globals()['G{}_w_layer{}'.format(global_epoch, layer_index)] = 0\n",
    "\n",
    "        globals()['var_list_layer{}_w'.format(layer_index)] = []\n",
    "        globals()['var_list_layer{}_b'.format(layer_index)] = []\n",
    "        w_scaler = len(globals()['L{}_x_train'.format(i)]) / 60000\n",
    "        \n",
    "        for i in range(1, local):\n",
    "            globals()['G{}_w_layer{}'.format(global_epoch, layer_index)] = globals()['G{}_w_layer{}'.format(global_epoch, layer_index)] + (np.array(globals()['L{}_layer{}_w_tmp'.format(i,layer_index)])*w_scaler)\n",
    "\n",
    "        for i in range(1, local):\n",
    "            globals()['var_list_layer{}_w'.format(layer_index)].append(np.var(globals()['G{}_w_layer{}'.format(global_epoch, layer_index)][0]))            \n",
    "            globals()['var_list_layer{}_b'.format(layer_index)].append(np.var(globals()['G{}_w_layer{}'.format(global_epoch, layer_index)][1]))\n",
    "            \n",
    "          \n",
    "        VAR_final_list_w.append(globals()['var_list_layer{}_w'.format(layer_index)])\n",
    "        VAR_final_list_b.append(globals()['var_list_layer{}_b'.format(layer_index)])\n",
    "    \n",
    "\n",
    "    FedAvg_ACC.append(fedavg_acc)\n",
    "    FedAvg_LOSS.append(fedavg_loss)\n",
    "\n",
    "    print(\"\\n\\n====================================================== One Global Epoch =====================================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1077,
     "status": "ok",
     "timestamp": 1627963428738,
     "user": {
      "displayName": "이훈민",
      "photoUrl": "",
      "userId": "00157268181097362793"
     },
     "user_tz": 240
    },
    "id": "zyIlPPiUlh8v",
    "outputId": "3b448d56-eebd-4cf2-93a0-7bf9f47d2677",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Accumulate Layer 0,2,4,6,7\n",
      "--------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Var Accumulate Weight\n",
      "--------------------------------------\n",
      "[1.3814808e-06, 3.7262726e-06, 0.0020933582, 0.015556488, 0.011864399, 0.011563524, 0.016357927, 0.021966197, 0.018215904, 0.036567584, 0.01410364, 0.037957672, 0.066075556, 0.014959316, 0.014608307, 0.009190669, 0.02534289, 0.021314254, 0.058807135, 0.13031569, 0.09850134, 0.022589846, 0.031862885, 0.023661293, 0.036819275, 0.038420327, 0.108797565, 0.1553872, 0.3805308, 0.07079339, 0.1843088, 0.49025896, 0.5486946, 0.7873566, 1.3069847, 0.17764033, 0.11406183, 0.17668186, 0.32218364, 0.099803, 0.04004443, 0.019867975, 0.011240948, 0.014885586, 0.006270702, 0.00795199, 0.0018117452, 0.019913651, 0.05383552]\n",
      "[4.8733614e-07, 5.822477e-07, 0.00033560558, 0.0050323014, 0.0030670005, 0.0030503955, 0.004341065, 0.005385229, 0.0039925273, 0.007665563, 0.0026216833, 0.008043695, 0.012554538, 0.0026457994, 0.002971108, 0.0019444538, 0.006219232, 0.00477589, 0.012776597, 0.02624315, 0.018879779, 0.0042822883, 0.0064755436, 0.0046829754, 0.00726612, 0.0072635356, 0.020035403, 0.027258532, 0.065085374, 0.011862878, 0.0318843, 0.08236881, 0.09073571, 0.12925416, 0.21359998, 0.028912004, 0.01897588, 0.02988363, 0.05395697, 0.016605416, 0.00687839, 0.0035751064, 0.00217256, 0.0032480357, 0.0014142026, 0.0021725285, 0.0005352993, 0.008344044, 0.021376846]\n",
      "[3.001176e-07, 7.2971267e-07, 0.00016609766, 0.0017153323, 0.0010208343, 0.0009918334, 0.0014125719, 0.001773641, 0.0013893313, 0.0026998858, 0.0009745161, 0.0028852718, 0.0047640707, 0.001048865, 0.0010694552, 0.00065652403, 0.0018999159, 0.0014980955, 0.003988686, 0.008570105, 0.006427216, 0.0014725944, 0.0021731758, 0.0016028984, 0.0024697054, 0.0025289515, 0.0071213674, 0.010017019, 0.024497082, 0.004560573, 0.01208683, 0.03191884, 0.03571866, 0.051314697, 0.085299484, 0.011579917, 0.0075450945, 0.011864386, 0.021671776, 0.006748931, 0.0027547388, 0.0014367385, 0.0008433107, 0.0011293055, 0.00046250815, 0.0006464092, 0.0001465503, 0.002280317, 0.006085998]\n",
      "[4.1317065e-07, 4.8032507e-07, 2.5976598e-05, 0.00055557035, 0.00043174677, 0.00040968807, 0.00055440376, 0.00070120505, 0.0005637933, 0.0010822793, 0.00040167206, 0.001150916, 0.0019414289, 0.0004301512, 0.00044098202, 0.00027171604, 0.00076755584, 0.00063497695, 0.0017606539, 0.003775886, 0.0028208839, 0.00064395106, 0.0010082282, 0.0007637732, 0.001194869, 0.0012435021, 0.0035534266, 0.004992492, 0.012176735, 0.0022676599, 0.006118059, 0.016100802, 0.018018344, 0.025965635, 0.043287095, 0.0058849794, 0.0038708826, 0.0061539705, 0.011240146, 0.003506339, 0.001460383, 0.0007825776, 0.00044549696, 0.00055080804, 0.00022601403, 0.00028948914, 6.4823595e-05, 0.0009196438, 0.0024189765]\n",
      "[3.406011e-06, 3.364704e-06, 6.447066e-05, 0.0011425952, 0.0011347753, 0.0012693338, 0.0018496141, 0.0028834278, 0.0028501044, 0.005533398, 0.0023797231, 0.0059893555, 0.010965501, 0.0026919446, 0.0025246707, 0.0014244847, 0.0034725447, 0.003076584, 0.00892588, 0.01986287, 0.015253568, 0.003907977, 0.0060618334, 0.0047655962, 0.007448636, 0.008189832, 0.024794752, 0.034808464, 0.08618212, 0.01601928, 0.046975654, 0.1240772, 0.13890445, 0.20438981, 0.34781158, 0.04807558, 0.033296667, 0.05573535, 0.10491352, 0.03325807, 0.014307047, 0.007430698, 0.0038209916, 0.0040094345, 0.0015710896, 0.0016240912, 0.0003243871, 0.0031895563, 0.008946613]\n",
      "\n",
      "Var Accumulate Bias\n",
      "--------------------------------------\n",
      "[6.411747e-08, 1.7602911e-06, 7.954508e-05, 0.00062909734, 0.00041127228, 0.00033177133, 0.000605574, 0.0010707574, 0.0010746231, 0.002884911, 0.0008830624, 0.0033657127, 0.00425997, 0.00072319445, 0.0011291008, 0.000977076, 0.0031277714, 0.002325249, 0.007065204, 0.0120377615, 0.006805074, 0.0016277408, 0.0031532748, 0.0024219141, 0.004408478, 0.0043689227, 0.0128907785, 0.013799636, 0.029361758, 0.0045469785, 0.0149372015, 0.0320417, 0.030114608, 0.039880756, 0.06312763, 0.008282089, 0.0060731755, 0.010595169, 0.017265163, 0.0048838556, 0.0023633721, 0.0016970299, 0.0014419192, 0.0023203217, 0.0011515145, 0.0014414416, 0.0003423852, 0.0032383194, 0.006966224]\n",
      "[3.479564e-08, 6.9552755e-07, 0.00016347738, 0.0016410443, 0.0014947046, 0.0014194949, 0.0018324124, 0.002192631, 0.0016284982, 0.002790266, 0.000955621, 0.0020323615, 0.0034940643, 0.0007881348, 0.00056789664, 0.00030221278, 0.00066231703, 0.00055572344, 0.0016494407, 0.0036405239, 0.0028198801, 0.00066661974, 0.0010722779, 0.00090741063, 0.001447802, 0.001537934, 0.0044724876, 0.005859687, 0.014332134, 0.002761103, 0.00721322, 0.018545916, 0.020851832, 0.031256236, 0.053251192, 0.0073742075, 0.004639533, 0.0068263873, 0.0126174595, 0.004020241, 0.0015331947, 0.0008063485, 0.000491485, 0.0006521886, 0.00028897988, 0.00029381012, 6.698191e-05, 0.00070161995, 0.0019796076]\n",
      "[2.807376e-08, 1.3729792e-06, 9.992223e-05, 0.0012542453, 0.001164144, 0.0011227112, 0.0013761234, 0.0018660617, 0.0017049853, 0.0035689555, 0.0013622602, 0.0032392845, 0.0057875793, 0.0013024765, 0.0011023341, 0.0006108722, 0.0013741852, 0.0011906489, 0.0031866601, 0.007306271, 0.005510445, 0.001295482, 0.0018064616, 0.0013802795, 0.0020077152, 0.0021032633, 0.0059818705, 0.008193939, 0.019893158, 0.0037086296, 0.010079817, 0.025929578, 0.029109169, 0.042440686, 0.071272776, 0.00967491, 0.0062726205, 0.009945165, 0.017938375, 0.0056221737, 0.0022623227, 0.0011684131, 0.0006295237, 0.00071352615, 0.00028130316, 0.00031259726, 7.076743e-05, 0.00077186566, 0.0027066101]\n",
      "[2.4703976e-08, 3.6403737e-06, 0.00010772063, 0.001611589, 0.0012045802, 0.0010299489, 0.0012339775, 0.0015243953, 0.0012061148, 0.0021788345, 0.00079793215, 0.0020118922, 0.0033843676, 0.00077144493, 0.00070999656, 0.00041062024, 0.0011009605, 0.00091244344, 0.0024480203, 0.0055550123, 0.004217307, 0.0009645593, 0.0013053704, 0.0009568436, 0.0013897404, 0.0014063932, 0.0038338744, 0.005478801, 0.01351466, 0.00255926, 0.00657993, 0.018183835, 0.020548724, 0.029754711, 0.050124094, 0.006842511, 0.0043753134, 0.0067735715, 0.012637611, 0.0040168725, 0.0015915674, 0.0007218008, 0.00036990677, 0.00045532204, 0.00017903712, 0.00024233953, 5.8215202e-05, 0.0009113021, 0.0033198684]\n",
      "[3.2213882e-07, 2.0166195e-05, 0.0003444175, 0.0025347662, 0.0019147459, 0.0015247219, 0.0017130703, 0.0020464282, 0.0015853991, 0.002739847, 0.0010472604, 0.0022761517, 0.0041296473, 0.0010273822, 0.00080648717, 0.0004866601, 0.0013154123, 0.001174782, 0.0031444307, 0.007874908, 0.006405038, 0.001523332, 0.0017624624, 0.0013400505, 0.0020281088, 0.002174709, 0.0061250567, 0.009746691, 0.025502663, 0.004802003, 0.012035825, 0.035154045, 0.04070675, 0.07004669, 0.15140882, 0.025382012, 0.016348423, 0.024801617, 0.04849133, 0.0153875295, 0.0058692554, 0.0024541204, 0.0010359057, 0.0009651279, 0.00034791854, 0.00036314264, 8.170859e-05, 0.0009513963, 0.004224484]\n",
      "\n",
      "\n",
      "Variance Change Layer 0,2,4,6,7\n",
      "--------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Var Changes Weight\n",
      "--------------------------------------\n",
      "[2.3447917e-06, 0.002089632, 0.01346313, -0.0036920896, -0.00030087493, 0.004794403, 0.00560827, -0.0037502926, 0.01835168, -0.022463944, 0.023854032, 0.028117884, -0.05111624, -0.00035100896, -0.0054176375, 0.01615222, -0.004028635, 0.03749288, 0.07150856, -0.03181435, -0.07591149, 0.009273039, -0.008201592, 0.013157982, 0.0016010515, 0.07037724, 0.046589628, 0.22514361, -0.3097374, 0.11351541, 0.30595016, 0.05843565, 0.238662, 0.51962805, -1.1293443, -0.0635785, 0.06262003, 0.14550178, -0.22238064, -0.05975857, -0.020176455, -0.008627027, 0.0036446378, -0.008614884, 0.0016812878, -0.0061402447, 0.018101906, 0.033921868, -0.0295542]\n",
      "[9.491157e-08, 0.00033502333, 0.004696696, -0.0019653009, -1.6605016e-05, 0.0012906694, 0.001044164, -0.0013927016, 0.0036730357, -0.0050438796, 0.005422012, 0.004510843, -0.0099087395, 0.00032530865, -0.0010266543, 0.004274778, -0.0014433418, 0.008000707, 0.013466553, -0.0073633716, -0.01459749, 0.0021932553, -0.0017925682, 0.0025831447, -2.5844201e-06, 0.012771867, 0.0072231293, 0.037826844, -0.053222496, 0.020021424, 0.050484512, 0.008366898, 0.03851845, 0.08434582, -0.18468797, -0.009936124, 0.010907751, 0.02407334, -0.037351556, -0.009727026, -0.0033032836, -0.0014025464, 0.0010754757, -0.001833833, 0.0007583259, -0.0016372292, 0.007808745, 0.013032802, -0.012047637]\n",
      "[4.2959508e-07, 0.00016536795, 0.0015492346, -0.00069449795, -2.900092e-05, 0.00042073848, 0.0003610691, -0.00038430968, 0.0013105544, -0.0017253696, 0.0019107556, 0.0018787989, -0.0037152057, 2.0590145e-05, -0.00041293114, 0.0012433918, -0.0004018204, 0.0024905906, 0.004581419, -0.002142889, -0.004954621, 0.00070058135, -0.00057027745, 0.00086680707, 5.9246086e-05, 0.004592416, 0.0028956514, 0.014480064, -0.01993651, 0.007526257, 0.019832008, 0.0037998222, 0.015596036, 0.033984788, -0.07371957, -0.0040348223, 0.004319291, 0.00980739, -0.014922844, -0.003994192, -0.0013180003, -0.0005934278, 0.00028599473, -0.0006667973, 0.00018390102, -0.00049985887, 0.0021337667, 0.003805681, -0.00328204]\n",
      "[6.715442e-08, 2.5496272e-05, 0.00052959373, -0.00012382359, -2.2058695e-05, 0.00014471568, 0.00014680129, -0.00013741176, 0.00051848596, -0.00068060716, 0.0007492439, 0.0007905129, -0.0015112776, 1.0830816e-05, -0.00016926599, 0.0004958398, -0.00013257889, 0.001125677, 0.002015232, -0.00095500215, -0.0021769328, 0.0003642771, -0.00024445495, 0.00043109583, 4.8633083e-05, 0.0023099245, 0.0014390654, 0.0071842433, -0.009909076, 0.0038503993, 0.009982742, 0.0019175429, 0.00794729, 0.01732146, -0.037402116, -0.0020140968, 0.002283088, 0.0050861756, -0.007733807, -0.002045956, -0.00067780534, -0.00033708065, 0.000105311075, -0.000324794, 6.3475105e-05, -0.00022466553, 0.0008548202, 0.0014993327, -0.0013206832]\n",
      "[-4.1306976e-08, 6.110596e-05, 0.0010781245, -7.81985e-06, 0.00013455842, 0.0005802803, 0.0010338137, -3.332342e-05, 0.0026832938, -0.003153675, 0.0036096324, 0.0049761455, -0.008273557, -0.00016727392, -0.001100186, 0.00204806, -0.00039596064, 0.005849296, 0.010936989, -0.0046093017, -0.011345591, 0.0021538562, -0.0012962371, 0.0026830398, 0.00074119586, 0.016604919, 0.010013713, 0.051373653, -0.07016284, 0.030956374, 0.07710154, 0.014827251, 0.06548536, 0.14342177, -0.299736, -0.014778912, 0.022438683, 0.04917817, -0.07165545, -0.018951021, -0.0068763494, -0.0036097062, 0.00018844288, -0.002438345, 5.3001568e-05, -0.0012997041, 0.0028651692, 0.005757057, -0.0047934377]\n",
      "\n",
      "Var Changes Bias\n",
      "--------------------------------------\n",
      "[1.6961736e-06, 7.778479e-05, 0.00054955226, -0.00021782506, -7.9500955e-05, 0.00027380267, 0.0004651834, 3.865687e-06, 0.0018102878, -0.0020018485, 0.0024826503, 0.00089425733, -0.0035367757, 0.00040590635, -0.00015202479, 0.0021506953, -0.0008025225, 0.004739955, 0.0049725575, -0.0052326876, -0.005177333, 0.001525534, -0.00073136063, 0.0019865637, -3.9555132e-05, 0.008521856, 0.0009088572, 0.015562123, -0.02481478, 0.010390223, 0.017104497, -0.0019270908, 0.009766148, 0.023246873, -0.05484554, -0.0022089132, 0.0045219935, 0.0066699944, -0.012381308, -0.0025204835, -0.0006663422, -0.00025511067, 0.0008784025, -0.0011688073, 0.00028992712, -0.0010990563, 0.0028959343, 0.0037279045, -0.0050081257]\n",
      "[6.607319e-07, 0.00016278186, 0.0014775669, -0.00014633965, -7.520977e-05, 0.00041291758, 0.00036021846, -0.0005641327, 0.0011617678, -0.0018346449, 0.0010767404, 0.0014617029, -0.0027059296, -0.00022023817, -0.00026568386, 0.00036010426, -0.000106593594, 0.0010937173, 0.0019910831, -0.00082064373, -0.0021532604, 0.00040565815, -0.00016486726, 0.0005403913, 9.0132e-05, 0.0029345537, 0.0013871994, 0.008472447, -0.011571031, 0.004452117, 0.011332696, 0.0023059156, 0.010404404, 0.021994956, -0.045876984, -0.0027346746, 0.0021868544, 0.0057910723, -0.008597218, -0.0024870464, -0.00072684616, -0.00031486352, 0.00016070361, -0.00036320873, 4.8302463e-06, -0.00022682821, 0.000634638, 0.0012779876, -0.0013835714]\n",
      "[1.3449055e-06, 9.854925e-05, 0.0011543231, -9.010127e-05, -4.1432795e-05, 0.00025341217, 0.0004899383, -0.00016107643, 0.0018639702, -0.0022066953, 0.0018770243, 0.0025482948, -0.004485103, -0.00020014239, -0.00049146195, 0.00076331303, -0.00018353632, 0.0019960112, 0.0041196113, -0.001795826, -0.004214963, 0.00051097956, -0.00042618206, 0.0006274356, 9.554811e-05, 0.0038786072, 0.0022120685, 0.011699219, -0.01618453, 0.006371187, 0.015849762, 0.0031795911, 0.013331518, 0.02883209, -0.061597865, -0.00340229, 0.0036725448, 0.00799321, -0.012316202, -0.003359851, -0.0010939096, -0.0005388894, 8.4002444e-05, -0.000432223, 3.1294097e-05, -0.00024182982, 0.00070109824, 0.0019347444, -0.0014846862]\n",
      "[3.6156698e-06, 0.00010408026, 0.0015038684, -0.0004070088, -0.00017463125, 0.00020402856, 0.0002904178, -0.00031828054, 0.00097271975, -0.0013809024, 0.00121396, 0.0013724754, -0.0026129226, -6.144837e-05, -0.00029937632, 0.0006903403, -0.0001885171, 0.0015355768, 0.003106992, -0.0013377052, -0.0032527477, 0.00034081104, -0.00034852675, 0.00043289678, 1.6652863e-05, 0.002427481, 0.0016449268, 0.008035859, -0.010955401, 0.00402067, 0.011603905, 0.0023648888, 0.009205988, 0.020369383, -0.043281585, -0.0024671974, 0.002398258, 0.005864039, -0.008620738, -0.002425305, -0.00086976663, -0.000351894, 8.541526e-05, -0.00027628493, 6.330242e-05, -0.00018412434, 0.0008530869, 0.0024085662, -0.0015777545]\n",
      "[1.9844056e-05, 0.0003242513, 0.0021903487, -0.0006200203, -0.00039002404, 0.00018834847, 0.00033335784, -0.000461029, 0.0011544478, -0.0016925866, 0.0012288913, 0.0018534956, -0.003102265, -0.00022089505, -0.00031982706, 0.00082875224, -0.00014063029, 0.0019696485, 0.004730477, -0.0014698701, -0.004881706, 0.00023913046, -0.00042241195, 0.0006880583, 0.00014660018, 0.0039503477, 0.0036216346, 0.015755972, -0.02070066, 0.0072338223, 0.02311822, 0.0055527054, 0.029339943, 0.08136213, -0.12602681, -0.009033589, 0.008453194, 0.023689711, -0.0331038, -0.009518274, -0.003415135, -0.0014182148, -7.077778e-05, -0.00061720936, 1.5224097e-05, -0.00028143404, 0.0008696877, 0.0032730876, -0.001608843]\n",
      "\n",
      "Now Check the graph\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAADCCAYAAADNYZB9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzNElEQVR4nO3dd3xc1Znw8d9zp0ka9S65yQ2DaQYbTDG9GRJaNiSQkJC2LLvUtA1pm5B9s+ElCekJMQkpbxJYOgZMcQg92NjG3ZYsWW6ymlVGbTT1nvePGcljW7ZHtuQZ2c/389FnZm6bc4z0cM4995xHjDEopZRKjpXqAiil1FiiQVMppYZBg6ZSSg2DBk2llBoGDZpKKTUMGjSVUmoYnKkuwHAUFxebqqqqVBdDKXWUWbFiRZsxpiSZY8dU0KyqqmL58uWpLoZS6igjItuSPVa750opNQwaNJVSahg0aCql1DAkFTRFZL6I1IhInYjcO8T+40XkPREJishX9tq3VUTWisgqEVmesL1QRBaLSG38teDwq6OUUqProEFTRBzAr4ArgZnATSIyc6/DOoC7gB/t5zIXGWNmGWPmJGy7F3jNGDMdeC3+WSk1hO62flb/Y0eqi6FIrqV5JlBnjKk3xoSAx4BrEw8wxrQaY5YB4WF897XAn+Lv/wRcN4xzlTqmbHq/mXceryXUH0l1UY55yQTNcUDi/+Ia4tuSZYBXRWSFiNyasL3MGNMEEH8tHcY1lTqmBPpiwTIciqa4JCqZ5zRliG3DWYTzXGNMo4iUAotFpNoY81ayJ8cD7a0AEydOHMbXKnX0CPpjnbhwUINmqiXT0mwAJiR8Hg80JvsFxpjG+Gsr8Ayx7j5Ai4hUAMRfW/dz/gJjzBxjzJySkqQe2FfqqBP0x1qaEW1pplwyQXMZMF1EJouIG7gRWJjMxUXEKyI5A++By4F18d0LgVvi728BnhtOwZU6lgwEzXDQTnFJ1EG758aYiIjcAbwCOIBHjDHrReS2+P6HRKQcWA7kAraI3ENspL0YeEZEBr7rb8aYl+OXvh94XEQ+D2wHbhjRmil1FBnonke0e55ySc09N8YsAhbtte2hhPfNxLrte+sGTt3PNduBS5IuqVLHsMGWpnbPU05nBCk1BgQGu+caNFNNg6ZSaS4atQe75ToQlHoaNJVKc8G+3Q+0a0sz9TRoKpXmBgaBQFua6UCDplJpbmAQCPSRo3SgQVOpNLdH0NSWZspp0FQqze3RPdd7mimnQVOpNDfQ0vRkObWlmQY0aCqV5gZamt58j7Y004AGTaXSXMAfwem2tKWZJjRoKpXmgv4IniwXTrdDR8/TgAZNpdJcsC+MJ8uJy+3Q5zTTgAZNpdJcrKXpxOmxdEZQGtCgqVSaG+iea0szPWjQVCrNBf1hMrKcOD0ObWmmgVHNey4iE0TkdRHZKCLrReTuhH3fFZGd8Xzoq0TkqpGpklJHlz1bmjbGHk6KLjXSDroIcULe88uI5QtaJiILjTEbEg4byHt+3V6nR4AvG2M+iKe9WCEiixPO/YkxZn+50pU65kWjNuFgFI/XicMZa+NEwjYujyPFJTt2jWrec2NMkzHmg/j7HmAjw0v/q9QxLZQwG8jpjgVK7aKn1pHIew6AiFQBpwFLEzbfISJrROQRESkY7jWVOtrtnkLpwuWJtzR1MCilkgmah5v3HBHJBp4C7jHGdMc3/waYCswCmoAf7+fcW0VkuYgs37Vr13C+VqkxLxCfQrlHS1ODZkqNet5zEXERC5h/NcY8PbDdGNNijIkaY2zgYXbnQ9+D5j1Xx7I9W5qxoBnRWUEpNdp5zwX4PbDRGPPgXvsqEj5ez+586EqpuGBCS9OlLc20MNp5z08BPgWsFZFV8Ut+I54S+AERmUWsq78V+LcRrJdSR4XEgaCBASBd6Si1Rjvv+TsMfU8UY8ynki+mUsemgdS9GVmuwQRr2tJMLZ0RpFQaC/ojOF0WDpeFMz56ro8cpZYGTaXSWNAfW+EI2D0QpC3NlNKgqVQaC/ojeLwugN0DQdrSTCkNmkqlscSWpsNlgUAkpI8cpZIGTaXS2MBiHQAigsutKx2lmgZNpdJYsC8y2NIEYsvD6T3NlNKgqVQaS+yeA7jclj6nmWIaNJVKU7ZtCAWig91ziI2ga/c8tTRoKpWmEmcDDXBqyouU06CpVJoaWOEoI7F77tE0vqmmQVOpNJW4wtEAp1sHglJNg6ZSaSpxhaMBLo9DB4JSTIOmUmlq6JampS3NFNOgqVSaGgya3sRHjrSlmWoaNJVKU0N1z2MPt9sYo2l8U0WDplJpKtgXiS0J59qdrtfldmBsgx3RoJkqSQVNEZkvIjUiUici9w6x/3gReU9EgiLylWTOFZFCEVksIrXxV81GqVSCvWcDwe7l4fS+ZuocNGiKiAP4FXAlsRQWN4nIzL0O6wDuAn40jHPvBV4zxkwHXot/VkrFJS7WMcDp1oWIUy2ZluaZQJ0xpt4YEwIeA65NPMAY02qMWQaEh3HutcCf4u//BFx3aFVQ6ugU8Ef2eLAddCHidJBM0BwH7Ej43BDflowDnVtmjGkCiL+WDnUBzXuujlVDdc+duhBxyiUTNIdKjJbsXejDOTd2sOY9V8eoobrn2tJMvWSCZgMwIeHzeKAxyesf6NyWgdzn8dfWJK+p1DEhFjT3MxCk889TJpmguQyYLiKTRcQN3AgsTPL6Bzp3IXBL/P0twHPJF1upo5ttG0L9+wbNge65tjRT56B5z40xERG5A3gFcACPGGPWi8ht8f0PiUg5sBzIBWwRuQeYaYzpHurc+KXvBx4Xkc8D24EbRrhuSo1Zof59p1ACuAbS+GrQTJmDBk0AY8wiYNFe2x5KeN9MrOud1Lnx7e3AJcMprFLHisHZQN79tDR1IChldEaQUmloqMU6QO9ppgMNmkqloWBfPGhm7ueRI+2ep4wGTaXSUGCIxToALEtwuDS5Wipp0FQqDe2vew6xRTu0pZk6GjSVSkP7GwgCcHq0pZlKGjSVSkNBfwTLKThd+/6JaksztTRoKpWGBqZQiuw7E1kzUqaWBk2l0lDQH95nhaMBmvs8tTRoKpWGhpp3PiDW0tSgmSoaNJVKQ0OtcDRAW5qppUFTqTQ01FqaA1weS1uaKaRBU6k0dKCWpo6ep5YGTaXSjLENwSGWhRvgdDuI6Oh5ymjQVCrNBPsjYPadQjnA6XEQjdjYtqbxTQUNmkqlmQNNoYRY9xx0ebhUGam85yIiP4/vXyMip8e3zxCRVQk/3fEFihGR74rIzoR9V41ozZQao4L7WaxjgC5EnFoHXYQ4IXf5ZcRy/iwTkYXGmA0Jh10JTI//zAV+A8w1xtQAsxKusxN4JuG8nxhj9siVrtSxbqClmTHEvHOIdc9BM1KmyojkPY9//rOJWQLkDyRNS3AJsNkYs+2wS63UUSzp7rm2NFNipPKeJ3PMjcCje227I96df0RECpIoi1JHvYN1z526entKjVTe8wMeE89EeQ3wRML+3wBTiXXfm4AfD/nlIreKyHIRWb5r164kiqvU2KYDQeltpPKeH+yYK4EPjDEtAxuMMS3GmKgxxgYeJnYbYB/GmAXGmDnGmDklJSVJFFepsS3oD2M5BKd76D/PwTxB2j1PiZHKe74Q+HR8FP0soMsY05Sw/yb26prvdc/zemDdsEuv1FEoEF+sI3FZONvY+MN+gMFgqgNBqXHQoGmMiQADucs3Ao8P5D0fyH1OLEVvPVBHrNX4HwPni0gWsZH3p/e69AMislZE1gAXAV883MoodTQIDTGF8pnaZ7jsycsIRoODLU0dCEqNkcp7boDb93OuHygaYvunhlVSpY4Rgb59F+tY1rKM7lA37f3tFLpjt6m0pZkaOiNIqTTja/GTV5K5x7aajhoA2vvbtaWZYho0lUojgb4wvZ1BisZn794WCbClawsAHYEOHE4LyxJ95ChFNGgqlUbaGnoBKE4Impt9m4maWKuyPdAOxJ7V1JZmamjQVCqNtO3oAaB4fM7gtuqO6sH3HYEOAFxuSx85SpGkBoKUUkdGe0MvmblusnLdg9uqO6rxurzYxqa9P6GlqQNBKaEtTaXSSNvO3j265gA1nTXMKJhBgadosHvu8jgIh/SeZipo0FQqTUSjNh1NfRSP2x00bWPHRs5DlTS2O2jzD3TPNSNlqmjQVCpN+Jr92BGzx8h5Q08D/oifzs4SwmEvrf42QAeCUkmDplJpYqiR84FBoG3NeZhINp0BbWmmmgZNpdJEW0MvDqdFfnnW4LaazhoscdDVVYSJZtMT7iJqR3F6LG1ppogGTaXSRHtDD4WVXhyO3X+WNR01FLnHg3FhIl4MNr6gT1uaKaRBU6k00dbQu8f9TIh1z52R8RR63Vh27NnNjkAHTh09TxkNmkqlgb6uIP094T1GzjsDnbT4W/D5Spg9qYA8dyy5QXugHZc7NhAUWytHHUkaNJVKA+1DDALVdMYX6ego5oyqAooyiwHo6O+IralpIBLW1uaRpkFTqTQwMHKe2D0fWNnIDlYwe1Ih5d5Y0GwPJKx0pPc1jzgNmkqlgbaGXrILPGR4dy8+XN1RTaZVhFtyOCkvwOX2SjBW7J6mW9P4pkpSQVNE5otIjYjUici9Q+wXEfl5fP8aETk9Yd/W+Artq0RkecL2QhFZLCK18VfNRqmOWW0N+06frO6oRkKVnDo+H8/SX3LTtu9CJItWf5vmCUqhgwZNEXEAvyKWHG0mcJOIzNzrsCuB6fGfW4llmkx0kTFmljFmTsK2e4HXjDHTgdfin5U65kTCUXwt/j265sFokC1dW+jylTCnqgC2vQuAK+qhubctISOl3tM80pJpaZ4J1Blj6o0xIeAx4Nq9jrkW+LOJWQLk75U4bSjXAn+Kv/8TcF3yxVbq6NHR2IexzR7LwdX56oiaKJFABXPHuYhuW0Nvk4esqJM2f/vu3Ofa0jzikgma44AdCZ8b4tuSPcYAr4rIChG5NeGYsoGMlfHX0qG+XPOeq6PdUNMnBwaBooFKZksN7Ruy2PFmIWV9Np3BDs19nkLJBE0ZYtveD4cd6JhzjTGnE+vC3y4i5w+jfJr3XB312ht6cXoc5CbkBarpqMEyHqYVTiC7+X36mjMAYbIvRE+4c3ca38Noafpa/Cz82UqC/vDhVuGYkkzQbAAmJHweDzQme4wxZuC1FXiGWHcfoGWgCx9/bR1u4ZU6GrQ19FJU6cWydrc9qjuqsYMVzJlUTGTDWwQ6Y6PqVV0BIiZE2BECDm/0vG5FKzs2dtK8pfvwKnCMSSZoLgOmi8hkEXEDNwIL9zpmIfDp+Cj6WUCXMaZJRLwikgMgIl7gcmBdwjm3xN/fAjx3mHVRaswxxtC+18LDtrHZ2F5NyF/BWeM9+NfsTncxsScIQK/dBRxeRsrm+tg1Opv6Dvkax6KDprswxkRE5A7gFcABPGKMWS8it8X3P0QsJ/pVQB3gBz4bP70MeEZEBr7rb8aYl+P77gceF5HPA9uBG0asVkqNEb2dQYL+yB5Bc2fvTvqjfuxgBWe56ulrcmJlZUAkTGlPEPDQZfuAQ29pGtsMBs0ODZrDklSOIGPMImKBMXHbQwnvDXD7EOfVA6fu55rtwCXDKaxSR5vdM4F2j5wPDALlWZMo7VjG5hYPWWeeSbh2LbndzYCHzmgHiBA5xEU7Opv9BP2R2HsNmsOiM4KUSqH2hlj2yaJx3sFt1R3VYCxmV55AeM1bhHudeOedj6usGGdv7E+2MxibFXSoLc2BVub44wvobPbrwh/DoEFTqRRqa+gltyQTd8buTt8HLWuJhoo5e0IBfati9zO955yNa/x4TJ8DjGFXX9thpfFt2uwjI9vF5FOLCfoj+LtDI1KfY4EGTaVSqG3HnoNAu/y7WNGylGjvDM7L2oq/yYGzMBf35Mm4Jk3BDlvk+Z009sSmUh7qc5rN9d2UT8mjoCLWwtX7msnToKlUitSv3EXXrn5KJ+2+n/lM3TPYRLF6z2ZS90r6Wtx4zzkXEcE15QQAxndYNPftOuTueX9vCF+Ln4qpeRTGg6be10yeBk2lUmDrmjZe+d06yqfkcvKF4wGI2lGeqHkCKzCdM8fPILLidaJBB97zLgDANaEKgIk+Q1t/bHm4Q3nkqLk+9lxm+ZQ8snLdeLKcdDb5R6ZixwANmkodYds3tPPSgrUUj8/mw3fOGryf+W7juzT7m+lrO4O7L5xE36rYKHrWWWcD4BpXCcB4XwRfsBOn23FIo+fNm31YDqF0Ug4iQkG5V7vnw6BBU6kjqKGmk0W/WUtBuZer75qFJ3P3ANBf1j+GiWRz6aSLOd25lb5GC/eEUlxlsWUZHPn5iNuisitCb7gTl8dxSANBTZu7KJmYM7gmZ0FFFp3NGjSTpUFTqSOksc7Hi79aTV5JJtfePWuPBYeb+5p5r/kdol1ncO/8k7Dr3sS/y433nN1LNYgI7qJsSnqiBE0vDrcM+55mNGLTuq2H8il5g9sKK7z094Tp79UR9GRo0FTqCPC1+nnhl6vJLsjgmrtnkZnj3mP/gpWPYgxcPeV6qoq99P/zNUzUwnvBRXsc5yotJCc+Vdx2RIY9er5rRw/RsL1H0CwYHAzS+5rJ0KCp1BFQv3IX4UCUq+88FW+eZ499YTvMs3VPIf0z+Ppl50I0Qt/qWrCErDPO2ONY17hKPL2xhT3CVmjYaXybN8ceaq+YumdLE/Sxo2Rp0FTqCGja3EV+WRa5xZn77Fuw7AXC0sWHqj5CgdcNzavxNwqZ08bjyMnZ41jXxMlYIYusgCFkBYbd0myu7yKnKANv/u7AnV3gwelx6GNHSdKgqdQoM7ahsc7HViL8Zck2Ovt23zu0bcMf1z6GRPP41sUfASC64R/0d7jwnnfRPtdyTTkegJIuCIgf2zZEI8m1No0xNG3u2qNrDrF7pYXlOhiUrKQW7FBKHbrOFj8hf4T3TIiHn13Hfc+v54LjSrnutEq2d+8g4NrAxWU3k+2Jtf78b74MRsi6YN/1bAaCZmmXobusF/AQDkZxOA/e/ulpD+DvCu3RNR9QUOGlobrz8Cp6jNCgqVSSAuEoGS7HsM9rqvMBUFSVw4s3nMSzK3eycHUjf9/YgrvkJTxFFvfOiy8tu2MZfas3Ie58MmfN2udarnGxLDJlndAZ7qKAotgD7gkj8fszsEhH+RBBs7DCS82SZoL9kT0eg1L70u65Ukmo39XLKfe9yju1bcM+t25DO31iOO/0Ck6szOObH5rJP++9hG9+1EFOyQrmlJ5LRXY5AJEX76NrmxfvufOw3O59ruXIz0dcwjifwReNBcFkHztq3tyFy+OgqNK7z76C8ixAp1MmY1TznovIBBF5XUQ2ish6Ebk74ZzvisjOeD70VSJy1chVS6mR9ezKnYQiNm/VDj+5X0Otj0anzRUnxgJjQ08DX37zi/x8/Vcpyy7g62ffEztwy9vsen4NdtRB6Ve+MuS1RARnQRYVXYauqA8g6VlBTfVdlE3OxXLs+2c/+NiR3tc8qIO2wxPynl9GLBfQMhFZaIzZkHBYYt7zucTyns8FIsCXjTEfxNNerBCRxQnn/sQY86ORq45SI88Yw8LVsbRYq7b7hnVuX1cQeiOES10U5wq/WvUr/rDuD1hicddpd/HpEz+Nx+EBY+h/9Nv4Nnsp/NRNeKZO3e81XaX5lDT30m1i9yCTaWmGAhHaG3qZfVXVkPtzizNxOC069FnNg0rm5sVg3nMAERnIe54YNAfzngNLRCRfRCriqXkH0vT2iMhGYql9N6DUGLF2Zxdb2/3MdHtY2+AjHLVxDdFaG0rNuljLdPzxDq579joa+xq5supKvjTnS5R7ywePM5tepWXRDhy5+RTfdff+LgeAp7KCvE0N+E07kFxGypat3RgDFVP2vZ8JYFlCfnmWds+TcCTyngMgIlXAacDShM13xLvzj4hIQbKFVupIWriqkYm2xYdaLab4hZrmnqTP/WBFC2EM/or3aPG38MgVj/DABQ/sETCxbbp/8y3629yUfuU/93k2c2+uiZNwh4RQJHZ/tX1n70HL0VTrA4Gy/QRNQB87StKRyHuOiGQDTwH3GGMG8oX+BpgKzCLWGv3xkF8ucquILBeR5bt2Df9+klKHw7YNL6xp4uLM2ELBVWGLlTt8SZ/fvq2HzgxhWcc/OKviLM4oP2OfY6IfPEHrG11kTKkk76MHzy/oqjou9hpsomJGLisWbT3gyuv9PSHWvrGTcdPzDzgyXlDhpbs9cFhpgY8Fo573XERcxALmX40xTw8cYIxpMcZEjTE28DC786HvwRizwBgzxxgzp6SkJIniKjVylm3toKUrQFlXbLClKupg5baOpM5t7wqQ1RfFVRliZ+9Orqi6Yt+D7CjtD/4PkYCD8u//ELEO/ifpmnYiACXdhulX5xAJ27z3TN1+j3/niVpCgQjn3zjjgNctrPCCAV+L3tc8kNHOey7A74GNxpgHE08QkYqEj9ezOx+6Umlj4epGpuHEDkSZeGIRWbawebMvqXP//vZ2LITguDqclpOLJ168zzGhVx+iY1WQvAtPJ/O005O6rmvSFCA2KyiY3cOsSydQ/V7z4HOYibata2fT+y3Mnj+JwiEeNUqkqS+Sc9CgaYyJAAN5zzcCjw/kPR/IfU4svW89sbznDwP/Ed9+LvAp4OIhHi16QETWisga4CLgiyNWK6VGQDhqs2htExdmenF5HJz70WkAWLuC+PwHX0Ztw9o2DIbl1svMq5xHnifhfmI0QnTpozT/8JeI06Lkvgf3f6G9OPLzMc7YrKAd3a3MvrKK7AIPbz5ag23vvnMWCkR48281FJRnMXt+1UGvm1eaiWWJDgYdxGjnPX+Hoe93Yoz51LBKqtQR9k5dG119YQoDEcadnMfX1t7D7NxPMMnvYNUOHxfOKN3vuYFwlGCjn0C2TUNoG7dPjrcv+toJLvopnY8+ia/GxkQtym6/GVdZWdLlEhHIc1PSFWa7rxX3cU7O+ZdpvPq79ax/a+dg+oz3F26hpyPAR75yOg7XwTuVDodFXmmmtjQPQmcEKbUfz69qZKa4sIM2m4tXsqRpCX2lzUyIWqzaduB52u/W7qIsLPSXtOBxeLioZDZ9P/4E268+k/pvP4mvRsi9cC6Tn36Swju/MeyyOQtzKfEZGntig6PTZpcybkYBSxfW098TomVLN2te38FJ54+jYlp+0tctrPDS2az3NA9Eg6ZSQwiEo7y6oYXzMrJwZzl4vO8PAKx2/5MMI2yqPvBg0OtLGnEjbMpcynnjziP6m2+x/eGVBLqzKf7sjUx78y0qf/VnMmaeeEjlc1eUUdoFbT2xMVkR4fyPH0c4EOWfT9Xx+l+qycp1c9b1+39I/v2m97lh4U009zUPbiuo8NLV6icaHn7uoWOFBk2lhvB6dSuBQITcjgimqpuuiI+bT7iZ6swVAPTu6CV2V2pfUduwtSYWVOsy1nBF5Tzannkbd0kG0959n5KvfQdncfFhlS9z4kS8QQh1NAxuK6z0csrF46le0kz7zl7Ov2nGfh8x6gn1cMff/5PqznX8aMnvB7cXVGRhTGyleTU0DZpKDWHh6kZOdbqxQzZveBYyu2w2d552J3ZmCH92D2X9sKVt6Ht/K7Z1UuC3CWX0E/UGOGPx6wQ7HRR97rNYHs+Q5wxX5tTYs5ruttY9tp/x4cnkFmcw/Ywypsza/yN6t7/0XfzRDqL94/h7w0L84ViQ1FXcD06DplJ76QmEea26lXNcWVhZhnWe9/nczM+Q1bCC8yrPpSFvA+MiFh/UD91Ff37VTsZHLJpya7mwch69Ty7Gmesk75O3DXn8oXBNOwkAr2/P2UDuDCc3fWcul31u5n7P/ePKRaz0vUpJdD5XVv47Ufz8cc0TAOSXZeH0OKhb0brf8491GjTVMa+jL8SS+nb+33tb+daza/nk75ZiwjZZbSG2F69lasEUztlRTfvXP878XX1szl6DC2HDun1nqDX6+lm0tIFsY7HdW8OHN/fib7YovPGjyBBLvR0q19RYUMzuCu6zz+lyxEbYh1DX3sKDK7+PFa7g0Rv+i69ecDl2/wT+34a/Yhsbp8vB6ZdPpH7lLnZu0kWJh6JBUx0xwUiUQDh9pugZY7jr0ZWc/t+LuXHBEr793HqeW9WIy2Fx54xx2BHD8pzX+cyU62j/8Q9pXZXHzEffor1gBwZD55Z956D/4h+1VEZiAauroIlJT76N5bHIv3Xopd4OlaOggIgTCrptgtF9A+dQgpEon372G9hWL9+f933y172FfcfVzJN59NpNvLrlDQBmXTaR7AIP7z5Zh7GHvm97LNOgqY6IHR1+5v/0bS598E22t6fHIMMLa5pYuLqRT86dyJ8/dyZLvn4Ja75zOU/9+zlMC1qEMvzYZb1ctOgpOja4sLwZ9G6yuMTOoy17J1m+MP0JKwxtbevj8WUNXOTJIuTo5wIR/FsNBddehiP7wLNxhktECOZalHRBR//Bp3UaY/i3p/5Ij/N9Lq34BJcHA2y//Ut0LdvJf/7jFexwLr9Y/ggALreDs6+fyq7tPVQvaT7IlY89GjTVqNvU0sNHH/on7b1BeoMRPr7gPep3HXxlntHU5Q9z3/PrOWV8Ht+79iTOP66E8ryMWDDyh9m6ro2NBUv5TM4sWp/YiKsoh6rHHgeEq1/ewo68DZRHLFZv2R2wfvZaLWeGnHjaIyyd+AKXv1yLOITCu741KnUI52dSEp8VdCDGGH76+kqW9T5MoXMyP5hyOdu/cCvYkHtqMaHVrXxoyzi296+mpn0TANPPKKNsci5LnttMKBAZlfKPVRo01ahasa2TGx56D2Pg8dvO5m9fOItQxObjC5ZQ25L8Emsj7QcvbaTTH+Z/rj8Zh7X7/l80bLPkuXpMFJrKqrnw9y8S7nVS8aOf4Zk+nfxL5pK7zqbPvRkLYdUHsZbYppYeli5v4ly/k7aKenpylpG5MULepXMP+/Gi/SrMo7QL/l7/GrYZ+rnKcNTmzqde4uHae3E4Azw0+0s0feZmIv2GCQ9+j4oFz+LKgc//fR2OkJMfLvkdEGvJzrthOv6uECtf3T465R+jNGiqUfPmpl3c/Lul5Ge5ePK2czi+PJfjy3N47NazAPj4giVsaOw+yFVG3pL6dh5btoMvzJvMSeN2zwdv3dbN4z9Yxro3d7K+7B3+xddJ7zqh4PrL8Z59DgBFX/0eGOH6NXVEJExLrQ+An71YzTV9bsJZfTw/fgHf/WcYjFD0pe+OWj3yKqvIDsCz6x/hsy9/lnpf/R772/v6ueqP9/FGzzfIyuzjZ3PuI/M/7iLUGWXC975I5iUfw8orovzLt2F3Gf7tbRfv71pMRyDWei6fksf0OaWsXLydno7AqNVjrNGgqUbF86sb+cKfllFV7OWJ286myOHgD997g4fu/gfr/reGB06ZTImxuGnBEtY0+I5YuQLhKN94Zi0TCjO5+9LpAEQjNu89V8cT9y+npaONRcf/lg2TnufsJ7fhKvZS+u0fDJ7vnjiRvPNP4aRV/bRl1WO19bJmhw/XBz68xvD8lIe4q/w8clcFyD1rJu5JVaNWl/xpsaXeztw8g9Ut1Xxk4b/wiw9+RSga4p2tG7n00Y/T7Hyamfln8crVjzH1q9+jvzFE5VduwfuRfxu8TvaNd5N7chEXLu+mvCPMb1b8ZXDfwIyi957ZPGr1GEnhqM2KJJfuO1QaNI9Sxpj9zlgZbb97u567HlvJaRMKeOzWszBdAR7579fxNfvZkL+UjfWb2fDiNq5pFD65y+LXP17G+4eQsOxQ/PqNzdTv6uP/XHcyWW4nm+saeOg7r/DBS9upLl7KS2f8kqvOP5dHXgpi9zqp/OFPsLKy9rhG8de+j2ULRZ01FIY8/PG3q5gecfDepGc5b1Ipl/32WeyIRdGX/mtU61I453wAvrpkJT9Z7iCjcxIL1j7E+X+7in9//ZNEHM3cVnU3D291033tfPrq/ZT/69Xkfu7r+1yr7IEFWA744iKbZ2r/l3A0DEBuUSazLp1A7bIWmrfsu/RcOqlt6eH6X7/LTQ8vpblr9FrGGjSPMuFomKdrn+aaZ6/hhudvYGfvziP23VHbcN/z6/k/L27kipnl/PnzZ7K9ZjuP3b+EQLCfSfZT/MfO9ZyU/zKbpv6at6seozVvLSf2C8//fAVvrRndkdralh5+80Yd182q5PzpxTz55D948ccb6OsOsPmMV7nmfB9PNmfy0R/8guDaMIXXXkjW2eftcx33lGnknTWDORurAZjaZrO1YB3FhRv5zP99E98mNwU3XEvGyaeOan08p82l9Et3E+zPo/zvnTz62Fr+Z5mXsL+fcb1lPP1BHpd/8QEaf7uYaMii8u4bKfjyD4e8lnPyTEpvvpyqBsNZa318/70HCERigef0KyaRlevm5d+uY+ua4acwHm22bfj9O1v40C/eodEX4Oc3zqI8L2PUvk9S1Ro5FHPmzDHLly9PdTHSkj/s54maJ/nD+j/S0d/O8f5z6aWN3sJmfnLRT5hdNntUvz8QjnLPY6t4eX0znzt3Mt/80Am89Oo7bHmuH9vsYt7Kh8nyd+AeN47Q1q2xk7IyaJtWwpslZeTYN9PjsDnjlpO54ozxh1yOnkCYl9Y18+amXUSjBsuKDWpYIqzf2UWHP8RTn5/Nwj++jntHIR0FG7nO/wjFtbvoacwgGnCABdmzZzJuwV+wMjOH/J5gzTpqr/sYb5z/AL2eAG35D/Kvz7VjbCfl3/kO+R/92CHXYbjsYJCuJx+jY8GvCbV048yKYIcs7IhF1tRCCj/3BbKv+zTicBzwOiYSYctlp9PVGeLOf3ViFVTy3+f9FxdMmEfrtm5e+9NGOhr7mHp6Ked9fDrevJGZEno4dvr6+crjq3mvvp1Lji/la2dPobOmi7nXTBnWdURkhTFmTlLHatBML8FokLcb3uaFuhdp87fzL8dfz/zJ88l0Dv3H+2b9Bn7+/mPU+RdT2lfKzJ3zmNZ5PJbEngtsytnIW9Of4YsX3c71068/5HIZY1i1w0dtay9VRV4mF3spznYjInT0hfjCn5axcoePb151AlfNzOKpJ1/HWllGdu8mTlu1gIKTKyk7vRe3u5OIpwp/Zy7+hjD+ulaC25rYNn4GNdO/QMCymHHD8Vx34Z6/9K3dAd6payNiGyYVZjGpyEtpjgfLEqK24Z26Np7+oIFX1jcTCNtU5mWQk+HCNgbbGIwBEfjEdCe+1zpwhTIoCjzN7BWvY0IWVqab7HPmkj3/arLPPx9H3v4TkA3YdvMVbK13sWpqN5cv24WnsoBxC/6MZ9q0Q/53PhzGtul9+QU6H/klzvxcCu64l8xZScWBQYElL7P1c/cQteD1k108fZahYNwFPHjptxmfXcrKV7ezfNFWHC6Lcz4ylZnnViLW0LOPRlPUNjyxfAfff3EjtjF864rjGb8jwNo3d+IixE3/cxHZBcm3Nkc8aIrIfOBngAP4nTHm/r32S3z/VYAf+Iwx5oMDnSsihcD/AlXAVuBjxpgDzts6UkGzpyPAhnca2bq2jQyvi+wCD9kFGeQUZpBd4CEzx01GtosMrwun29p3ylokhN3bTqSrnaDPR6inG39XDx3dXfj8flxZHrILcskuKSWnrJLMonEsq32TN5f/k6YGm4rOCRT2T8LCRYu3mtryDZx4WhWfmHMTU/On0tTbxO9WPstrG9+grN3JjJaplPtnYax8rGiI4vZ1lLUtpy+jjG2TriBqOakufoMJVxbx5XPuwWEduMWRqKs/zHOrdvK3pdup3isLY47HyeQSL+29Idp7e/n8CRFkg4+M9vEITsqbl3Jyx1NUnriT7DI/lJ4IJTOgvQ7aN0M4tihEX4uHprUVdPYXsez0Owg6Mym8chwzThrHm5t28WZ1KzVNPtwOP1GEUDQTxIHHaTGhMIvu/jCtPUHyMhxccZyHU4osMqMhwuEodsQmGrGJhg29HQHYUIAV3cXsVb8nt2cn2fPmUnDLF/DOPXPY0xyDa5ex+YZPIQj5l51J2Q9/i5Uxet3CIyXwz0W0/+L/0r2qBQMsPc7ihTM8hCd/mGm5MznRfTzOFSF6t/dRPDGHaaeXMH5GISWTcrDiAdQYQ2tPkNqWXmpbe6jf1UdepovTJuYza0I+RdmH1ko1xrB4Qws/fKWG2tZezpxUwD2TitmwaAvBsIPKpnfJ7nyec554Dm/53klz929Eg6aIOIBNwGXEEqgtA24yxmxIOOYq4E5iQXMu8DNjzNwDnSsiDwAdxpj7ReReoMAY87UDlWU0g6ZtG7avb2fN86vYsR0wkNuzGdtyEPQUEHbmgQx1CziCgz4gisGJMS4MbpDkA5MxQUTiv0TGxutvIbd7K2KitBWdRMiTDyZKv1WLL3c73p4CcsOTwRF7/s+Khij0VTMhuo6q44T8S68k47wPEanfwJYffJ913afRXH42xu6mtXI5nqJMok4HEaeTsAhhy4GVnYM3t4D8zALyM4rIdefzxqYG3tm4kUp/JyeYKOURD+6IC9syRMQQxiaIwYpa5AerECsbV6ib8pbllPctYWrlegpP9SKnfgxm3QTlJydWGrobob0Wtr6DWfEX2ld0s7VuMmtm3o4/s5iI9OPAhRgXkvDvaUwImz5sy0/E6gcBVzQPh12AyAGSERib8ualHLflCYovP4fC27+KZ/LkpP87DaXztw/gKCoj96O3HNZ10lF40wd0/vQ7tL9TCyGhqQAaioWdRdCa58a4L6QkcB754Vj27aBl055l0+l10dIfxh+JYMRgY+NxC10RoQuhxzKML8pi1oR8JhRm0heM0huM0BuI0BuMELFtji/P5eRxeZwyPo8pJdk4LGHZ1g7uf6maFds6OSnHxWdLw/St7KDHHkdOzzac3f/L+hO3cFyJnxv+dSlZuZVJ13Wkg+bZwHeNMVfEP38dwBjzg4Rjfgu8YYx5NP65BriQWCtyyHMHjoknYKuIn3/AdHnDCZpN2zaz+OePkJhtwyCxxMK2hR11YmxX7Me4iUQriDoKcYe6qWj6J66+d9lS5sMZheyAwdtv4Ynk4TIFINnYjizCLm/sx+nFWA4sO4wjGsayw9iEMYQxBIgSIixhAmITEgu3scjAiYsMLMnEWF7E+HFnBCk9YSLT551O1vEzEJeL3iVLqFn0Lq2tbtrzTsKfVY476COvt54SdyuVEywqzj2R7IuuxcrOHfLfIlS7hpX3/YhN0fPoztv/orSxf6QoVjSA2P0Yhxfbsfu2gBUN4g51Y8SBbTkxlhNbnAiGgo61lEXe5cTc1eSdMgH3CXPguPkw9RJwJJFVJRqB2lcJv/4wa5/fzA7rOqKWC4cdxBENISaIWEEMTiKSQ9SZTdjlJeTKBrHICLSTEWjHE2knw3SQZfXgkAgOojhMFIsoToH8s8+k4M7v4CwsTOK3SAHYbQ34fvlfdK9aR19rL/hsLHv331XAnU1LyQzaC2fQmzODiPsgD/MbG7F7ENMJpg9BAEESQpEhCCaIkTC2hLGsKFY4C4cpIeosI+KK/a47w34cgYXIce9xwcxTmTb5Yph4DhQfB0lk9hww0kHzo8B8Y8wX4p8/Bcw1xtyRcMwLwP3xnECIyGvA14gFzSHPFRGfMSY/4RqdxpiCIb7/VuBWgIkTJ87etm1bMvXi/VdeYNkzWQc8xoqGcEb6cUb6cQfbMdGlNBfvpG7aXGTCxYzPGU/ENgTCUfyhKP2hKP3hKOGojYmEIRRAwiGsSBAHFm5vDm5vFhneTLwZTrI9Loqz3RRluynyeijKdlPodeNy7PsfsyDLvcfMlKH0bK5n62v/YOpF88icNmO/K9nsT9PaldT/7VGsiI0TsGwwNoRtoT9o8IctghEXEdtNxGTgkH687g4Kc/qYUAqlE3JxFuRhgkFMMIgdiL2C4DltLtakM6DkBHAe5mo+vh2E3vorYGEVl+MorkCySyCrECwnRALYfT3YXR1EfZ0YGxyVU3COm45kjuwcb7UvEwwSqvmA4NplBLbU0etrw9/VSbCnl4g/QDCUgW25sB1OsJwYhwPjcBKxMwjZOYQlj4iVR9hZQMQ58De6Ow4ZEWzxYDs8RB0ZRB0eEAtHxI8r1IwlrViZHWQUBaiaU8kZF92MlT/xsOo0nKCZTGK1of4y9460+zsmmXMPyBizAFgAsZZmsuedMHceocDiwdINFkTA5fGQkevFnV2AO7OKjKxccvLyycm6czhFO+Jypk7h5KnDGxVMVHHyaVT84LQRLNEoyZ+A+5p7D3iIVQjWhCQzA6oRJR4PnlPOxnPK2eQC+08vd/iMbRPq6aSvs5Xcyik43akfsU/md64BmJDweTzQmOQx7gOc2yIiFQnd8xFd9TQnP595194wkpdUSh1hYll48orw5BWluiiDkun0LwOmi8hkEXEDNwIL9zpmIfBpiTkL6DLGNB3k3IXAwN3zW4DnDrMuSik16g7a0jTGRETkDuAVYo8NPWKMWS8it8X3P0QsJ/pVQB2xR44+e6Bz45e+H3hcRD4PbAe0WaiUSnv6cLtS6pg3nIEgnXuulFLDoEFTKaWGYUx1z0VkF5Dcg5q7FQPptzTLoTva6gNap7HiaK7TJGPM/hPFJxhTQfNQiMjyZO9VjAVHW31A6zRWaJ1itHuulFLDoEFTKaWG4VgImgtSXYARdrTVB7ROY4XWiWPgnqZSSo2kY6GlqZRSI+aoDZoiMl9EakSkLr7I8ZgjIo+ISKuIrEvYVigii0WkNv66z3J66UxEJojI6yKyUUTWi8jd8e1jtl4ikiEi74vI6nid7otvH7N1gtgC5CKyMr7049FQn60islZEVonI8vi2YdfpqAya8RXjfwVcCcwEbhKRmakt1SH5IzB/r233Aq8ZY6YDr8U/jyUR4MvGmBOAs4Db4/9txnK9gsDFxphTgVnA/PjCNWO5TgB3AxsTPo/1+gBcZIyZlfCY0fDrNJAf+2j6Ac4GXkn4/HXg66ku1yHWpQpYl/C5BqiIv68AalJdxsOs33PE0qEcFfUCsoAPiKV9GbN1IraM42vAxcAL8W1jtj7xMm8FivfaNuw6HZUtTWAcsCPhc0N829GgzMSW3SP+OpprwI4qEakCTgOWMsbrFe/KriK2LuxiY8xYr9NPgf8E7IRtY7k+EFsA/VURWRHPCAGHUKejdeHrw14xXo0uEckGngLuMcZ0Dzd1R7oxxkSBWSKSDzwjIieluEiHTEQ+DLQaY1aIyIUpLs5IOtcY0ygipcBiEak+lIscrS3NZFabH6ta4ivdMxor3h8JIuIiFjD/aox5Or55zNcLwBjjA94gdi96rNbpXOAaEdkKPAZcLCJ/YezWBwBjTGP8tRV4BjiTQ6jT0Ro0k1ltfqwa0yveS6xJ+XtgozHmwYRdY7ZeIlISb2EiIpnApUA1Y7ROxpivG2PGG2OqiP3t/MMYczNjtD4AIuIVkZyB98DlwDoOpU6pvjk7ijd9ryKWc30z8M1Ul+cQ6/Ao0ASEibWePw8UEbtBXxt/LUx1OYdZp3nEbpWsAVbFf64ay/UCTgFWxuu0Dviv+PYxW6eEul3I7oGgMVsfYAqwOv6zfiAmHEqddEaQUkoNw9HaPVdKqVGhQVMppYZBg6ZSSg2DBk2llBoGDZpKKTUMGjSVUmoYNGgqpdQwaNBUSqlh+P/XH6lItL5cOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_changes_L0_w, var_changes_L2_w, var_changes_L4_w, var_changes_L6_w, var_changes_L7_w = [], [], [], [], [] \n",
    "var_accumulate_L0_w, var_accumulate_L2_w, var_accumulate_L4_w, var_accumulate_L6_w, var_accumulate_L7_w = [], [], [], [], [] \n",
    "\n",
    "var_changes_L0_b, var_changes_L2_b, var_changes_L4_b, var_changes_L6_b, var_changes_L7_b = [], [], [], [], [] \n",
    "var_accumulate_L0_b, var_accumulate_L2_b, var_accumulate_L4_b, var_accumulate_L6_b, var_accumulate_L7_b = [], [], [], [], [] \n",
    "\n",
    "\n",
    "for global_epoch in range(G_epoch-2):\n",
    "    for layer_index in num_layers_list:\n",
    "        globals()['var_accumulate_L{}_w'.format(layer_index)].append(np.var(globals()['G{}_w_layer{}'.format(global_epoch, layer_index)][0]))\n",
    "        globals()['var_changes_L{}_w'.format(layer_index)].append(np.var(globals()['G{}_w_layer{}'.format(global_epoch+1, layer_index)][0]) - np.var(globals()['G{}_w_layer{}'.format(global_epoch, layer_index)][0]))\n",
    "        \n",
    "        globals()['var_accumulate_L{}_b'.format(layer_index)].append(np.var(globals()['G{}_w_layer{}'.format(global_epoch, layer_index)][1]))\n",
    "        globals()['var_changes_L{}_b'.format(layer_index)].append(np.var(globals()['G{}_w_layer{}'.format(global_epoch+1, layer_index)][1]) - np.var(globals()['G{}_w_layer{}'.format(global_epoch, layer_index)][1]))\n",
    "        \n",
    "\n",
    "print(\"Variance Accumulate Layer 0,2,4,6,7\\n--------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "print(\"\\nVar Accumulate Weight\\n--------------------------------------\")\n",
    "for j in num_layers_list:\n",
    "    print(globals()['var_accumulate_L{}_w'.format(j)])\n",
    "\n",
    "print(\"\\nVar Accumulate Bias\\n--------------------------------------\")\n",
    "for j in num_layers_list:\n",
    "    print(globals()['var_accumulate_L{}_b'.format(j)])\n",
    "\n",
    "print(\"\\n\\nVariance Change Layer 0,2,4,6,7\\n--------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "print(\"\\nVar Changes Weight\\n--------------------------------------\")\n",
    "for j in num_layers_list:\n",
    "    print(globals()['var_changes_L{}_w'.format(j)])\n",
    "\n",
    "print(\"\\nVar Changes Bias\\n--------------------------------------\")\n",
    "for j in num_layers_list:\n",
    "    print(globals()['var_changes_L{}_b'.format(j)])\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nNow Check the graph\\n\")\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "for j in num_layers_list:\n",
    "    plt.plot(globals()['var_accumulate_L{}_w'.format(j)])\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "for j in num_layers_list:\n",
    "    plt.plot(globals()['var_accumulate_L{}_b'.format(j)])\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "for j in num_layers_list:\n",
    "    plt.plot(globals()['var_changes_L{}_b'.format(j)])\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "for j in num_layers_list:\n",
    "    plt.plot(globals()['var_changes_L{}_b'.format(j)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1627963811737,
     "user": {
      "displayName": "이훈민",
      "photoUrl": "",
      "userId": "00157268181097362793"
     },
     "user_tz": 240
    },
    "id": "b2lKZ6AZlkSb",
    "outputId": "dbe4ee8b-aa53-4a7d-c4f4-06ebef21ec69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Layer 0,2,4,6,7\n",
      "--------------------------------------------------------------------------------------------------\n",
      "[0.0017341586, 0.046391018, 0.08156031, 0.038093135, 0.013723632, 0.019122515, 0.019166201, 0.017063389, 0.04447517, 0.05880895, 0.06710649, 0.03999655, 0.10018125, 0.020556152, 0.016670613, 0.05594929, 0.020190915, 0.07724048, 0.080368616, 0.048172016, 0.116388746, 0.032655798, 0.02045875, 0.03290626, 0.007199036, 0.100364774, 0.040155403, 0.1482449, 0.24969196, 0.11860403, 0.17628676, 0.034628354, 0.09433934, 0.16547394, 0.47238758, 0.058068916, 0.05868365, 0.09277166, 0.16594285, 0.07284447, 0.03645423, 0.023220215, 0.022880139, 0.033218708, 0.01679694, 0.040814254, 0.0996725, 0.07001998, 0.076586515]\n",
      "[0.0010613686, 0.016593056, 0.07262242, 0.021970225, 0.010313084, 0.013510823, 0.01042572, 0.016648121, 0.025381826, 0.041533303, 0.03783746, 0.024676014, 0.061677728, 0.011894578, 0.013390889, 0.029684484, 0.0136422645, 0.03676341, 0.041377258, 0.023872385, 0.060048714, 0.018597212, 0.011260271, 0.015630553, 0.00587507, 0.048861846, 0.024269165, 0.077528164, 0.123587504, 0.061476205, 0.09422733, 0.021925053, 0.05329217, 0.090621576, 0.25171226, 0.03164711, 0.030632712, 0.052125905, 0.08756277, 0.041609388, 0.021774432, 0.01355274, 0.012514856, 0.017115925, 0.011089981, 0.02018498, 0.05948615, 0.048766375, 0.0433983]\n",
      "[0.001410293, 0.009045844, 0.03244196, 0.012783268, 0.0069271233, 0.007749945, 0.008717183, 0.007794659, 0.018413119, 0.023760138, 0.02206133, 0.019031499, 0.040312726, 0.0068180896, 0.008578713, 0.01564762, 0.0054313354, 0.02376985, 0.03048565, 0.015762528, 0.04018094, 0.014214022, 0.0069893184, 0.010109279, 0.0031981217, 0.03449854, 0.018273963, 0.05428148, 0.08565835, 0.044972207, 0.06517132, 0.01518697, 0.037252534, 0.06373182, 0.17673463, 0.021454003, 0.02270454, 0.036634784, 0.06267886, 0.029183682, 0.014928811, 0.009638437, 0.005191969, 0.0117446445, 0.004391704, 0.01232421, 0.029636638, 0.02954527, 0.024765393]\n",
      "[0.0016928205, 0.006492747, 0.027138673, 0.008519072, 0.0056306827, 0.0053957575, 0.005221508, 0.00586083, 0.01155963, 0.016327022, 0.016442854, 0.012586537, 0.027586304, 0.0051616286, 0.0063823345, 0.01232736, 0.004326628, 0.018058937, 0.022955341, 0.01425666, 0.030608483, 0.011165379, 0.005452571, 0.0072668693, 0.002477969, 0.024482718, 0.015241038, 0.040857963, 0.06318655, 0.032262474, 0.051538344, 0.013303532, 0.02842228, 0.048946302, 0.13447195, 0.016698169, 0.01634109, 0.02918959, 0.04708801, 0.022664346, 0.012351091, 0.007727394, 0.0042345645, 0.008239978, 0.0035312814, 0.0084828725, 0.022880964, 0.02498754, 0.018545402]\n",
      "[0.0046557556, 0.017042981, 0.03713196, 0.01249128, 0.00797801, 0.008206762, 0.010447083, 0.008555276, 0.0227522, 0.029331744, 0.029456, 0.028487036, 0.054396857, 0.008148363, 0.01229743, 0.02281239, 0.0056918184, 0.038813494, 0.050729275, 0.018889854, 0.06458114, 0.016006881, 0.009572317, 0.016627664, 0.005062986, 0.061719317, 0.032584473, 0.106146015, 0.16281696, 0.08256612, 0.13359536, 0.033507608, 0.09301516, 0.16245334, 0.36877832, 0.04111234, 0.051865242, 0.09214859, 0.144645, 0.06699721, 0.036948156, 0.025461575, 0.0062065003, 0.022898015, 0.0048631513, 0.02071783, 0.037808776, 0.04637484, 0.028722022] \n",
      "\n",
      "Check the graph\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD4CAYAAADmWv3KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABuN0lEQVR4nO2ddXhcVfrHP2c8ycTd2yR199IixSlWuviiu+gKC7+FRRYWWJxdYJGFLe4uheKFGlBP3Rtr3H1mMn5+f9yJtWmbQpOQ9Hyep0+SOzcz56bJd977Pa8IKSUKhUKhGHjo+noBCoVCoegZlMArFArFAEUJvEKhUAxQlMArFArFAEUJvEKhUAxQDH31wjExMXLQoEF99fIKhULRL1m3bl2NlDK2O+f2mcAPGjSI7Ozsvnp5hUKh6JcIIQq7e66yaBQKhWKAogReoVAoBihK4BUKhWKAogReoVAoBihK4BUKhWKAogReoVAoBihK4BUKhWKAogReoVC0saWkkU3FDX29DMVhQgm8QqFo46GvdvDglzv6ehmKw0SfVbIqFIpfH01OT18vQXEYUQKvUCjasLu86HWir5ehOEwogVcoFG3Y3T5MeuXcDhSUwCsUijbsLi9+o76vl6E4TCiBVygUAPj9EofbhzJoBg7qXkyhUADg8PgAaPH4kFL28WoUhwMl8AqFAtDsGQC/BI9PCfxAQAm8QqEA2gUewOn19eFKFIcLJfAKhQIAu6td1J1uJfADASXwCoUCAFvHCN7j78OVKA4XSuAVCgUADreyaAYaSuAVCgXQOYJvURbNgEAJvEKhAMDRQdSdHiXwAwEl8AqFAtg7i0Z58AMBJfAKhQJQFs1ARAm8QqEAOls0LrXJOiBQAq9QKIC90ySVwA8ElMArFApA8+BDLVr/QWXRDAyUwCsUCkCrZI2xmgG1yTpQUAKvUCgALYKPCjEByqIZKCiBVygUgFbJajUbMBl0tCiBHxAogVcoFIC2yWo1Gwgy6nGpXjQDAiXwCoUC0Dz4ELMei1GnLJoBghJ4hUIBgN3tJdhkwGLUK4tmgKAEXqFQIKXE3sGiURH8wEAJvEKhwOX145cQbNZjNupVP/gBQrcEXghxmhBilxAiVwhx+wHOmyKE8Akhzjt8S1QoFD1NaxWr1WzAorJoBgwHFXghhB54FpgNjAQuFkKM3M95jwLfHu5FKhSKnqW1k2SIyUCQSY9LCfyAoDsR/FQgV0qZL6V0A+8Bc7o47wbgY6DqMK5PoVD0Aq3zWEPMeiwGZdEMFLoj8MlAcYevSwLH2hBCJANzgXmHb2kKhaK3sAfG9YWYDViMyqIZKHRH4EUXx+ReXz8J3CalPOBvhRDiWiFEthAiu7q6uptLVCgUPU2rBx9i1iwalUUzMDB045wSILXD1ylA2V7nTAbeE0IAxACnCyG8UspPO54kpXwBeAFg8uTJe79JKBSKPsLRatGYDJgNSuAHCt0R+LXAECHEYKAUuAj4bccTpJSDWz8XQrwGfLG3uCsUil8vbZusZj0WlSY5YDiowEspvUKIP6Nlx+iBV6SU24QQ1wceV767QtHPafPgTVqhk9vnx+eX6HVdObSK/kJ3IniklF8BX+11rEthl1Je+cuXpVAoehO7q/MmK2hj+4JN3ZIIxa8UVcmqUCiwuXyY9DpMBh0Wox5QU50GAkrgFQoFDreXYLMm7EEBgVdTnfo/SuAVCgU2l5eQgB1jDlg0KpOm/6MEXqFQ4Aj0ggeURTOAUAKvUCiwu72EmLUIvtWicXmVwPd3lMArFIq2cX3QHsGrXPj+jxJ4hUKBw+Uj2NRq0WiyoCya/o9KclUoFNomq9nAkrd30mh3A+BUFk2/Rwm8QqHA7tYsmqqcJrx+rU2Usmj6P0rgFQpFwKIx4LR7EIaARaPSJPs9yoNXKI5w3F4/bp8fq1mP0+7FF/De1VSn/o8SeIXiCMcRaDQWpNfjdfnwujRrRhU69X+UwCsURzitwz6CA7N9vC4feiGURTMAUAKvUBzhtM5jtQT2VP1+SYjqCT8gUAKvUBzhtPaCN3bQc6tBzWUdCCiBVyiOcFp7wRu97VM0Q3RqbN9AQAm8QnGE02rR6DztAm/V63Api6bfowReoTjCaY3gdR0EPVinNlkHAkrgFYojnFYPHle7wAcJnbJoBgBK4BWKI5xWi8bvbBf0IL0S+IGAEniF4gjH7vKiE+Bp8aIzaLnwFnS0KA++36MEXqE4wmkd1+e0ewiNtABgRrUqGAgogVcojnAcgWlOTruX0OhWgRfKohkAKIFXKI5w7IF5rC67B2ukGQCjVFk0AwEl8ArFEY7d7SXEpMdp9xAcZkJv0GFE9YMfCCiBVyiOcOwuL2EGA36fxBxixGjWY/RrE52klAd/AsWvFiXwCsURjs3lI0wXmMcaEHi9H6QEl1dF8f0ZJfAKxRGOw+3FqgukR4YYMVr06AJj+1S7gv6NEniF4gjH7vISEpACS4gRg0mPLrC/qgZv92+UwCsURzh2l4+ggNXeatGIgDXT4lYC359RAq9QHMH4/JIWjw+LP2DRWAMC79MUX0Xw/Rsl8ArFEUxrozFTwGo3hxgwmvUQ6A2vUiX7N0rgFYojGEeg0ZjBKzFa9Oj1OowWPX6PsmgGAt0SeCHEaUKIXUKIXCHE7V08PkcIsVkIsVEIkS2EOPrwL1WhUBxuWgdu6z0SS4gRAKO5XeCVRdO/MRzsBCGEHngWOBkoAdYKIRZIKbd3OG0RsEBKKYUQY4EPgOE9sWCFQnH4aB32Idz+doE36fG7/RCkGo71d7oTwU8FcqWU+VJKN/AeMKfjCVJKm2wveQsBVPmbQtEPaPXgpduPxdoewYMW/al+NP2b7gh8MlDc4euSwLFOCCHmCiF2Al8Cvz88y1MoFD1Jx2EflmDthr5V4E1SbbL2d7oj8KKLY/tE6FLK+VLK4cA5wP1dPpEQ1wY8+uzq6upDWqhCoTj8OAIRvM/pbbdoLJrAG6VqGdzf6Y7AlwCpHb5OAcr2d7KU8gcgUwgR08VjL0gpJ0spJ8fGxh7yYhUKxeHF5vIiJHicPsx7WTQmlEXT3+mOwK8FhgghBgshTMBFwIKOJwghsoQQIvD5RLTfjdrDvViFQnF4sbu8mCUg6bTJCq0RvLJo+jMHzaKRUnqFEH8GvgX0wCtSym1CiOsDj88DzgUuF0J4gBbgQqn6jCoUv3q0NgXtjcagPYIP0QuVRdPPOajAA0gpvwK+2uvYvA6fPwo8eniXplAoehq7y0uEob1VMLR78CE6vbJo+jmqklWhOIKxu32E6/YS+EAEH6zTqU3Wfo4SeIXiCMbu8hKuD7QKtramSWofg3Q65cH3c5TAKxRHMHaXF6vQZMAcrEXwBlNA8FGDt/s7SuAViiMYu1sb9iEEmIMCEXwgi8YiVB58f0cJvEJxBNM67MMcYkQExvYJncBg1mNCqJF9/Rwl8ArFEYyWBy/aNlhbMZr1qtBpAKAEXqE4grG7vZh9YAnpnDFtNOsxqVYF/R4l8ArFEYzd5cPglV1G8Eap+sH3d5TAKxRHKFJK7G5vp2EfrRhNevR+aHErD74/owReoThCafH4kBKEx9/WaKwVo0UTeNWqoH+jBF6hOEKxubzoJeCVWIL3tWj0fqksmn6OEniF4gjF4fJhCbQEtOwdwZv1CK/E45N4fcqm6a8ogVcojlBsLu8+nSRbMZr1CJ+m/k6vEvj+ihJ4heIIxeH2EeRvFfi90iRNevAGBF758P2WbrULVigUhxefXyIAna6riZi9g93lbbNozK0R/Hf3gPRhtFwFPomQ0OJWAt9fURG8QtEHXPdmNrd9vLlP19ClRZO7CPKXtrUMNgIutdHab1ERvELRB2QX1pMQZunTNTjcXiytAt+6yWqrBIO5XeAlqmVwP0YJvELRy9Tb3TQ4PPT1UEtboNGY3qDTPHe/Dxw1YAxpH7wtVcvg/oyyaBSKXia/xg5AY4sHu8vbZ+vQPHiBuXWD1V4D0g/uZgyBQ1oErwS+v6IEXqHoZQoCAg9Q3tjSZ+vQesELgjraMwGMQluXCaE2WfsxSuAVil6moMbW9nlpg7PP1mF3acM+2jZYbVVtjxnR3oS0hmPKg++vKIFXKHqZgho7IYGpSeUNfRfBO1w+gjr2gu8YwcvmwEdl0fRnlMArFL1MfrWdyYOi0Ako60OBt7m8mP0dcuA7CrxfE3jVE75/owReoehF/H5JQY2dofFW4kItlDX2pUXjweSjS4vG5GsAtDx4JfD9FyXwCkUvUt7kxOX1MzjGSlKEpU8jeGeLDx10tmgsEQAYvA1AawSvPPj+ihJ4haIXKajWNi8Hx4SQGBHUpwLvbdFSNC3WQE6krQpihgKgd9chdAKzUHnw/Rkl8ApFL9KaQZMRG0JyRBBljU5kH1U8+ZxaZN4pgg9LAnMYwlmP0awnSCgPvj+jBF6h6EXyAxk0caFmEsMtuL1+au3uPlmL36UJt7mjB2+Nh6AIaGnAaNZjETpl0fRjlMArFL1IfrWdwbEhCCFIiggCoLwPcuGllIiAwFtCjOBpAVcjWOM0H75Fi+DNqAi+P6MEXqHoRQpq7AyOsQKQFK4JfGkf+PBunx9TIDC3hBjbM2is8RAUCc6GgMCrLJr+jBJ4haKXcHl9lNQ7GBwTAkBShNZNsi/aFdhdvvZOkiGGfQU+EMGbVATfr1ECr1D0EsV1DvwSMgICHxViwmzQ9Ukmjd3lJcgvEEYdOr2uvcjJGtfJgzf4UVk0/Rgl8ApFL5HfIUUSaPPh+6LYye72aq2Cg7SWCe0C3zmCV/3g+zfdEnghxGlCiF1CiFwhxO1dPH6JEGJz4N8KIcS4w79UhaJ/09pFclBA4IE+K3ZqbRVsCOqQA4+AkFhtk9XvwWjwo/crD74/c1CBF0LogWeB2cBI4GIhxMi9TisAjpNSjgXuB1443AtVKPo7+dV2YqwmwoOMbccSw4P6JIum1YM3B7cKfCWExIDeoEXwgEHvVQLfz+lOBD8VyJVS5ksp3cB7wJyOJ0gpV0gp6wNfrgJSDu8yFYr+T0GNnYxABk0rSRFBVDY78fh61waxuzSLplORkzVe+zwg8EadC51PKoumH9MdgU8Gijt8XRI4tj+uAr7u6gEhxLVCiGwhRHZ1dXX3V6lQDADya+xt/nsrSeEWpISKXvbhWwdudxr2YY3TPg+KADSBFxLcKoLvt3RH4EUXx7qsrRZCHI8m8Ld19biU8gUp5WQp5eTY2Njur1Kh6Oc0OT3U2FwMjt1L4FuLnXpZ4O1OzYMPCTVpB1qrWKE9gkfbG/C6lMD3V7oj8CVAaoevU4CyvU8SQowFXgLmSClrD8/yFIqBwZ6azhk0rbTmwvf2RqvdprVHCA03g5SdI/hAR8nWqU7SK/usX47il9EdgV8LDBFCDBZCmICLgAUdTxBCpAGfAJdJKXcf/mUqFP2b1gyajL0EPjFQzVrWy8VOLTYPANZQIzgbwOfeN4KXWmM0kwSXGtvXLzEc7AQppVcI8WfgW0APvCKl3CaEuD7w+DzgbiAaeE4IAeCVUk7uuWUrFP2LvGo7OgFp0cGdjoeYDYQHGXs9gnfaPQQBFqupcxUrgCkEdAaM/iZAG9vX4vZhMep7dY2KX85BBR5ASvkV8NVex+Z1+Pxq4OrDuzSFYuBQUGMnJTIYs2FfkUyK6P1USZc90As+xNi5ihVACAiKxOhrBMAoBU6v8uH7I6qSVaHoBQpqbPv4760khVt6veGY19lR4PeK4EETeG8dACZUNWt/RQm8QtHDSCkpqN43RbKVpIigXs+i8bW0tgo27BvBA1gi2gTeKAUtbhXB90eUwCsUPUx1swu720dGbNcCnxhhobHFg93l7bU1SZcPCZiCAgKvN7VlzwBaBO+pAbRNVmXR9E+UwCsUPUz+flIkW0luy4U/sE2zrawR9+HKZnH78RoEQoj2HHgh2Fqzlc3VmyEoAqNbK0bUGo4pge+PKIFXKHqYvbtI7k1i2+CP/ds0e2rsnPnMT3y2sfSwrEnnkUhToIaxQw78w6sf5tG1j0JQJAZXQOBVT/h+ixJ4haKHKaixYTbo2iY47U3b4I8DbLT+mFONlFBU5zgsazJ4JZgCf/4dqliLm4upclRBUCR6dx06vdAsGrXJ2i9RAq9Q9DAFgR40Ol1XXT8gPsyCEAeuZl2eqxWHH67NWKNXIswdesFb47C5bdS76qlpqUGawwEwmISWJqki+H6JEniFoofpqslYR4x6HfGhlv1aND6/ZGW+JvCVTb9c4L0+P2Y/6C168HnBXgPWeEpsJdrjfi8NJu2uwmDSNlnVVKf+iRJ4haIH8fr8FNU6DijwoNk0+9tk3V7WRGOLB5NBd1i6Trb2gjcGG8BRA0iwxlHSXNJ2TnXgbsNokAEP/vBZNKvzazn+saU0tngO23MqukYJvELRg5TUt+D1y30EfteqcvI3trfMTowI2q9FszxPS1c8eUT8YRH43IomTAjCw82dRvV1FPgaoQm6yeg77Fk0322vpKDGzvaypsP2nIquUQKvUPQg+TVaw66OOfDSL/nxwxzWflnQdiw5MJu1q66Ny3NrGBpvZXRyOM0u7y/Ol9+4U3vDyEgL71TF2mrRAFRLLbo26b2BStbDJ/CbS7QWCLlVzYftORVdowReoehB2lMk2yc51ZTYcNm91JXb8QXy2hPDLbi9fmrt7k7f7/L6WLunjhmZMSSEmwGo+IU+/J5d2vC1ISOiO1WxFjcXkxGeAUC1X3sNo96D+TCmSfr8kq1lrQJvOyzPqdg/SuAVih6koMZORLCRqBBT27HiHVoLAL9XUl+hpT22Df7Ya6N1Q1EDTo+fmVkxxIdpG5+/1Kaxlzvw6SEyPrhd4EM0D35o5FBCjCHUeLQ3JqNwYpKHz4PPrbLhCLQ9yFEC3+MogVcoepCCLjJoinfUtQ27rinWbIqktmKnzj78itwadAKmZUS1FUT9EoFvcLgJtfnRx1oQukAVqzkMn8FMma2MlNAUYoNiqXbWgsmKUbRg4vBl0WwuaQBgQlqEEvheQAm8QtGD7C3wXreP8txGhk1LwGDUUVOsiVxbsdNemTQ/5dYwNiWCMIuRhNYI/hdYNOvz64jxCxIGh2kHAjnwlY5KvNJLijWFmKAYalpqtH400oHBf/gsms0ljVjNBk4ZmUB1s4tGh8qk6UmUwCsUPYTD7aW80dlpilN5fiM+r5/UkVFEp1ipKdEi+KgQE2aDrlMmTbPTw6aSRo7OigEgyKQnPMj4iyL4LVuq0SEYOSYwEzlQxVrcXAzQFsHXtNRoHSVlMwYJzsPUTXJzSQOjk8MYGq/tSeRWq43WnkQJvELRQ+yp0fz1QR0EvmRHHTqdIGlIBDEpVmpKbEgpEUKQFMikaWVNQR0+v2RGVnTbsYQwyy+K4CvytQ3OwUOjtAOBCL41RTI1NJWY4BiqW6q1hmOyGQG4D8PgbbfXz47yZsalRDAkLhRQG609jRJ4haKHKKrTNioHRbcLfPGOeuIzwjBZDMSkhuJyeGmu1QQ7MdzSKYJfnluL2aBjYlpk27H4cMvPrmaVUuKtduEJ0mGxGrWDgQi+xFaCQRiID44nNiiWFm8LdktY21Qnz2EQ+J0VTbh9frJ8Br57aB0Reh05lUrgexIl8ApFD7GnVovgW+ewOm0eqoubSR2hRc8xqZpNUVPS6sN3LnZakVfDlEFRnWahJoZZfnY/muI6BzEuCE4KzIV1O8DV1BbBJ1mT0Ov0xARpllC1Oaht6If3MHjwmwL578bSFpx2D+ODgtVGaw+jBF6h6CEKa+1Eh5gIs2jRcsmuepC0CXx0shUhOmbSWKhqduHx+amxudhZ0dzJngEtgq+xaeccKut21GCVgvQhgTsCe2uRUwLFzcWkhKYAEBus+fPVRjNGr5Yz7z0MEfzm4gaigozU5gRsIoNRWTQ9jBJ4haKH2FPjID0QvQMU76zDZNETl675z0aTnoj44E4RvJRaGuSKPK252MzMmE7PmRBmQUptStShsnu7VsE6ZlxgNN9eVaypoakAxAZpAl+j12GU2puP371vhe2hsrmkkemRoTjtWuZMtEdQ2tDSq5OsjjSUwCsUPURhrb2T/16yo47kYZHo9O1/djEpVqoDEXxi22QnJytyawizGBidHN7+fNtqiQ82tZ1zqNQX2fAJiE/T3mBai5yazCE0uhpJsaZQ/+67BH26BIBqoRU6AchfOLLP4faSU9XMML8BISB1RCTGJk3YW6t9FYcfJfAKRQ/g9Pgob3KSHhD4xuoWmmqcpAyP6nReTGootjoXTruH5EAufFlDC8vzapieEY0+0NWxuriZL57ZhC9fi/YPdaPV4/NjaPDgjzCib32DCQh8qdDEOyU0hbrXXqflw/mYdCZq8LYJvP8XVrJuK2vCL8Fa5yF+cDgpw6PwNnuw+CFH9aTpMZTAKxQ9QEm9Aylps2hKdmqblakjIjud13GjtbVSdXVBHcV1LczMardnCrdo9gpNmr1xqLnwO0obifUKolqjd9AsGqGj2Ku9aSQbY3EXFeEpLSPGEk21dLcJPF7ZZSO07rKpuIFgPzirnKSPjiY2sI4kqVc+fA+iBF6h6AFac+BbBb54Rz3WSDMR8cGdzotJ0YSupriZELOB8CAjX2wqA2Bmhw3WPVs0T76l1qn1hT/ECH7D5ioMCIaO7LBpa6uE4BhK7NrrxVU4QUqk00m6P4JqrwNDQOANfvD4fr7Aby5pZLxRu0NJHx1NbKp23cPMZpVJ04MogVcoeoA9te058NIvKdlVR8rwSIQIjO1rqQdnE8FhJoLDTR1aFgTR7PISF2omM1aL7h1Nbir3NIGAhkqHVux0iBF84W4tG2bUmA6btq058M0lRJoj0Re0twseZAumxtPcFsEbpcD5C3z4zSUNjBJGgsNMxKRasViNhEZZSMGgIvgeRAm8QtEDFNY6CLMYiAg2Ul3cjMvu7ey/vzkXPrkWgNjU0LaWBUnhWpQ7Myum7c2gcGstSMgYF4ut3kWS1XzIEbyjvAW3URAa1WHwd4cq1pTQFFy7d7c9lNRsoNpVj1Fo2Tq/ZOhHo8NDYY2DiEYfaaOj264rNi2UMKeksNaO6xdu4iq6Rgm8QtEDFNY5GBQTghCCkp1a9JwyPOC/1+RA2QYo+AF8HmJSrNSXO/B6fG1tg2dktlsphVtqCAk3kTVZS29MNR5aP5pmpwer3YchztL5gQ59aFKsKTh378aUlQlAXIOkyd2MW69DrwsM/XD/vI3WzaUNJPl04JGkj2q/rtg0KzqbF4Nfa8qmOPwogVf0Gzw+P3V7DcT4tVJYayctqtV/ryM6OYSQwMAOtn+mffTYoXwTMamh+P2S+nItb14I2jZYfV4/RTvqSB8b0+bfx6Gnoqnr6U9dsT6nlki/jsSMsPaDUoKtEm9IDOX2ci2C37WboHHj0EdFEVGn/ZxrgiMx6D2/yKLZXNLIYI8OoYPUke13MTEBHz7Wp1M2TQ+hBF7Rb3h+WR4nPL70Z1Vx9iYen5+S+hYGRYe0tQfuZM9s/wyis7TPC5cTk6J57dXFzVw8NY1P/jCjLZIvy23A4/QxaEwMEXGawId5tcZdDd1stbttszb7dczYuPaDzgbwuamwhOCTPgZ5I/DV1WEZOhRjSgoh1Zrg1gSHYdC5Mf0Ci2ZTcQPDpZHEzAjMQYa2462ZNAk+oXrS9BBK4BX9hp9ya2hweH71t/Ol9S34/JL06GDK87T2wG32TF0+VGyGSb+D6CFQuILw2CCMZj01xTZCzAYmdGguVri5Fr1RR8rwSIxmPdZIM+YW7Q2uu8VOFQWN+IGMYR3eZAJVrCWBnPiUKk28zUOHYkpJxlSp2Uo1phCMwoVRClp+ZsvgnD2NRLq17JmOhISbCQ4zkaE3kVutBL4nUAKv6Bd4fX42FWs9THaUN/Xxag5MWwZNTAglO+vQ6bX2wABsX6B9HHk2pM+AwpUI/IHWwZ0LfqSUFGypIXloJEaT1nAsIj4YmrUK0O4WO/lrXLit+rbnANqKnIoDRU6Rpdprm4cNw5icAlU1CL+k2mTGpHNiBJzeQ79zqmpyElKv3WnsLfCgRfHxPh25KoLvEZTAK/oFuyqb28bG7az4dVc+Fta258AX76gnISMckyVgTWz/DJImQkQapM8EVyNUbmvvDe9v99UbKh00VbcwaEy7MEbEB+Oqd4Hs3mSn8voWopxgTeqcf98WwfscGHVGTHvK0cfEYIiKwpiSAl4fMTYd1QYDRuyBuayHHsFvLmkkw6vHGGokKilkn8dj00KxOP0UVtvw/sqtt/5ItwReCHGaEGKXECJXCHF7F48PF0KsFEK4hBC3HP5lKo501hc1ANrko197BF9Y6yDYpCcUHdXFze32TEMRlK2HkXO0r9NnBL5hBTGpoXicPhpr2tsFF27VipvS9xJ4r9NHCN2zaNZursSMYNCwzhW0rRF8ibuRZGsy7t05WIYOAcCYkgxAliOUGr0OE/afnSa5uaieQR4dg8e0p0d2JDY1FCEhwg1FdY5Dfn7FgTmowAsh9MCzwGxgJHCxEGLkXqfVAX8BHjvsK1QogA2F9cRYzRw3NJad5b/2CF7LoKkqagYJiVkR2gMd7RmAiFQtki9c3t6yoLjdqtizpYbo5BDCottz1yMDmTSDTWYquyHwOTu0N4lx4+I7P2CrBL2ZkpZKUkKScOXmYh4yFABTitY2eJA9mGr8mPzNWprkzxD4/J31mBFkjo3t8vHW64736VRFaw/QnQh+KpArpcyXUrqB94A5HU+QUlZJKdcCaoLurwy/X7J4ZyV+/y9v99qXrC+qZ2JaBCMSQ6loclLfB+mS6wrr2Vlx8LuHPYEuklWB6tO41v4v2z+DhLEQldF+cvpMKFxBVGIwQifafHiXw0N5TiPpYzq3C25NlUw1Grtl0TQU2/DoIT7J2vmBDjnwwxzhSJcL87BhABgSE0EIkpsN1AT60WhZNIdmoUgpcZfYkaJDDcBehEZbMAUbNB++Hwq80+OjseXXK3vdEfhkoLjD1yWBY4eMEOJaIUS2ECK7urr65zyF4hBZsquK37+WzbLd/ffnXWd3s6fWwcT0SIYnaLncfeHD3/zBRu6cv/WA5/j8kuK6FtJjgqkqbCYyPhhTkAEaS6FkTbs900r6DHDUYGjMIzKhvTd80fY6/H7JoL0E3hplQW/QabnwB4ngfX6JsdGLP9KE0O1lj9gqabTG0OxuJqNG23w1D9UieJ3JhCE+nrgGSbWvBaPOiVHStgfSXUrqW0hygCEhqH0PYi+EEMSlhZJC/2w6duf8rZzx9I+/2krc7gj8vsYZ/KxwUEr5gpRyspRycmxs17dsisPL8lztFn1zYFxaf2RDkZayNyE1guGJWjTcnUj6cOL0+Cisc7CpuOGAAyrKG1tw+/xaBF/YRFx6oLhox+fax5HndP6G9Jnax4BNU1OkvXEVbqnFEmIkfnBYp9N1OkF4XBBhnoNvsu4qaSTKC9EdO0i2YquiJDgCgIQKF+h0mANVrKD58BF1buq8DvTCiQEdTvehDeZYt6OaWL+uU/VqV8SmhhLpEeRW/rr3VvbG75cs3VVFSX0L760pPvg39AHdEfgSILXD1ylAWc8sR3G4WZWvCfz28v4r8OuL6jHoBGNTIoi1monug43W/Go7UoLXL1lXWL/f84oCGTSJRiOORjex6R3smbhREJPV+RuiMsCaAHuWE5MSir3Rjb3RReG2WtJGR6FrjbwddfDSSVC0ioj4YCxOP40tngPmpq/fUIlAMLQrgbVVUmLRWheEFtdjSktDZ2lvZWBKTiG4xo4fiUen9aNxthxalJqzSWtxPHF64gHPi00LRSehvrylX1mJu6uaqbW7sRh1PLsk92cXgvUk3RH4tcAQIcRgIYQJuAhY0LPLUhwOGhxudgQi3W1l/Ss66sj6wgZGJIYRZNIjhGBEYlivWzQdh1K0vml2ReugbatD86vjB4VBcwUUrdzXngEQIpAPv4LYQEXr9p/KcNo8ne2ZtS9ByVrY8bnmw9u86A6SKlkQ6EE/rmMFK4DPC/YaivWaNWMoKG3z31sxpqRgrGvG4JU4DZrAu53dj+CllDTlNdFihLhk6wHPba1ojXBKSjsMHf+1szIwVvHBc8ZQ1ezirVWFfbyifTmowEspvcCfgW+BHcAHUsptQojrhRDXAwghEoQQJcBfgbuEECVCiLD9P6uiN1hTUIeUcMLwOErqW37Vm0H7w+eXbCppYGJaRNux4Qmh7KpoxteL0V5elQ2dgNHJYQcU+MJaOyaDDk+1E6ETRKdYA/aM7FrgAQbNhOYyYkI1Qd60qBihE6S19m3xtMDqedrnpeu1TBoJ4X6xXx9eSom7vIWWEB3BoabOD1ZsAiQlekjQReItLsEcSJFsxZiSgpCSmCaw67XfG7ez+xHqD5sribX7iRoe0WV6JJ52IQ+PDUJn0mkbrf2oonVFXi3p0cGcOymFGZnRzFuWh+MQbayeplt58FLKr6SUQ6WUmVLKBwPH5kkp5wU+r5BSpkgpw6SUEYHP+2/IOEBYmV+Lxajj4qlpAGzvh1H8ropmHG5fp/L94YlhuLz+torR3iCnysag6BCOHRLL5pLG/frwewIpktVFzUQlhWjVo9s/g5hhEDe87bxyWznVjsDGd8CHt1SvwhppxuXwkpQVjjnYqD2+8W1w1ELieCjfSESM1rQs0i/2W826p9JOjFMSlt6F/77uNTAGU2I0MN4WBVK2bbC2Ygrkwsc1SGx6LWPJcwjDsb/5Kg89gtlnZe374OYP4dHB0KD51kIniE62Eu8T/aai1eeXrMqvbev6efMpQ6mxuXlj5a8rileVrAOYVfl1TEqPZHxqBADbyvqfD78+sME6saPAJ2ii1Zs+fE6Vjcw4K0dlRuP1S7L348MX1joYFBVEVWET8emhYKuGwuWdonePz8MV31zBTUtu0g7EDIOgqLaCJ6A9PdLvgxXPQPJkmP5H8DiIMJQCEOXT7bfY6ac1JRgQjBq/lz3jbIQtH8GY8yixVzCsXvPdLXsJvDGQCx/XCE0mzW5yu7oXwedWNWMubsEfaSQxba8beSlh+VPgbWnvqgkkDgojzq8jt/LXXePQyrayRpqdXqZnaAI/KT2K44bG8vyyPGyH8EbY0xwRAr86v5bPNpb29TJ6lQaHm50VTUwfHE1sqJm4UDPbf2UVoN1pXrWhqIEYq4nUDoMqhsRb0etErxU8eXx+9tTYGRJnZVJ6JAad6NKmkVJqAh9kwWX3EpseBju/AOnvJPBf5H9Bub2czTWbyW/IB50u4MO3Fzy1tSfYsQDq98DMGyF5EgCW+o1YrEbihX6/EXzBtjr8SCZNTuj8wOYPwOPAM+EyKuwVpFZJRFAQxtTUTqcZ4uLAaCS12URDYO/V181+8G99k0OsX8fkWan7Pli0Eiq3gM7QSeBj00IxSkFp8a/rd3R/tPrvR3Xo2/9/Jw+l3uHhteUFfbWsfRjwAu/zS/720WZu/Wgzzc7+50H/XFbla/576y/gyKSwPrVoGhxufthdzX8X53DNG9lMe+h7Rtz9DUt2Vh3w+zYU1TM+NbKTj2s26MmMDem1VMnCWjtevyQrzkqwycC41IguBb662UWLx0eiX/uzih8UpolYVCbEjwLA6/fy0paXGBw+GL3Q81leQOTSZ0L9HsZO0nPataOJTAjRot2fntRaCw8/Q8u4MYdD6Toi4oKJRdelBy+lxFvRgstqwNJq82gPQParkDieivBEfNJHdJkd85AhCF1nKRB6PcbERJKbjdQHIvjuCHy93U3phhqkgAlHd1Eus3oeWCJg5k1aXUCjFni1brTaK1t+0XDv3mJFXi1D4qzEhbZnHo1PjeCkEXG88EM+Tb8SrRnwAr90VxVFdQ5cXj/fba/s6+X0GqsC/vvYlAgARiWFkVtl6/VUrsU7Kznu30sYf993XP7KGh5buJu8ahszMmNICrfw1KKc/f5B19vd5NfYmZgesc9jwxPC2NFLEXxrAc6QOE2EjsqIZnNJ4z634m0ZNDY/OoMgKsKlTW0aOUfLlgEW7llIUXMRf5nwF2Ymz+SLvC/w+X1tfWmCataQOTFgqxT8AOUbYcYNoNNrkX7yBChbT0RCMOFeQXkXEXxeeTMxLogYtJf/XrwGqrbB5N9TbCsGKQkurNpng7UVU0oysY2SGqMmVv5u/O68s7KQoU49CSMjsYQYOz/YWAI7voCJl8O4i7VjO7SEvMiEYNALwp2S6mbXQV+nL3F7/azdU9dp6lYrN500lCanl5d/7DqKb3R4eH5Z3gE36g8nA17gX1uxh4QwC8kRQSzYdOSk76/Kr2VyehQmg/ZfPCopHK9f9vpghTdXFmJ3+bj1tGG8ffU0Nt1zCotvnsV/LhzPH4/PYmNxA6vy67r83g3F+/rvrQxPDKW0oXcyg1p/ZplxWjfE6RnR+PyS7D2d19266euvcxGTEoq+cClIHww7XTsu/by45UUywzM5Ie0Ezs48m6qWKlaXr4aEMWAO0/z6VpY/BSFxMPai9mNJE6FyG5ExRkweSV39vgK/fHUZegSjJ+zlv2e/AqZQGH0uJc0lhNtBNDbv47+3YkxOIbLOTbVeE1zpOXBk7fb6WbKkkGApmHJ82r4nZL8CSJhytVYPEDeqzabR6XUEx1qI6wc9aTaXNOBw+zrZM62MTg7ntFEJvPJTAQ2O9nYauVXN3Dl/C9MfXsTDX+/stcryAS3wOZXN/JhTwyPp2fwn4n1+yqnpNyPffgl1djc7K5o7/QKOTNQ2u3pzo9Xt9bO6oI7ZoxP446wsZmbFEB7UHtWdNymFGKuZ/y3L6/L7NxQ1oNcJxqaE7/PYiMD17OqFfPjcahvJEUEEm7Ry+4npERj1Yp83psJaOwYhaC5zaBusud9rm6fJEwFYUryE3IZcrh57NTqhY1bqLMJMYZpNo9ND2nQoXKE9WcUWyFsE068HY4dZqsmTwO8lwqRZW74m9z5tdvfs0Pz3CRM7NBhz1MG2+TDuQjBbKWkuIbNGux7z0M458K0YU1KwNLup82lvXPIg/eC/3FJGSqPEEGIgdcReb8oep5a9M3Q2RKZrx0bOgaJV0FQOQMKgMOK9Orb/ypMBVubVIgRMG9x1he5NJw/B5vbywg/5LNlVxeWvrOGkJ37gw3UlnDUuka/+cgy3nTa8y+893AxogX995R5MBh3H1H7AlMoPsPqb+GpLeV8vq8dZU6Dd/k3PaJ/gkxYVjNVs6NWN1k2BSKd1vujeWIx6fn/0IH7YXc3W0n3/qNcX1TM8IbRNWDsyoq0nTc9fT06ljay49mKdYJOBcSn7+vB7ah0Mt1rwuHzEplk1gc88AXR6pJS8uPlFUqwpnDboNADMejOzB89mcdFibG6bZtPU7NIyb5Y/DSYrTP5958UE3iwivDsBCPcKamztQYuUEn9FC64wA+YOb6Zsehd8Lm2SFFBiK2F0k2bhmIftJ4IPpEqGN3kQ+MC7/wheSskbS/LJ9OoZMzMJnX4vadn6sZbqOe269mMj5wBS24gGUjMisCD4ZnXpr9qHX5FXy8jEMCJDTF0+PjwhjDPGJPLc0jx+9+padpY3cfPJQ1l5+wn867xxjEzqvRKhASvwjS0ePl5XyuUj9ejrchHSz4URO/u1TeP0+Hh7deFBo9ZV+XUEGfWMSY5oO6bTCUYkhvZqRetPOTXohOZZ749Lp6cTajYwb68o3ueXbCxq6NKeAYgPMxMRbOxxH97nl+RV2xgS17ka86jMaLaUdvbhi2odDDVqOepxIeVgr4YhJwOwomwF22q3cdWYqzDo2t+wzs48G6fPycLChe19aTa/pwnipCshaK/rD0uC0ETCm1eDgCif6FTNuqukkWg3RA3aa8B29iuQMhUSRgO0RfD62BgMkV3/jE1tqZISvXCi9+4//W91QR26Igc6YPjerQmkhDXPQ+wIGHxs+/G44RA7HLZ9qn0ZyNlvLre3pcf+2nB6fKwrqu/Sf+/IbacN54wxiTx10Xh+uu0EbjhxCNFWcy+tsp0BK/AfZhfT4vFxZcIe7YDezLnWrazdU0d5Y/8phwatqdHH60o44bGl3Dl/K39+Z/0Bp9+syq9l8qDINv+9lVFJ4ewob+q1fh/Lc2sYkxxOeLBxv+eEWYxcMj2dr7aUs6fDrNXdlc3Y3b5OG6y2ehd7Nmv9TYQQDE8I7fFc+NL6Flxef6cIHtp9+LUBH15KyZ5aO4k+HQaznsiGJdqJmScA8MLmF4gPjufszLM7Pc+YmDEMChvEZ7mfaYVMxmBYdL+2KTv9D23n2T127llxj5ZWmTQRfUU2lggzkXtVs65YpfnvYyd1sGf2/Ai1uW13A1JKipuLSahwYxnSdfQOYExuLXYCoXNi9u1/v+OlH/IZ7zUSmx667+Sm4jVQvgmmXtO22dzGyDnavoOtiugkK0aLntE+I2/+ygqGWllfWI/b62dGZtd3pa2kRgXz7CUTmTM+eZ+/w95kQAq8zy95feUepg6KIqVuFVjjYcz5ZDWtQi+9fLGp/9g0P+ZUc8YzP3Hzh5uItpr5ywlZ5FTZ+CC7pMvza20udlY0txVgAFCTA2ipkg63r1cqQJudHjYUN+zXnunI72cOwqDX8fwP+W3HNgQmOE1IbY8uV32ax5fPbcbeoG36DU8IY1dFc4++YeVWa3cIQ+Kt2BtcOG2ayE1Miwz48JpNU+/w0Oz0EmL3E5tqRZf3vSbY1jiyK7JZX7We343+HSa9CSklFffdR/VzzyGEYE7WHNZXrafYUQkpUzQrZcwFEK5F0FJK/rnyn3yS8wnv73pfs2lqc4mMNRLl11HRIWAp3lWPD8nYjgVO2a9qqYmjzgGgoKkAu6uZ8PKmfXrQdEQfHQ0WM3GNEqlzYfH7umwPUVBjZ8u2aqK8gpEzumgstnqelt459kIACpsKeWTNI7h97nabZsfn6I06xp2QSqZLx5oNldTYfn3ZNCvza9HrBFMGRx385F8BA1LgF++soriuhStnpEH+UsiYBcNmo3M3c2FcSb+waXaUN3H5K2u47OU1NDs9PHXReD7700z+7+ShTB0UxRPf7eqyYm5NgRZRtgn87m/hv5Mhd1GHjdaet2nWFNTh80uO7obAx4VZOG9SCh+vK6EqYDesL6onKsREerQ24MLn8VOwUUtzLQhE8SMTw2jx+Hp01FtrBk1WbCgLnt7I589sREpJkEnPhNRIVgUKXvbU2tFJoN5NXIpJy/EO2DMvbnmRKEsUvxnyGwAa539K/TvvUvPsc7hLSjgz40wEggX5CwIWhtBSIwN8nPMxXxd8jdVoZVnJMmSS5sPHhto0iyYQwUspkZVO3OFGTOaADWSr0nrhjL8EjFqx2H/W/YeM5iB0bu8+LQo6IoTAmJxMbCP4dC4s+Lvse/7q8gLGeAzoDIKsyXtNjmoq11IhJ1wKZmvbm9XbO97mi/wvIG6klucfyKYZd2IqBrOeKQ4976/99bXgXZFXy9iUcKxtP99qqN7Vt4s6AANS4F9bUUBiuIVToqq1jZ2M4zWR15u4KHwbW0obKajpvT4mh8pbqwo54+kf2VTcwF1njGDRzccxZ3wyOp1ACMHfzxhBjc3NvKX7Zp+syq8l2KRvzzxZ84L2cccChsaHYtSLXtlo/Sm3BrNBx8T0rv3dvbnu2Ay8fj8vB6oAWyc4tRY4Fe+sw+2S6PBSsFa7fe+N3vA5VTZiQ83onD7qyuxUFTZTsFF7g5meEcWW0kaanR4Ka+3E+ATSJ4kzF2rVq1knsbVmKyvKVnD5yMsJMgThKS+n8qGHsIwZg9DpqH3hRRJCEpiWOI3P8z7HP+16uG4ZxGtTMXfV7eKRNY8wI2kG/zfp/yi1lZITov3fRuqKMCKoqdYi+O2FDUR7IDqjg/++4S3wezQ/H1hZtpKlxUu50nI8wH5z4Fsxp6SS0Cjw6l2YpeS8/63k5CeWMfORxUy6/ztG3v0Nb60oZKzPSMb42H1z37Nf0dotTL0agO+LvmdtxVoseguvb3sdP1Lrkb/nJ7DXYAkxMv6kVIZ69Hz1Q1GvNpQ7GDaXl03FDZ3994+vguema7baASysvmLACfzuymaW59Zy2VHpGPYs1Q5mzAKzFQYfy4jmlQgBCzb+OqP455flcdenW5k1LI4f/nY8Vx+Tgdmg73TO+NQIzh6XxIs/5lO2V3vVlfm1TB4UhVGvg7oCyF2ETcbD7m8x6bRinZ8bwVc0Ornw+ZXkd6Pj34rcWqYOjsJi1B/0XID06BDOGJvE26uKKKp1kF9t79RgLG9FHiZhZ1TwN5TkOXC3eBkSF4pO0KMbrblV2gZrSaD1rsVqZPXn+fj9kukZ0fglZO+pp7DWQUKggjXO8QNYwiF5Mi9ufpFQUygXDrsQKSXld96J9PtJfuJxws87l4b58/GUlTEnaw6ltlLW1e+AxHGA5rvfsuwWwkxhPHT0Qxyfqonysur1EJ1FhFubLmWr1u5gVq4qQ4dgfGt6pN+vpSYOOgZih+L1e/nX2n+RbE1mmiNRG/KRmcmBMKakENsgcenchBn0xIWZyYqzMi0jitNGJ3DJtDT+MiIFvUcy/Ki97BmvC9a9CkNPhagMnF4nj619jCGRQ7hr+l3kN+bzU+lPmk0jfW3ZNONPTEVn0jGkxsfig1Q69yZr99Th9ct2/72uAAqWaZXKPz4GL58CtV2n/PYVA07gX1uxB7NBx0VT0iB/ibZzHxb4xRt6GoaGfOakOFiw6deViiWl5PGFu3j4652cOTaR5y+bdMDNyVtPG4YEHvu2/fawxuZid6WtPT1y3WvkOmfweuU8imtioHzjL2pZ8M7qQlYX1PHifqr0WqlqdrKrsrlb/ntHrj8uA5vLyy0fbQJgQqBFsM/rp2BrA4Mta8lKqcHv11G4tYYgk55BMSE9ttEqpSS3SkuRLN5RT1CokWMvGkpdmZ3c7Eompkdi0utYlV9LYa2DDJ0Jc5CB8LLPIPME8m1FLC5ezCUjLsFqstLw3nvYV6wk/ta/YUpNJebqq0FKal96mRPTTiTEGMKCvAVtr33fyvsoai7i0WMfJToomtjgWEZHj2Zp8VJImkhE048AeBq1yLFkdz0+AWNa/fe8xdBQCJO11MhPcj4htyGXmyffjDc3D9OgQZ2GfHSFMSWFIJfELdxEmE289rup/O/SSTxxwXgenDuGO88YyRCHICTcROqIvXzpbfO1TKKp1wLw+rbXKbOXccfUOzg943TiguN4Y9sbWpFX5OA2m8YcbGTCSWkM8ej5eFH+3kvqM1bm1WLS65jUele68W1AwOWfwfmvQ10+zDsG1r+hZQ79ChhQAt/o8PDJ+hLOGZ9MlMkHhSsh8/j2E4aeCsBl0TvIq7b/appvSSm574vtPLM4lwsnp/LURRO0CPwApEQG8/uZg/lkQ2lbDnkn/93rwrPufZa3XA9AjvNY2PU1o5LCqLG52rzu7uLzSz5ap23sfrqhlEbH/m9HVwTGBB7If2+qbeGnD3NwNLXncI9KCue4obGsKahDJ2BcoM1CydZyXB4jWUN9JJxwJhbRSMFKLQ+8J4d/VDa5sLm8ZMWGULKzjpThUWRNjCM6xcqazwsw6gTj0yJYmV8byKARxCYKhL0Csk7ivZ3vYdQZuWjYRbiLi6n892OEzJhBxIXaZqMxOZmIuefQ8NFHGOqaOSX9FBbuWYjD4+CTnE/4quAr/jjuj0xJmIIrJ4fcU05lbk06W2q2UBM/nBDHTqQedDYvfr9EVLlwhxswtN41LX8SQhNh+Jk0uZv474b/Mjl+MielnYRrd84B/fdWWnPh/T43nr1qBP1+yfpvCyncUsOw6Qnt06cA3HZY9i+IGQoZx1Nhr+DlrS9zcvrJTEmYglFn5LIRl7G6YjU76nZqUXz+Mq0gC5hwchrSKLDssnXKrupLVubVMiEtQrsr9ftg4zuQdSKEJ2sb2H9YASmTYMEN8P6lbdfSlwwogX8/uwinx88VMwZpXet8Ls1/byUiDeJGMda+CoNO/Co2W31+ye0fb+HV5Xv4/czBPHLuGPR7D0jeD388PpOoEBMPfLkdKSUr82oJMekZkxwOOz5nffVx2FxWopJCKPDMwL/z25+90fpTbg1ljU7+fHwWLR4fH67b/wbYT7k1RAQb215rb4q31/HhQ9lsWlRM9ped7wb+MEuzDIYnhBES2MjKXbwek7CTevJsdCPPYHDwRgp3O/F5/YxICKWoztEjLVpbpzglCwMtzR5SPd8hlj7EtLMzaKxuYdfKCqZnRLO1tJH8ChshTklckPYmaE+fwYK8BZw66FSizJGU3XEHQqcj8cEHOjVOi772WqTPR93Lr3B25tk4vA7mbZ7Hw2seZnridK4eczW+5mZKbvgLnqIixnybi0Tyg1HLOLQEuwjzwIodVUR7ITYzsPdStFpLj5xxAxjMvLDpBRpcDdw65Va8VVV4iosP6r9Dey48Xjceb/u6m+ucLHhyAyvn55ExIY5Jpw3q/I3f3qlFtGc8DjodT6x7Ar/0c/PkmwHwt7Rw7tBzCTGG8Pr219ttml1fAWAOMjD6+BSGePW8+03uz/nvO6w0OjxsLWtst2fylkBTKUy4rP2k8GS47DM45QEtueG56bD4Aaje3TeLZgAJvN8veWNlIdMGR2mVYnlLQGfUpuV0ZOipGEtWcWqGmS82lffpDEiPz8+N723g/exi/nJCFv84c0TX02/2Q5jFyE0nDWFVfh3f76gK5L9r/nvTTx+ywfEbsibFMu2sDJzeYEqL/YwK0aL9Q717+SC7mMhgIzecmMWUQZG8sbKwy5+dlJLluTXMyIzuHNEFHlv/bSGfP7OR4HATg8bGsH1FeacoftrgKOaMT+LcSZqw+Lw+CvIEg8J3o8+cCaYQBg/V4/aaKNtRyfCEnmtZ0NpkzFyr3a2klP0Xfvg3gyILiB8cxtovC5iaFoFfQrDDh5AQ514FCWP4vGoNdo+di4dfTN0bb9CSvY74v/8dY2Jnn9qUmkr4mWdS//77jDWkk2xN5tWtrxJqCuXhYx5Gh6DsjjtwFxcTevLJsGEbYx3RLLXlg85ApKWWKL9g0Q9FCAQTWtsD//gYBEfDpCspbCrk7Z1vM3fIXIZHDKXsb7ciLBbCTz/9oD+D1lx4o9uNx6vdGeSuq+L9B9ZQVdjMiVeM4NRrRmEK6lBtvOtrzXufcQMMPpb1lev5uuBrrhx1JcnWZKqffobd04/CsLuIc4ecyzcF31ARnqgFYIGiJ4CjZg/GZxDUr63uVmvpnmRVQS1SwoyswAbrhje1NhTDZnc+UafDN+1PbB73JfOr7qJhyTvw7BR4/litr39T7waVA0bgswvrKalv4bfTAk2O8pdA6jQw7VV0MWw2SB9XxOdR2tDSpxVz932+nS82l3PH7OH89ZRhhyTurVw8NY2M2BDuXbCNnCqbZs9U7WDFzjEInZ4Z5w4hbVQUBpMgzzkDa+Ei0qODD6knTb3dzXfbKjlnQjJmg57LjxpEUZ2Dpbv33QArqLFT3ujcx393O718+8JWVs7PI3NSHOfeOomZ52bh9/rZtKj9bkAIwVMXTeCqowcDUPrTaly+YLImJ7UVyaTOOgaDcJL/w4a2TJqe8OFzqmyEBxmpz28iIsxNqK4agiIQX/4f085Mx1bvIqioBZNBR4IvsMHa9DUy80Te2/keI6NHMrQphOr/PIl11izC557T5etEX3cd0uWi4fU3OG/oeeiEjkePeZSYoBhqX3wJ2/eLiPvbLSTc/Q8wGLhgVxSrKtbijBtBrH4PYX5B1e4GvAJGjY6Fso2Qs1AbEGIK4fHsxzHpTNww4QZq5s3DsWYNCXffjWnQoIP+DPRhYfhCggh2OvFLPd+9uo1vX9xKRHwwF9w5heFHJXb+vbVVwWd/hvgxcMJd+Pw+HlnzCPHB8fx+9O9p/Owzap57Dul2U3HvvVwyVOsq+daOtwM2zVJo0f4mzUEGUqfHk+7S8Ukfe/Er82oJMuo129BeCzu/1PL6De3VqVJK9myp4f371/Dj13YqbKl8IV+g5bh/gdDBwrvgiZHw+lnam2AvMGAE/svNZZgNOk4cEa/lplZs6ey/t5I8CYKjmeBcjdmg6zObZndlM2+vLuSKo9K57ri9MhnKN8Hb58OXN2sl6837b3Ns1Ov4++wRbcOKj8qMpuSbT8lzzWDiyUlYI80UtRSSPjqWfM9M/Du/ZmTioW20frqxFLfPz4VTtAEOp41OIC7UzOsr9q02XJ6rpRB29N/rK+x89Eg2+ZtqmHleFqfMMWFa9ywRS68lc5SFLctKcO3H08/9YRtG0ULqaWfg8/uoaanBMORY0kJ2UrDLS1K4hVCLoUdSJXOrbAyNCaEst4FU8yZtM/Csp6BiC6lNH5I8LIJNC4uYlBROgleH2eLHSiVrY9LJa8zj4iEXUn7H3xEWCwn3/XO/b+DmjMGEzZ5N3dvvcEXyb1h47kKmJk7Ftnw51U89Rdjps4m64goMsbGEHj+LrFUluF0O1sQOIs6zCR2CzBYd3kgjeqMOfnxcKyyaeg2rylexpHgJ14y9hqAt+dQ8+xxhZ59F+Dn7mQ/bBTIxFqtDKzrKWVPJ5NMHMfeWiUTEBe91otTE3dUM574IBjOf5X3Gjrod/HXSX2HzDsrv+gfB06eT+PBDOLduxfL5Mk4ZdAof5XxE89BTtJTOLR+1PeXpvxmCWwe7F5X0aVLEyrwO1eFbPtDWObHdnqkttfH5M5v48tnN+P2S0/8whrm3TMTW4OXrdZPx/W4x/HkdHHeb1ja5pndsmwEh8D6/5KutFZwwPE4rQMhfqj3QlcDr9DDkFIx533PK8Bi+2lJ+wLL/nuKRr3cSYjZw40l7bXRV74Y350LJWtj0Hnz0e3h8KDwT2LzZ9D44O4vZiSPiOCojmjCLgZGRgh/XJhFqsTHh9GG8sf0N5nw6h+aUUlq8oVTsqmZ8nI49tY5uDUCRUvL+2mLGpoS32SFGvY5LpqWzbHf1PvUEP+XWkBIZRFqU9sdfurueDx/JxtnkYM7MdYzfMRfx7BT47m7YvZCJzf/E4/SxZdm+E7d8jVXkl8cxKKkegzWMu5bfxeyPZ1NsL2PwcAt2t5WaXcWMSAjrkelOuVU2RposeN1+Ujzfw5jzYcTZkHUyLHmQaSeG0dLs4WjMJPp1xIdWISxhvNewmXBzODPW2nBu3kzCXXdhjIs74GtFX38d0uGg/s03iQ+Jx1NaStnNt2DOzCDx/vvb3hwizj8fXUMzR+eZWGqCKDR/2owgLiscqnZqhUXTrsVrCuHRNY+SbE3mt4lnUnaLlr2TcPc9h3S3aExJJq42B4s1h3Nunsi0szPQd5UEkP0K5HwLJ98HcSNodjfz1PqnmBA3gRMNoyn58w0Yk5NJeepJwufMIWTGDKr/8x+uiDsLu8fOJ7Z8SDsKvrunzbc2BxsJHRdJnE3y0+q+CcYW76xkV2UzJwyP097E1r8JSRMgfhQtNjdL39mlWVZ7mjj6/CFcfPc0Bo+LJSEjnBOvHEF5biOL3tiBjM6E4++AG9bDtD8c/IUPAwNC4FcX1FLd7OKMsQF/M3+JVpqdOB6Anz7I4YtnN7V7xkNPA2cDl6dWUmNz8+G6rsv+e4oVeTUs3lnFn47PIqpjR7qGInjzHO127upFcFshXLNY27SJHqKlkc2/Fl48XsvBDSCE4LlLJvLRH2aw85PvqfOkMvP0KHJtOTy1/ikAPna9jt4AuS1TmIGWhtid7JMtpY3srGjmgsmdx69dPC0Vo1506hni80tW5NVydFYMQgiklPz0ZjZB3nIuCLma5LxHNJ/19Mfgpq1w1bfE+jeTHpbDpu+L8Ozls5Z+Mx+XDCXr2DGsLFvJF/lf4PQ5eTz7cQaddBwCH/lL1jA8MZSdFc2HNcKrtbmos7tJdIEQkmTTVhh9rmYTnf5v8HtJ3Hkf6aOjMeXYifbriPevo2LwUSwuXsqFCadT/8xzBE+bRtiZZxz09SxDhxJ68snUv/kW3upqSv5yI9LrJeWZZ9CFtNuMITNnYkhKZM72YJbZiwjXt4vepCmJ8NMTWj+baX/g/V3vk9uQy18n/h+1d96Lr76e5P88gd4a0tUS9ktw2iBSK0sxpz1GUlZE1yfV5Ggbq5knwNRrtbTf7Mepd9Zz+4gbKPnDH8HvJ3Xe/9CHhyOEIOGeu5EeD+HPf8KUhCm8tfNtPHOf19ojf3C5lokDnHvRCJxCsuqjXGyNvdu+wO7y8o9PtzEkzsol09KhbIM2NGXCZTjtHuY/tp7tP5UxelYKl953FONOTEXfoffMkMnxTJuTQc7aStZ+EfibFQIMXXeiPNwMCIH/cnM5QUZ9+zts3hLIOA50enasKGPT4mIKt9Sy7YdAlJh5AuiMTHatZtrgKB75emev9b3w+yUPfbWD5IggrpwxqP0BWxW8cQ64bHDZfIjOBL1Bs5Rm3AC/fQ9uLYBLP9Gqc186CUqy2749MsREWrCZNastJFvzSJw1gdt+uI0IcwQ3TryRbU1bCM3Uke+aQWbdTwBs66JF7958kF2M2aDjrHFJnY7HhVqYPTqRD7OLsQcyWLSqTm+b/16yPoeaaj2TEldhvehxuDVfu7ap10BEqhYFnfcKk4yv4rR72fFjhyje5yVvfRVGnZv4qUN4cPWDpIelc/2461lUtIiN5maSrEUU7PYyPCEMm8tLSX33m8j5/JL6A8wGaN1gNdW4ibcUYR48gcd2v8fT659GRg6CY2+B7Z8xbXwV7hYvSIjzbeDDsHD80s/shXX4bTYS7rqz29FyzB+ux2+zUXD+BTi3bSPpX4/u45MLvZ6Ic88lZUctVNSRazWh0zvwChiW0KTZG5N/zx5vM0+ue5KZyTOZtLQc27JlxN16K5aRI7v9M2rFmpaJyQtNdrdWPLU3Pg98fLUmzHOew4ufe1fey8c5H/O7EZdjvW8e7qIikp95utP1mNLTib7+Opq//oZr7JOpsFewsH4rnPsSVO+EL/4KUhIZbsE4LQajzctL/1hB4c5fNg2pvLGl25Xs//luN6UNLTz0mzGaPbPhLTBY8A6by1f/20xjTQtzbhzPsRcOxWLtum5l0mnpDD8qgbVf7mHX6opftPZDpd8LvNfn55utFZw4Ik7rG16zG5rLION4aktt/PDubryJjTTGlrPy0zzsjS6whMGgmYjd3/Lg3DE43F4e/HJHr6x3waYytpY2ccupQ9urPFsa4M3fQHM5XPKh5vV2hU6v5d1e9Z1WmfvaGVqfkQCr31uD22fimJNN/Gf9k+Q35vPA0Q9w2cjLiLJEsTV8FXZfFI27CogP0R80VdLp8fHZxjJOH5PYaVBHK1fMSKfZ5WX+Bk2YW/33GZnRICUbP1pBkK6BoVf/GUbN1X7uHahyVMGw2SSe/TsSjdvY8MUWfIGhEv6d35DfNJpBWTpe3/UahU2F3DnpNq5MmEOKNYVH1zxK2vAg6pzxDHdrUey8ZXndstuqm11c8PxKZj66mOL99LHJrbZh9kNLZQsputXsyDqW17e/zotbXuTJ9U/CjL9AzFBi191C5nitwCfCmMtHTTs51z8Bz/yviLzkt5iHHDwVsRXLyJFYZ83CW1FB9PXXEXrCCV2eF3HuuaDTceJmybLYVNKsucSOiEC/8inQGfBO/yN3/nQnJr2JuyN+S9UTT2A96UQiL72k22vpiClVy2hy2fTwxY3w/T+1aVPr34DtC+CbO7TRgmc9jSskiluW3cInOZ9w/djruOgrO/YVK0i8915Cpk7d57mjr74a0+DBxD43nyHB6by+7XVkxvGaV735PVj/OgA3XDEWy2lJNHt9fP7kJpZ/kY88xAw4KSVvrSrkxMeXccbTP7KxuOGA528tbeSV5QVcPDWNKYOiwNMCWz5CjpjD9++VUZ7byElXjiR52IHbcQghmHXJcJKHRbD4jR2U5fReYse+kxT6GSvza6m1uzlzbCDCzNPatLpTjuPbeVvB5OftpH9j8lm4aPPfWf5RLqdcNUqzab65nSxDFdcfl8kzi3M5b1LKIVdfHgpOj49/f7uL0clhzBkXGEjstsM7F2gRyyUf4E+eQv66KnLXVeL1+JF+QEqtkZTUfkkNJj3moFcx13yH+aWvMI+wIQYfzbZ1LkZbv2fbkON578fHuGzkZcxI0mZ9Xjz8Yl7MfpmrdFPIaxzNWZnFrCw/8K36N1sraHZ6OX9yIBe6Yit8+3c44R+QOoWJaZGMTg7jjZV7uGRaGstzaxiRGEa01Uzt4o8oqk9j2oRqDPFZbc/p9Xv5vuh73tz2JptrNnP5yMu5ZeotTNrxGF+sCmL3e+8z4tKLKV30DU75G0Inx/DSlts5K+VUku5+heL167njiRv5U+l/2Dq0BbJBbN7C72bO4NXle9hTa+e/F0/c7zCGbWWNXPN6NnWBcWoPfLmd5y+bvM95OZU2soQBJKRatvKYy4DVaOWk9JN4ZesrhJnCuOqMx+H1szhu2jcMd5axPCiOOmc9c7+oRR8ZSeyf/3yIvyGQcPc/aJ4xg8hLfrvfc4wJCViPOYaTNqzgieMF71kfgsvOgWfegUlX8GrhV2yu2cy/J92H468PYoiJIemBB35Wlha0p0pKZ7CWPdLSoOWsd2T8pdiyTuDG7//Imoo13D71dk5b4aLqvWeJvvoqIs79TZfPrTOZSLjnHoquvJKbNh/Hn7KW82Ppjxx73K1QvBq+uhWSJiASx3H9OSP4LNnKkjd3Ir7YQ3luI2deM3rf/jddUNHo5LaPN7NsdzVHZ8VQVOfgylfX8NH1R5EVF7rP+V6fnzs+2UJUiJnbW6cv7fgcXI0sr7+YvPVVzDg3ixVB33DHAi3I0gktXhZCoEOHxWBhWuI0Tkw7kayILE67dgwf/2sdX83bwnm3TiYiPnif1z3c9PsI/svN5YSY9MwaFqsdyF+CjBjMsq9baKh0sGzYu5y5x8gduXGsT1xIztpKinfWtVW1svtb/nR8FunRwdz16dYeHUr92oo9lDa08PfZI7Qcca9Lq3grWYvzzJdZn5vJm3et5NsXt1KR34Sj0Y3T5sbp8OJx+fB5/Ph9Ekejm4oiJ7vt08m2n8fy7Hh++jAHi66JrOkt/GPtwwyNHMqNE2+keelS8mafzlznSHRmcCbUkO86ipN069ld2Yz7AGPY3l9bTFpUMNMHR2s9Nt6cq/XeePtcqNiCEILLjxrE7kobS3dVk72nnqOzosFWxYavdmDQuRn9Wy1bo9ndzOvbXuf0T07nb8v+RoOrgRNST+CN7W/w8JqHSbn0RmKsNaxf6cX/49PkFYRgMPh4xfYswcLMVR8341i1Cl1wMIkPvc2ssEnMK32ZiOAaCnIl95wxgn+dN5a1BfWc9d+fukyb/HpLOef9byUS+PC6GdxwwhC+3VbJjzn7zsfMrbIxWmfCIFzYh8fxXekyLh5+Mf+c8U9mD57Nk+uf5ENPJYy9iKC1jzGo6R3eDQ1hbl40xm15xN38V/Rhhz65x5iURNTllyH0B+7hE3HB+YQ2eQja2UAFXvj0T4Bk5+gzeW7Tc5yReCIjHvkET2kpyY8/hj4i4pDX0ramgMDrvZGazXZ3LdxRou2jXP8TXPU9tSffy++//T3rK9fz8IwHOfGTQqr+/W9CTzuN2L/+9YDPHzJ9GuFzziZ2/nKmtiRxy7JbWF2ZrVk1wdHwwRXg1OzEOVNSufimiSwP81G2s4637ltN5Z7934lKKflsYymn/GcZawrquH/OKN68aipvXjUVg07HZS+vactA68hrK/awpbSRe88e2d4yZP0bbPRfwaZsydjjU8hJW81j2Y9h1ptJsiYRHxxPXHAc0ZZoIiwRtHhbeHbjs/xmwW84c/6ZPLfjGTIuNiKEYMuy3tn369cRvMfn55ttFZw8Ml6zO3we2PMTOyJuZvfqSpwTSvBUr+S8TyXCV8WM2TaqLVP4/q0tXH7PMehjhsHub7BM/wP3zxnN5a+sYd6yPG7aO7PlMFBvd/PsklxOGB7HjKwYKFkHX99KXWEFm+PeYNeroXg9eSQPi2DSuclUxOQRbjGREJJAfHA8Jn3XEan0enF//U9cq9/FqGvh5qDjsdfbefmUl3EvW0HJjTeCx0Pz3Q/ym7+fweqKRRzru4iEmiI8Pq3XSlcjxIpqHazMr+Xmk4eis1Vom79+L1zyMXz+F03sf/cNZ48bzMNf7eDv87fg9vmZmRWD7ZN7yLHNZfT0cOwGO0+teYr5ufOxe+xMip/E7VNv57iU49AJHY9nP87r21/H7XNzyXm/Y+FreeR98S75rmswZbpZVbWcednjcC/+gfi/30HQ+PEUXnIpf/oskYtn2SlPKSV492gc237ggsmzGBJn5fq31vGb51bw2PnjOGNsIn6/5KlFOTy1KIcJaRE8f9kk4kItDE2w8kF2Mfcu2MY3Nx3bqT1EbpWN6S1ekk1beCUiiKCmIM7dHkrD9nd54IJ/YnPbuH/l/YROvYvTdn/Ndr+D3bZa/vadBcvYsYTPnXvYf4c6Yj3uOIiJ4qSN9Sw7IYgLC3/CPe5i7tj4NHEijGter8SxYTNJ//4XwRMn/qLX0gUF4QyzEBSo7EUIMIdq/0ilzFbGdQt/T4W9gqenP8qgxz6hftkyoq64grhb/4bQHTyOjLv1VpqXLuP2HyK59YIg/vj9H3l81uPMOv9VePV0+PSPcOFbIATTMqK575bp3Py/tUyvdPHRv9Zx3HWjSMwMx2jQYdLrMOp1NLZ4uOvTLXy1pYJJ6ZE8dv44Bsdod63p0SG88fupXPjCSi57eTUfXndU28Sl0oYWnvhuN8cPi+WMMYHEjboCcnf6WN4wh8wJscijKnho6YMck3wMT057GH9JGe7CItxFRXiKi3AXFuFrdKI78Qqyp0aysGk1b25/k1flqwwaPZTfjj4fOPw6szf9WuCX59bQ4PC02zMla6mxR/ND6TjCMwy87X+MZ76yYEqOJmj0KGZ+9TVv/eYLHDVXsPKb3Rw99FRY9T9oKufYoYmcNS6J55bkcfa4JDJirQd+8UPk6cU52F1e7jo2Eub/Af/G9/ix5Qa2Ns1C36AjY3I0jhGlfG97hX9uX45Xdi69j7JEtYl9ZkQmI6NHMjJ6JEkhSZjPuh9zUibvFn/PjzWbuGPqHcSvL6Tkpv/DMnw4MdddS8mfb+C8xRP4JHUzx4gLKG8YTIapjG1ljV0K/IfrihECzh8dAm/ORdrr2DbmQza8DsfMfo9By+fCG3Ow/P4bLpySxrxleRj1gqNcy8neaEQKPUNPG8J1311LXkMepw4+lctGXsYwkUjz999TuvB6WjZu5JIzziDk+Et5LuctPIM9jIiZzbL6P+Dyh7DC9AE3rY4masl6Yv74B6IuvxyA+Dv/TsW9/+TuhHE8k/Yd5zKOPUtXM3LMLCakRfL5DUfzh7fW86d31rOlNJPCWjtfb63g3IkpPDh3dNveh9mg5+4zR3LV69m8vmIPVx+TAUCT04O9wYVwWrBG7uKr+q3c5D+Rpkf+RRPQ8OGHPHjnbdzksXPH2oexHn09C3fP58IfXJgaHST8465uidovQRgMRJ97PuNfeJ7XTgjjQuz8NyaO4p0/8fJ3Gbi3auIefsbBM3i6gzs+goi6SuZtmke9s556Zz11rjrqnHWUNpei1+l5YdxDhP/tWWy5uSTcey+RF13Y7ec3REcTd/Nfqbj7Hp4afTF3jDRz05KbeOjohzj95H9qRUJLH4HjbgWdnqy4UF786wyuf2ktE3NcfDlvC2+EOrHv9WM36XXcdtpwrj02A71O4Pf5+f7V7dgb3Zz553G8cuUULn1pNVe+upZ3r51OiEnP3Z9uRUq4b87oNlur7LvP+a7hJhIHBZE8R8dVi25hRGgWt31uIO/P0zu9pj4mBlNqKvrQUBzPvczoF43MOH02xgueY1VEDYuLFhNsCvrF/yfdQfRV8cDkyZNldnb2wU88ALd8uIlvt1WQfddJmA163N8+zIcLUnAFp/PVpGc574Mcxu32MOjddzEPyaLw0stoycvlnRMvI75lDJf9KYaIT07TUirPf42qqAmc+PgyxiSH8/bV0/bxLP1+ybqienaWN9H6U2v1xQH0eh3JERbSo0NIiQxqa/NbWGvn9Ce+4/HU5ZxW9w4+r4/vdU+SWxJHzFQdm1MX813VN7R4W4gPjuf0wadzfNrxOL1OKh2VVNgrtH+OCipsFRQ2Fba9AUSYI7SKycihvLvzXaYmTOUR/1xK//pXLKNGkvbSS+hDQ6l44EHq33qLBTdNprnwaIY2WamKWs77lt9w/LBYZmTGcFRmNPFhFm1Qx6OLGRNr4AV5H/bSQpYEv0BhPhjMepCSuVeEErdwLoREUzp3Psc8t41ZaUb+13gzrxc9SvqEFL4d8hqLihbx3Nj7GbG1meaFC3FkZ4PfjzE1FcvIkTR//z26kBB2nzOOfySs4DfiWqJXj0YafFR6b+W3S51E/va3xP/jrrb/Dykl5bffQeOCBTx9cShDam9jmC6fMx79Q1vlssvr494F23h3TTE6AX8/fQRXHT14n/9TKSW/e20t2XvqWXzLccSFWthQVM+9/1nBKS1B1E18nm9FDi+/HYrBEkzMDX+m6t+P4a2oIHjuWdwzLpdt3mISanw88qKTyLm/IemBB37R73V3cZeUkHfSyXx8tJ7jzz6KmypX8djnkcTl1h5WcQdYd/2lNG9cxw1/MBBqDCXSEkmkJZIoSxTRQdFc7J8Ctz2MdDpJfupJrDNnHvxJ90L6/VTccw8NH36EcdhQXphj5hv9Tv4x/R+cv/kr2PaJ1h32pHs1i1UIHG4vX/5YSNUnReijzehPjMcrNQ/d65fMHpPQVr8hpWTJWzvZsbwcBGSOj+XUa0azZHcV17yxjmmDozh/cgr/9/4m7jx9BNccq73hV69dwWev1hJkdjPj9qn8ftnlBHv1PLUwCc+qtURdeSVB48djSk/DmJrWKQ3VlV9A/dtv0zh/Pn6HA8u4sURdeilhp56KMP28VEkhxDop5b4bR12d218F3uX1MfmB7zllZAKPXzAOv1/y3Z3Pklc/HN9ZhRQsfIJrvvUTd+utRP9ea5fqqaig4LzzqbMEs2rojZhT/Fz/u3TEh5dDfSGccj9vcgb/+Gwb/7lwHHMnaJuLOZXNfLqxlE83lHXp13WFEJAUHsTgKDMjGpZyuf01UkUVniFz+KbyDxTtbiFv+Eq+i3yPUFMop6SfwhkZZzApfhLC48W5Ywd+lwv8EqQf6fe3fU5KIgXWFrbX7WB73Xa2124ntz6XcHM4b4fcQNPt9xI0ahSpL72IPlTbQPI7HOTPnYvL1cKDpwxjZtHFnJb5Av9KuIVV+XU0tmhFT5mxIWTFWVmyrYTlac/TVCRZ6vwbHp+eGb/JInNCLB//ax1ej49zLzUQ/sVvIHIwH4yex6w9/6F0q2RF0+VwbgHPl/yHp7ZOIOFL7f/ZlJlJ6CknE3bKKZiHD0cIgSs3l8qHH8G+fDmOpEienmFjnON+XK6dnLPoNcLOOIOkf/9rn4jY39LCnosuxl5axCsnn8WQhqO4ZtRDGGfdqA2Q0Glvrl9sLiM6xMxRew1Jbq5z0lTdQvKwSPKrbZz65A/MGZ/MY+eP44PsYna9sZxEr5Fnp93PQz8kM2hVIYPefYegsWPx2+1UP/ccda+/gQgJ5sMTzWRtqGF8dRBDvl2IIfrAA5kPJ1suPZ+G3Vu547pgbvvQR1aR57CLO0DVf56k9qWXiLv/nxjMFoTRGPhnwlNaSuXDD2OIiSF13v8wZ2Ud/AkPQPPixZTffQ++hgZWnJHG08MLuWnyX/mdPlrL4KnL0waUn3y/1r0R2L2mgu9e2c64E1I5+oKuM5dWfZbHuq8LmTyuFrPJx/K1cUyanc70OZl8sr6Ev36g1YeMSgrjsz/NxNBSS938f/PpyqPQ63ycfE0cfyx4gqb6Sp77Nhm5eQeJ99+/3w3kjvhsNm2S19tv496zh4iLLyLxnnt+1s/niBD4RTsquer1bF793RRmpEay8ImFFJUEkTU6h2edz/HQa17CjppJ6vPzOomDY/0GCq+4nC1jZ1MdehpZF1g4dcYozePb+QVyxBx+W3UZuxvgmmMzWLCxjO3lTegEHDMklnPGJzAjIwq9wUhrLCiEQKDtCRTXt1BYa6e6vIjUgg+ZWreAGH8NdSGZWM94jC+/Dqcsp4HlWR9TkrKV26bexsnpJ6Nv8WD/8Qeav/se2w8/4LcdeKiGISGBkGnTCJ42jZBpU/EnxND0zbfU3Pp3gsaM0cTd2tlmcqxbR+Gll7F2eipN5r8xyfoxR/3zAXxBUewob2JFXg0r8mrJLqjhCTEPfeNYdjpPIDYtlAkXxfNZ7QcsK1nGOTEXIOenY7EaOff8FoI+vRDCU/DVFvFm01v444w8E3cTDy9JID27lIiLLiTqssv2O1xCSolt6VKqHnkUd2Eh29OCGFLqJfSoqQz63/8Qxq6zJNxFRRScex674tMoTvkj0UFFTDR9RGZSFfrjbtIqT/XGji9E3ZZNbPgml90F4filnpGj/Rxz7fE8tiiHecvymP/HGXyzpZyIL/Jwhm9lu/5d/vqxh5g//oHYv/yl0+s7d++m4r77aMleB0D83/9O1OWX0ZvUf/UlFX+9hYoIiG8SJP/734dd3AGavl1I6Y037vfxoPHjSXn2v4ftzc1bX0/Fvf+k+dtvqRocwYMnNzNj+nlcOORchhesQix7VOs1P/IcOP5OiM7kxw/z2LykhJOvGsnQKYGma34/lG1g8xcb+HFjBiODFjIr7H8ALG3+M9sdJ3LSGYJhZxzHqysLefL7HN783UTGln9C47fPM7/iDvxGK2f9dTy377yT3XvW8b+vktDnFZP8738RNnv2/i+iC6Tfj335CoyJCT/7jfCIEPj/e38ji3dW8d3VM/ju6RU0NUqOzvyJf2Xs5Hf/2UEyEWR+9lmXv3ANH31E6T/uYemxf8dhDiHhJMHpxxxL9PY34ft7cYWlc07N9ezwpTArycdlqTVMtxQSUr0RSjeAtwXiR0HSRK1YJ2kCxA7XosY9P8Lal7XpNH6v1q54ylW0JJ3E/Gc2Uldq5/usN0gaZ+XeUTdj/Gk9tu8XYV+5Eul2o4+KwnrC8ViPPRZ9WDjohPYGpdNptwUSXLt2Yl+9Bsfq1fjqtZxaY0oKnvJygsaNI/WFF/ZbrVj5yKPUvfYan5xyI3EyhGtOWAHBUWCrhOYKmutaKKpJYF3DWdhkLBknRLAiYQGfF3xGRqmfWZWRfJlaS0bcqYxZfSZxaaHMmV2B4ZPL2am/gEUlF7B06Ev8bkkug3OaO91BHQzpdlP39jtU/PdpdFmDGfbaW+iCDuxVNi9ZQvEf/siSKcfQFHMSYS0xWAzNjDF/yajE7YTMugqscVSsXsP6zREU2MdhwMXImA0YaGF9zfHEhNZxzHVTOef93SSGWxgkvQzd5mdtytvc+Nk6IlIzGfTeu13eUkspafz0M5zbthF/+20IQ+9ua0m3my3HHIWhuaXHxL0Vb3U1/pYWpNeL9HiQbg/S4wHpJ2jMmJ9tOewPKSVNX35FxX334Xba+Wwq/DQCTBmDmZ12EqfXVpC+9nXw2AGBzxzJZ1V3Uu1K4bwxHxId6YSSteRUZ7Kw8WYGR+Zz2hluStMm4PE5Sd+xmAULk6l0ZnBO+v9IOGYWvrgx6Bffi620jE+aHseti+Skvwznv0WPsWrrN/x3QSyW8jqSn3qS0OO7aIXSCwx4gXd6NHvm3MRoUrY3oPc2c9rIhXx37CSaH3yCEzZD+isvE3LUUft9jor7H6BwwY+smfJHdP5Q/PjwxDUxNFMwo/Q/RPh24w+KxGAr175BZ9BEPXkSmEJwl2ynsbiSBkc4Db4kGvypNMt4rLKCUHMTYYMzCR1/HGGDMxA6wQdPrsBR72XZ0De5OmYYY9fU0LxkCXg8GJOTCT3pJEJPPomgCRMOmiLXivT7ceXk4li9Gvua1ehDQoj/x90HLEX3O53kz53LNl06JakXcF7032ghhmL/dIpbRlPv1N4Qg8Kc7J6ylmW1HzFrh44524IJL2nQXlcnWD7WyIqxE5hcdBmDx8dy2hke3nnJTmlTGeM3PkRatZ+kBx8kfE73m1q1rbGlRbv976ZYVj35JLXznqdicCTfZyVD8CySGkcghI8s8wrsvijKPKMwG5wMGW3Hf5SZnZTS4rZx9A4dm1dmIdGTPqGBa/MjuNJdQqxjKCHldzGtwEbGxx8fUsFSb+PIzkb6/IRM27eQaCDgqayi4t57sS3RalzqY8z8lOEme4gOw+hhnGqJ5Xh9JGleH/aGFj5YeQpGnYvzM56iyjyDLzafQny6lbiLvLyb+w4/lvyIRHJM8jH8btAV7HqxCbfdyXmR/0eYvhpH8HDm1z2AvcUIZxfxWtU8TNVNPDE/jOAGJ6nPPXtAbelpBrzAf7O1nJde2szxTgPRhj2MHf01bwwfTMPXX3PjZz6ir7uWuP/7vwM+h/R4KLrqauzrN9Awajp5kYOp0aVi8msZOSKoHrPZjk9vwSdM+DHgkxLpk+AyYGjpPOqs2VSH3dRIsCcUqzsSnews0h6dk2D/uxyzJQ9q69FHRhJ+9lmEz5mDecSh9YH/pbRs2sTOK65j+bQHEIHiDKn344itoSIql7ygDZjLdzF7i54pO33oPT4so0YRcf75hMycQf3b71D3ztv4/F6+mzILk/k8ojIs1OU7SS56k2FlG0h9+mmsxx7bK9cjfT7q336bhg8/xJWTi9eoY+XwGIrSjiPeNQO9yU/1sDzWhn2LrWYPMY0Q2wRGv44NgyXTEo9nzE9TsDmSSQxdTaMrigZPKKctuf+Q7kAUPYunogLb0qU0L16MfeUq8HhwBOlZl+Fne6rANjyZoRNOZCLHsPt1F4mZ4VQXN+MPcbFo7Es492xnWomFWVXR6H2Sb5Pr+CHDyYiUUxjzw5mERxg48+QKvliUQl11C0tGv4queiPnliQydlMTOq+f1Bee/8Vpp7+Uwy7wQojTgKcAPfCSlPKRvR4XgcdPBxzAlVLK9Qd6zp8r8F6Pj389sJLwSjcJQavYmfo5zfnNTNsNw4r9mMeOJuOtt/fr23Z6rvp6al98CefmzTh37sRvs9FijqImZhSl8SPxGIOQ+AE/4AMhEUIicGOU9RhFPWZdMxa9HbNRj15nRLqc+BxOvG4jXq8VrwxFylDSijdgdVVjPe44Iuaeg/XYYw/7Le2hUPrvR9mysJQ9CVZMLTuIbiwgyuHH6pBYWrQMHRFqJeKss4g477x9eph4ysup/u+zNMz/hJ1ZcylPOhGju57pWx9lyAsvEDR+fK9fk5QS59atNHzyCQ1ffAHNNqrD9FSF+0ls1hHR5Ee3V3m7FJCXYmBllo7gqIuJrNWi4ITypYwM2s7wt9/v9h2Vovfw2ezYly/HtngxTT8uQ9Y1AGCzwK5kQVnaCYTI3+AV9YRUPcb4gmZCHFoRoykrU9vgz9E6cZbEG8geMoRQwx8RevD7/Ej7PGbsyCXE5kFYLFiPOZqYP/0Jy/DhfXXJbRxWgRdC6IHdwMlACbAWuFhKub3DOacDN6AJ/DTgKSnltAM9788V+I1Li1n+Xg5Bns+Iy11IZqBVun5IJpEnn0rkpZdgiIo68JN0gfT78ZSU4Ny+A+eOHTRu24jPZkPnB51fovNJ8PmQPh94vVpWi8/X+aOUCIsZXVAwuqAgdEFBiOAgdJYggsaPJ/zss3o1w+JA+N1u8q69Cm9uHoaoaExRMRiiItFHRqGPisSUPojQE084qAfuys+n6LFH2Z0fShBVzHz2nv1upvYmfpcL26JF1Mz/BL/NRlBKGsakJIyJiRiTkzAmJSE9HpoXLaJx4UI8u7T2tNsyJ1IbP4eRu95g2vvz2kfWKX61SCnxFBbiWL+B5uzVNKxdhb64ksq4KYQ35WMJ9RM+8zisR00nePpRGOO11s3uoiKaFy2m8fuFODdspCxhJrkZcxm54zVi7LsJO/4Ewk49Feuxx6AL7vm2At3lcAv8UcC9UspTA1/fASClfLjDOc8DS6WU7wa+3gXMklKW7+95f67Af/iPK0n9tpLwpj3UZUaTetYFJMyegyk9/ZCfS3H4cOXmoo+OxhB54MZLv1bcxcU0freQki8/xrS9ANOdNzHk0uv6elmKn4m3vh7n1m0Yk5MwDd63/mGf8+vqaFy8iKqNa0g+7hSsxxyDzmI54Pf0FYdb4M8DTpNSXh34+jJgmpTyzx3O+QJ4REr5U+DrRcBtUsrsvZ7rWuBagLS0tEmFhftOBDoYO1csYPXb93Dyn58jaUTfbXQoBi7S4+mWxadQ9AWHIvDdSVPo6q1v73eF7pyDlPIF4AXQIvhuvPY+DJ9xNsNnnP1zvlWh6BZK3BUDhe40zCgBOo7zSQH2np3VnXMUCoVC0Yt0R+DXAkOEEIOFECbgImDBXucsAC4XGtOBxgP57wqFQqHoeQ5q0UgpvUKIPwPfoqVJviKl3CaEuD7w+DzgK7QMmly0NEmVOKxQKBR9TLdKBaWUX6GJeMdj8zp8LoE/Hd6lKRQKheKX0O8nOikUCoWia5TAKxQKxQBFCbxCoVAMUJTAKxQKxQClz7pJCiGqgUMvZdWIAWoO43L6G0fy9R/J1w5H9vWra9dIl1LGdueb+kzgfwlCiOzuluoORI7k6z+Srx2O7OtX137o164sGoVCoRigKIFXKBSKAUp/FfgX+noBfcyRfP1H8rXDkX396toPkX7pwSsUCoXi4PTXCF6hUCgUB0EJvEKhUAxQ+p3ACyFOE0LsEkLkCiFu7+v19DRCiFeEEFVCiK0djkUJIb4TQuQEPvbPOXkHQQiRKoRYIoTYIYTYJoS4MXB8wF+/EMIihFgjhNgUuPZ/Bo4P+GtvRQihF0JsCEyMO9KufY8QYosQYqMQIjtw7JCvv18JfGAA+LPAbGAkcLEQYmTfrqrHeQ04ba9jtwOLpJRDgEWBrwciXuBmKeUIYDrwp8D/95Fw/S7gBCnlOGA8cFpg1sKRcO2t3Ajs6PD1kXTtAMdLKcd3yH8/5OvvVwIPTAVypZT5Uko38B4wp4/X1KNIKX8A6vY6PAd4PfD568A5vbmm3kJKWS6lXB/4vBntjz2ZI+D6pYYt8KUx8E9yBFw7gBAiBTgDeKnD4SPi2g/AIV9/fxP4ZKC4w9clgWNHGvGtE7MCH+P6eD09jhBiEDABWM0Rcv0Bi2IjUAV8J6U8Yq4deBK4FfB3OHakXDtob+YLhRDrhBDXBo4d8vV3a+DHr4huDfdWDCyEEFbgY+AmKWWTEF39Ggw8pJQ+YLwQIgKYL4QY3cdL6hWEEGcCVVLKdUKIWX28nL5ippSyTAgRB3wnhNj5c56kv0Xwari3RqUQIhEg8LGqj9fTYwghjGji/raU8pPA4SPm+gGklA3AUrS9mCPh2mcCZwsh9qDZsCcIId7iyLh2AKSUZYGPVcB8NHv6kK+/vwl8dwaAHwksAK4IfH4F8FkfrqXHEFqo/jKwQ0r5RIeHBvz1CyFiA5E7Qogg4CRgJ0fAtUsp75BSpkgpB6H9jS+WUl7KEXDtAEKIECFEaOvnwCnAVn7G9fe7SlYhxOlo/lzrAPAH+3ZFPYsQ4l1gFlq70ErgHuBT4AMgDSgCzpdS7r0R2+8RQhwN/Ahsod2L/TuaDz+gr18IMRZtI02PFoh9IKW8TwgRzQC/9o4ELJpbpJRnHinXLoTIQIvaQbPR35FSPvhzrr/fCbxCoVAoukd/s2gUCoVC0U2UwCsUCsUARQm8QqFQDFCUwCsUCsUARQm8QqFQDFCUwCsUCsUARQm8QqFQDFD+H0s1kaz3Wl8kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "dist_0, dist_2, dist_4, dist_6, dist_7  = [], [], [], [], []\n",
    "\n",
    "for global_epoch in range(G_epoch-2):\n",
    "    for layer_index in num_layers_list:\n",
    "        globals()['dist_{}'.format(layer_index)].append(np.mean(distance.euclidean(globals()['G{}_w_layer{}'.format(global_epoch, layer_index)], globals()['G{}_w_layer{}'.format(global_epoch+1, layer_index)])))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Distance Layer 0,2,4,6,7\\n--------------------------------------------------------------------------------------------------\")\n",
    "print(dist_0)\n",
    "print(dist_2)\n",
    "print(dist_4)\n",
    "print(dist_6)\n",
    "print(dist_7, \"\\n\\nCheck the graph\\n\")\n",
    "\n",
    "plt.plot(dist_0)\n",
    "plt.plot(dist_2)\n",
    "plt.plot(dist_4)\n",
    "plt.plot(dist_6)\n",
    "plt.plot(dist_7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1627963458139,
     "user": {
      "displayName": "이훈민",
      "photoUrl": "",
      "userId": "00157268181097362793"
     },
     "user_tz": 240
    },
    "id": "SCRUegHzlz1_",
    "outputId": "82a161e0-5799-441d-bb65-cb38d02fb9f6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Acc and Loss Layer 0,2,4,6,7\n",
      "--------------------------------------------------------------------------------------------------\n",
      "[[0.8172268867492676, 0.8067227005958557, 0.743697464466095, 0.75, 0.7836134433746338, 0.8340336084365845, 0.6827731132507324, 0.7457982897758484, 0.7668067216873169, 0.7542017102241516, 0.8088235259056091, 0.7752100825309753, 0.7983193397521973, 0.7878151535987854, 0.8004201650619507, 0.7815126180648804, 0.6953781247138977, 0.8004201650619507, 0.8214285969734192, 0.7815126180648804], [0.09663865715265274, 0.09663865715265274, 0.08193277567625046, 0.09663865715265274, 0.09243697673082352, 0.09663865715265274, 0.09243697673082352, 0.0903361365199089, 0.11344537883996964, 0.09453781694173813, 0.09453781694173813, 0.09453781694173813, 0.09663865715265274, 0.6302521228790283, 0.10084033757448196, 0.09663865715265274, 0.0903361365199089, 0.10924369841814041, 0.08193277567625046, 0.08403361588716507], [0.6239495873451233, 0.6029411554336548, 0.6785714030265808, 0.680672287940979, 0.6533613204956055, 0.6428571343421936, 0.6344537734985352, 0.1260504275560379, 0.6491596698760986, 0.7142857313156128, 0.680672287940979, 0.6407563090324402, 0.7247899174690247, 0.6092436909675598, 0.6260504126548767, 0.6260504126548767, 0.6827731132507324, 0.7058823704719543, 0.6533613204956055, 0.5777310729026794], [0.651260495185852, 0.7016806602478027, 0.720588207244873, 0.6281512379646301, 0.7394958138465881, 0.6659663915634155, 0.6890756487846375, 0.7142857313156128, 0.6827731132507324, 0.7415966391563416, 0.7478991746902466, 0.7457982897758484, 0.7373949289321899, 0.7899159789085388, 0.720588207244873, 0.7268907427787781, 0.7058823704719543, 0.7268907427787781, 0.75, 0.7457982897758484], [0.75, 0.756302535533905, 0.7815126180648804, 0.7310924530029297, 0.7962185144424438, 0.7731092572212219, 0.7710084319114685, 0.743697464466095, 0.7731092572212219, 0.7037814855575562, 0.756302535533905, 0.7373949289321899, 0.7668067216873169, 0.7878151535987854, 0.7689075469970703, 0.7773109078407288, 0.7521008253097534, 0.7247899174690247, 0.75, 0.7058823704719543], [0.756302535533905, 0.7941176295280457, 0.7478991746902466, 0.7079831957817078, 0.7731092572212219, 0.7373949289321899, 0.7647058963775635, 0.7773109078407288, 0.7584033608436584, 0.7710084319114685, 0.7289915680885315, 0.7857142686843872, 0.7941176295280457, 0.7773109078407288, 0.8130252361297607, 0.7731092572212219, 0.7731092572212219, 0.7878151535987854, 0.7710084319114685, 0.756302535533905], [0.7710084319114685, 0.7647058963775635, 0.8025209903717041, 0.7857142686843872, 0.8235294222831726, 0.7836134433746338, 0.8025209903717041, 0.8067227005958557, 0.779411792755127, 0.7752100825309753, 0.7773109078407288, 0.7521008253097534, 0.8025209903717041, 0.7899159789085388, 0.8004201650619507, 0.779411792755127, 0.8088235259056091, 0.7584033608436584, 0.7920168042182922, 0.8025209903717041], [0.8067227005958557, 0.7542017102241516, 0.8046218752861023, 0.7983193397521973, 0.8067227005958557, 0.8172268867492676, 0.8130252361297607, 0.8067227005958557, 0.7899159789085388, 0.7941176295280457, 0.7647058963775635, 0.7773109078407288, 0.7731092572212219, 0.7773109078407288, 0.8025209903717041, 0.8109243512153625, 0.7773109078407288, 0.7815126180648804, 0.7605041861534119, 0.7878151535987854], [0.8088235259056091, 0.825630247592926, 0.8172268867492676, 0.7899159789085388, 0.8340336084365845, 0.8046218752861023, 0.7668067216873169, 0.819327712059021, 0.7983193397521973, 0.8382353186607361, 0.7584033608436584, 0.7857142686843872, 0.8025209903717041, 0.7920168042182922, 0.7962185144424438, 0.8130252361297607, 0.7752100825309753, 0.8004201650619507, 0.8214285969734192, 0.8172268867492676], [0.8109243512153625, 0.7373949289321899, 0.8025209903717041, 0.8088235259056091, 0.8361344337463379, 0.779411792755127, 0.7878151535987854, 0.8109243512153625, 0.7962185144424438, 0.8361344337463379, 0.8340336084365845, 0.8466386795043945, 0.7857142686843872, 0.7752100825309753, 0.831932783126831, 0.8109243512153625, 0.8151260614395142, 0.825630247592926, 0.848739504814148, 0.7920168042182922], [0.8235294222831726, 0.8298319578170776, 0.8277310729026794, 0.8046218752861023, 0.8151260614395142, 0.8025209903717041, 0.8781512379646301, 0.8214285969734192, 0.7920168042182922, 0.855042040348053, 0.8025209903717041, 0.831932783126831, 0.8172268867492676, 0.8277310729026794, 0.8067227005958557, 0.8466386795043945, 0.8004201650619507, 0.8025209903717041, 0.8340336084365845, 0.831932783126831], [0.8109243512153625, 0.8214285969734192, 0.8088235259056091, 0.8067227005958557, 0.7983193397521973, 0.8235294222831726, 0.8214285969734192, 0.8298319578170776, 0.8214285969734192, 0.8172268867492676, 0.831932783126831, 0.7878151535987854, 0.8067227005958557, 0.7899159789085388, 0.8088235259056091, 0.8067227005958557, 0.8151260614395142, 0.8214285969734192, 0.819327712059021, 0.779411792755127], [0.825630247592926, 0.819327712059021, 0.8382353186607361, 0.8340336084365845, 0.8277310729026794, 0.8151260614395142, 0.7962185144424438, 0.825630247592926, 0.8088235259056091, 0.8340336084365845, 0.8340336084365845, 0.831932783126831, 0.8025209903717041, 0.8109243512153625, 0.831932783126831, 0.8046218752861023, 0.8088235259056091, 0.8424369692802429, 0.8445377945899963, 0.8046218752861023], [0.831932783126831, 0.8235294222831726, 0.8088235259056091, 0.8445377945899963, 0.831932783126831, 0.831932783126831, 0.8298319578170776, 0.8529411554336548, 0.8025209903717041, 0.8445377945899963, 0.8445377945899963, 0.831932783126831, 0.8676470518112183, 0.848739504814148, 0.8109243512153625, 0.8445377945899963, 0.8445377945899963, 0.819327712059021, 0.8697478771209717, 0.8529411554336548], [0.8277310729026794, 0.848739504814148, 0.8067227005958557, 0.8214285969734192, 0.8382353186607361, 0.8214285969734192, 0.8067227005958557, 0.8907563090324402, 0.819327712059021, 0.825630247592926, 0.831932783126831, 0.8172268867492676, 0.7899159789085388, 0.8088235259056091, 0.779411792755127, 0.8445377945899963, 0.8172268867492676, 0.8130252361297607, 0.825630247592926, 0.831932783126831], [0.831932783126831, 0.8382353186607361, 0.8067227005958557, 0.7962185144424438, 0.8214285969734192, 0.8067227005958557, 0.7773109078407288, 0.8109243512153625, 0.8298319578170776, 0.831932783126831, 0.8277310729026794, 0.8529411554336548, 0.8466386795043945, 0.848739504814148, 0.8466386795043945, 0.8025209903717041, 0.8130252361297607, 0.8004201650619507, 0.8046218752861023, 0.819327712059021], [0.8529411554336548, 0.825630247592926, 0.8403361439704895, 0.831932783126831, 0.8109243512153625, 0.825630247592926, 0.8214285969734192, 0.8277310729026794, 0.8109243512153625, 0.7815126180648804, 0.8172268867492676, 0.8130252361297607, 0.8382353186607361, 0.8067227005958557, 0.848739504814148, 0.8214285969734192, 0.7962185144424438, 0.8445377945899963, 0.8067227005958557, 0.8382353186607361], [0.8277310729026794, 0.8151260614395142, 0.8592436909675598, 0.848739504814148, 0.8151260614395142, 0.7941176295280457, 0.8298319578170776, 0.8214285969734192, 0.8403361439704895, 0.848739504814148, 0.8004201650619507, 0.8235294222831726, 0.8445377945899963, 0.831932783126831, 0.8445377945899963, 0.8235294222831726, 0.8004201650619507, 0.8109243512153625, 0.8529411554336548, 0.819327712059021], [0.8172268867492676, 0.8235294222831726, 0.8382353186607361, 0.8214285969734192, 0.855042040348053, 0.8445377945899963, 0.831932783126831, 0.819327712059021, 0.8004201650619507, 0.8004201650619507, 0.8235294222831726, 0.8718487620353699, 0.8277310729026794, 0.825630247592926, 0.831932783126831, 0.8214285969734192, 0.8529411554336548, 0.8235294222831726, 0.7962185144424438, 0.831932783126831], [0.8613445162773132, 0.8298319578170776, 0.8277310729026794, 0.8340336084365845, 0.831932783126831, 0.8592436909675598, 0.825630247592926, 0.8340336084365845, 0.848739504814148, 0.8508403301239014, 0.8613445162773132, 0.831932783126831, 0.825630247592926, 0.8529411554336548, 0.8571428656578064, 0.825630247592926, 0.848739504814148, 0.8424369692802429, 0.8802521228790283, 0.8403361439704895], [0.848739504814148, 0.8151260614395142, 0.8298319578170776, 0.855042040348053, 0.8340336084365845, 0.8361344337463379, 0.8403361439704895, 0.8655462265014648, 0.8361344337463379, 0.8592436909675598, 0.8508403301239014, 0.7983193397521973, 0.8298319578170776, 0.8613445162773132, 0.8424369692802429, 0.855042040348053, 0.848739504814148, 0.8802521228790283, 0.8361344337463379, 0.8340336084365845], [0.8655462265014648, 0.8739495873451233, 0.8676470518112183, 0.8466386795043945, 0.8760504126548767, 0.819327712059021, 0.8340336084365845, 0.8403361439704895, 0.8571428656578064, 0.831932783126831, 0.8214285969734192, 0.855042040348053, 0.8529411554336548, 0.8403361439704895, 0.848739504814148, 0.8466386795043945, 0.8508403301239014, 0.8424369692802429, 0.8298319578170776, 0.831932783126831], [0.8529411554336548, 0.8655462265014648, 0.8151260614395142, 0.8298319578170776, 0.8613445162773132, 0.855042040348053, 0.8403361439704895, 0.8340336084365845, 0.8508403301239014, 0.825630247592926, 0.8613445162773132, 0.8235294222831726, 0.848739504814148, 0.8403361439704895, 0.8571428656578064, 0.8361344337463379, 0.8424369692802429, 0.8928571343421936, 0.8340336084365845, 0.8760504126548767], [0.8466386795043945, 0.8466386795043945, 0.855042040348053, 0.8466386795043945, 0.8571428656578064, 0.8382353186607361, 0.8466386795043945, 0.8424369692802429, 0.848739504814148, 0.8613445162773132, 0.8823529481887817, 0.8340336084365845, 0.8298319578170776, 0.8361344337463379, 0.8613445162773132, 0.855042040348053, 0.8508403301239014, 0.8298319578170776, 0.855042040348053, 0.8466386795043945], [0.8508403301239014, 0.8655462265014648, 0.8718487620353699, 0.8697478771209717, 0.8235294222831726, 0.831932783126831, 0.8340336084365845, 0.8340336084365845, 0.855042040348053, 0.8403361439704895, 0.8634454011917114, 0.8172268867492676, 0.8277310729026794, 0.8361344337463379, 0.8424369692802429, 0.8529411554336548, 0.8655462265014648, 0.8907563090324402, 0.8655462265014648, 0.8928571343421936], [0.8340336084365845, 0.855042040348053, 0.8592436909675598, 0.8655462265014648, 0.8403361439704895, 0.8235294222831726, 0.855042040348053, 0.8529411554336548, 0.8382353186607361, 0.8109243512153625, 0.831932783126831, 0.8592436909675598, 0.8697478771209717, 0.8466386795043945, 0.8445377945899963, 0.8382353186607361, 0.8403361439704895, 0.8739495873451233, 0.8445377945899963, 0.8634454011917114], [0.8529411554336548, 0.8802521228790283, 0.8466386795043945, 0.8508403301239014, 0.8424369692802429, 0.8214285969734192, 0.8739495873451233, 0.8571428656578064, 0.8802521228790283, 0.855042040348053, 0.8529411554336548, 0.8613445162773132, 0.8760504126548767, 0.8445377945899963, 0.8508403301239014, 0.8466386795043945, 0.8718487620353699, 0.8382353186607361, 0.8634454011917114, 0.8718487620353699], [0.8802521228790283, 0.8760504126548767, 0.8928571343421936, 0.855042040348053, 0.855042040348053, 0.8571428656578064, 0.8361344337463379, 0.8466386795043945, 0.8382353186607361, 0.8424369692802429, 0.8571428656578064, 0.8424369692802429, 0.855042040348053, 0.8466386795043945, 0.819327712059021, 0.8529411554336548, 0.8340336084365845, 0.8466386795043945, 0.8928571343421936, 0.8823529481887817], [0.8403361439704895, 0.8466386795043945, 0.8445377945899963, 0.8403361439704895, 0.8718487620353699, 0.855042040348053, 0.8613445162773132, 0.8571428656578064, 0.8739495873451233, 0.8466386795043945, 0.8424369692802429, 0.8424369692802429, 0.8844537734985352, 0.8424369692802429, 0.848739504814148, 0.8403361439704895, 0.8697478771209717, 0.8403361439704895, 0.8613445162773132, 0.8571428656578064], [0.848739504814148, 0.8340336084365845, 0.8403361439704895, 0.8529411554336548, 0.8298319578170776, 0.8466386795043945, 0.8403361439704895, 0.819327712059021, 0.819327712059021, 0.8739495873451233, 0.8214285969734192, 0.819327712059021, 0.8361344337463379, 0.8298319578170776, 0.8172268867492676, 0.8382353186607361, 0.8088235259056091, 0.8361344337463379, 0.8613445162773132, 0.8571428656578064], [0.8571428656578064, 0.8592436909675598, 0.8655462265014648, 0.855042040348053, 0.8571428656578064, 0.855042040348053, 0.8529411554336548, 0.8676470518112183, 0.8634454011917114, 0.8676470518112183, 0.855042040348053, 0.8613445162773132, 0.8781512379646301, 0.8697478771209717, 0.8802521228790283, 0.8613445162773132, 0.8718487620353699, 0.8571428656578064, 0.8739495873451233, 0.8613445162773132], [0.8907563090324402, 0.8739495873451233, 0.8634454011917114, 0.8340336084365845, 0.831932783126831, 0.8634454011917114, 0.8298319578170776, 0.8592436909675598, 0.8802521228790283, 0.8445377945899963, 0.8529411554336548, 0.8739495873451233, 0.8844537734985352, 0.8445377945899963, 0.8676470518112183, 0.8865545988082886, 0.8634454011917114, 0.8718487620353699, 0.8676470518112183, 0.8634454011917114], [0.8592436909675598, 0.8340336084365845, 0.8508403301239014, 0.8277310729026794, 0.8424369692802429, 0.8466386795043945, 0.8235294222831726, 0.8466386795043945, 0.8361344337463379, 0.8130252361297607, 0.8235294222831726, 0.8361344337463379, 0.8235294222831726, 0.8466386795043945, 0.8466386795043945, 0.8403361439704895, 0.8046218752861023, 0.8445377945899963, 0.8235294222831726, 0.8214285969734192], [0.825630247592926, 0.8424369692802429, 0.8172268867492676, 0.8088235259056091, 0.8340336084365845, 0.8214285969734192, 0.8214285969734192, 0.831932783126831, 0.8214285969734192, 0.8361344337463379, 0.848739504814148, 0.825630247592926, 0.8172268867492676, 0.825630247592926, 0.8361344337463379, 0.819327712059021, 0.8277310729026794, 0.825630247592926, 0.825630247592926, 0.831932783126831], [0.8025209903717041, 0.8445377945899963, 0.8361344337463379, 0.8235294222831726, 0.819327712059021, 0.7626050710678101, 0.819327712059021, 0.819327712059021, 0.8298319578170776, 0.825630247592926, 0.8298319578170776, 0.7983193397521973, 0.825630247592926, 0.8340336084365845, 0.7983193397521973, 0.825630247592926, 0.7941176295280457, 0.779411792755127, 0.8004201650619507, 0.8445377945899963], [0.7584033608436584, 0.75, 0.756302535533905, 0.743697464466095, 0.7605041861534119, 0.7668067216873169, 0.7184873819351196, 0.7647058963775635, 0.7584033608436584, 0.7899159789085388, 0.7247899174690247, 0.7899159789085388, 0.7647058963775635, 0.8025209903717041, 0.75, 0.7352941036224365, 0.7394958138465881, 0.7668067216873169, 0.7521008253097534, 0.7836134433746338], [0.8676470518112183, 0.8802521228790283, 0.8382353186607361, 0.8676470518112183, 0.831932783126831, 0.8571428656578064, 0.855042040348053, 0.8697478771209717, 0.8592436909675598, 0.8739495873451233, 0.8886554837226868, 0.8151260614395142, 0.825630247592926, 0.8466386795043945, 0.8844537734985352, 0.8634454011917114, 0.8676470518112183, 0.8907563090324402, 0.8655462265014648, 0.8634454011917114], [0.8571428656578064, 0.8655462265014648, 0.8592436909675598, 0.8697478771209717, 0.8718487620353699, 0.8571428656578064, 0.8718487620353699, 0.8781512379646301, 0.8655462265014648, 0.8697478771209717, 0.8781512379646301, 0.8424369692802429, 0.8403361439704895, 0.8760504126548767, 0.8529411554336548, 0.8655462265014648, 0.8676470518112183, 0.8529411554336548, 0.8760504126548767, 0.8592436909675598], [0.8676470518112183, 0.8739495873451233, 0.8865545988082886, 0.8718487620353699, 0.8802521228790283, 0.8886554837226868, 0.8382353186607361, 0.8844537734985352, 0.8760504126548767, 0.8844537734985352, 0.8886554837226868, 0.8802521228790283, 0.8676470518112183, 0.8634454011917114, 0.8655462265014648, 0.855042040348053, 0.8571428656578064, 0.8571428656578064, 0.8781512379646301, 0.855042040348053], [0.8676470518112183, 0.8718487620353699, 0.8844537734985352, 0.8718487620353699, 0.8676470518112183, 0.8592436909675598, 0.8634454011917114, 0.8718487620353699, 0.8529411554336548, 0.8613445162773132, 0.8424369692802429, 0.8802521228790283, 0.8424369692802429, 0.8781512379646301, 0.8508403301239014, 0.8697478771209717, 0.8634454011917114, 0.8697478771209717, 0.8781512379646301, 0.848739504814148], [0.8676470518112183, 0.8634454011917114, 0.8655462265014648, 0.8802521228790283, 0.8970588445663452, 0.8844537734985352, 0.8571428656578064, 0.8508403301239014, 0.8634454011917114, 0.8844537734985352, 0.8571428656578064, 0.8655462265014648, 0.8886554837226868, 0.8928571343421936, 0.8634454011917114, 0.8760504126548767, 0.8823529481887817, 0.8697478771209717, 0.848739504814148, 0.8613445162773132], [0.8865545988082886, 0.8214285969734192, 0.8592436909675598, 0.8739495873451233, 0.819327712059021, 0.8676470518112183, 0.8571428656578064, 0.8466386795043945, 0.855042040348053, 0.8865545988082886, 0.8151260614395142, 0.8802521228790283, 0.8676470518112183, 0.8739495873451233, 0.8634454011917114, 0.8676470518112183, 0.8466386795043945, 0.8424369692802429, 0.8592436909675598, 0.8634454011917114], [0.8445377945899963, 0.8361344337463379, 0.8676470518112183, 0.8403361439704895, 0.8235294222831726, 0.8823529481887817, 0.8235294222831726, 0.8655462265014648, 0.8655462265014648, 0.848739504814148, 0.8739495873451233, 0.8718487620353699, 0.831932783126831, 0.8403361439704895, 0.894957959651947, 0.8466386795043945, 0.8445377945899963, 0.8445377945899963, 0.8571428656578064, 0.8130252361297607], [0.831932783126831, 0.8466386795043945, 0.8361344337463379, 0.8361344337463379, 0.8403361439704895, 0.8655462265014648, 0.8235294222831726, 0.8403361439704895, 0.8361344337463379, 0.8277310729026794, 0.8403361439704895, 0.8403361439704895, 0.848739504814148, 0.8571428656578064, 0.8361344337463379, 0.8403361439704895, 0.8214285969734192, 0.855042040348053, 0.8466386795043945, 0.8340336084365845], [0.8655462265014648, 0.8529411554336548, 0.8298319578170776, 0.8802521228790283, 0.8655462265014648, 0.819327712059021, 0.8844537734985352, 0.8298319578170776, 0.8277310729026794, 0.8739495873451233, 0.8613445162773132, 0.8592436909675598, 0.8361344337463379, 0.8634454011917114, 0.831932783126831, 0.8361344337463379, 0.8508403301239014, 0.825630247592926, 0.8277310729026794, 0.8634454011917114], [0.8508403301239014, 0.8151260614395142, 0.8445377945899963, 0.831932783126831, 0.8424369692802429, 0.8298319578170776, 0.8361344337463379, 0.8403361439704895, 0.8025209903717041, 0.8403361439704895, 0.825630247592926, 0.7983193397521973, 0.8004201650619507, 0.8172268867492676, 0.7941176295280457, 0.8298319578170776, 0.848739504814148, 0.8067227005958557, 0.7962185144424438, 0.7668067216873169], [0.8361344337463379, 0.8466386795043945, 0.825630247592926, 0.8067227005958557, 0.848739504814148, 0.8340336084365845, 0.8067227005958557, 0.7983193397521973, 0.819327712059021, 0.8004201650619507, 0.8445377945899963, 0.8004201650619507, 0.7857142686843872, 0.8235294222831726, 0.8424369692802429, 0.8088235259056091, 0.825630247592926, 0.8151260614395142, 0.8445377945899963, 0.7962185144424438], [0.7605041861534119, 0.7983193397521973, 0.7941176295280457, 0.8046218752861023, 0.7962185144424438, 0.7773109078407288, 0.8025209903717041, 0.8004201650619507, 0.7331932783126831, 0.7878151535987854, 0.825630247592926, 0.7478991746902466, 0.7731092572212219, 0.8046218752861023, 0.8046218752861023, 0.7457982897758484, 0.8088235259056091, 0.7331932783126831, 0.7983193397521973, 0.8109243512153625], [0.848739504814148, 0.8130252361297607, 0.831932783126831, 0.855042040348053, 0.8361344337463379, 0.8235294222831726, 0.8403361439704895, 0.8235294222831726, 0.8592436909675598, 0.8361344337463379, 0.8214285969734192, 0.8235294222831726, 0.8424369692802429, 0.8529411554336548, 0.8676470518112183, 0.8172268867492676, 0.7941176295280457, 0.8151260614395142, 0.8403361439704895, 0.8571428656578064], [0.8592436909675598, 0.8340336084365845, 0.8340336084365845, 0.8340336084365845, 0.8340336084365845, 0.825630247592926, 0.8403361439704895, 0.8445377945899963, 0.8298319578170776, 0.848739504814148, 0.8067227005958557, 0.8361344337463379, 0.8403361439704895, 0.8361344337463379, 0.8508403301239014, 0.8571428656578064, 0.8676470518112183, 0.8697478771209717, 0.8445377945899963, 0.8382353186607361], [0.8403361439704895, 0.8697478771209717, 0.8571428656578064, 0.8613445162773132, 0.8298319578170776, 0.8424369692802429, 0.8592436909675598, 0.8067227005958557, 0.8340336084365845, 0.8298319578170776, 0.8739495873451233, 0.848739504814148, 0.825630247592926, 0.8424369692802429, 0.8361344337463379, 0.8382353186607361, 0.8361344337463379, 0.7920168042182922, 0.8235294222831726, 0.8676470518112183]]\n",
      "[[0.4908963739871979, 0.5019108057022095, 0.6966427564620972, 0.6632401943206787, 0.5979707837104797, 0.47755685448646545, 0.793627142906189, 0.7309728264808655, 0.6246771812438965, 0.6340962648391724, 0.5184484124183655, 0.5756264925003052, 0.5528978109359741, 0.5986661911010742, 0.579437792301178, 0.6173111200332642, 0.7881613373756409, 0.5514618754386902, 0.5407475233078003, 0.5521776080131531], [2.3025524616241455, 2.3026134967803955, 2.304138660430908, 2.302525043487549, 2.30330753326416, 2.3033385276794434, 2.3050785064697266, 2.303069591522217, 2.3017566204071045, 2.3032572269439697, 2.303959608078003, 2.3028430938720703, 2.3021271228790283, 1.110701084136963, 2.303225517272949, 2.302130699157715, 2.3038711547851562, 2.3028666973114014, 2.3042454719543457, 2.3127481937408447], [1.0503902435302734, 1.0458921194076538, 0.8581143021583557, 0.8465525507926941, 0.8962392210960388, 0.9973414540290833, 0.8978966474533081, 2.2990715503692627, 0.8813292384147644, 0.7863569259643555, 0.7554268836975098, 0.9106287360191345, 0.7653200626373291, 0.9948413968086243, 0.8796271681785583, 0.9672502875328064, 0.8404120802879333, 0.8181647658348083, 0.9871708154678345, 1.045347809791565], [0.8216172456741333, 0.8083371520042419, 0.7913845181465149, 0.9319814443588257, 0.6937305927276611, 0.8132437467575073, 0.8958730101585388, 0.7483932375907898, 0.7655776143074036, 0.7092564702033997, 0.6497198343276978, 0.7250996828079224, 0.6851896643638611, 0.6424888968467712, 0.7127506136894226, 0.749341607093811, 0.7139381766319275, 0.7571333050727844, 0.7293403744697571, 0.6401020884513855], [0.6532595753669739, 0.6399177312850952, 0.6153185963630676, 0.6531695127487183, 0.5410880446434021, 0.6153400540351868, 0.5863568782806396, 0.6504793167114258, 0.6508678197860718, 0.6972755789756775, 0.6524763703346252, 0.7113834023475647, 0.6585989594459534, 0.5858714580535889, 0.6180126667022705, 0.675005316734314, 0.6439532041549683, 0.707390546798706, 0.6652947664260864, 0.839633584022522], [0.6049121618270874, 0.6049872040748596, 0.6777719855308533, 0.7322907447814941, 0.5983596444129944, 0.6654978394508362, 0.6493754386901855, 0.6076176166534424, 0.6298661828041077, 0.6185575723648071, 0.6982222199440002, 0.620521605014801, 0.5674673914909363, 0.5989329218864441, 0.5303147435188293, 0.608395516872406, 0.6220807433128357, 0.597050130367279, 0.6090766191482544, 0.6501128077507019], [0.6268089413642883, 0.6466618180274963, 0.4681010842323303, 0.5444996356964111, 0.5257324576377869, 0.5992838144302368, 0.5733323097229004, 0.5113110542297363, 0.5785513520240784, 0.5786573886871338, 0.5759440064430237, 0.707453727722168, 0.4942745566368103, 0.5704540610313416, 0.5850414037704468, 0.6441152095794678, 0.5615726709365845, 0.6455766558647156, 0.5101044178009033, 0.5578619241714478], [0.5252142548561096, 0.6453918814659119, 0.49573788046836853, 0.5408877730369568, 0.5647470355033875, 0.4802629053592682, 0.4774480164051056, 0.5325556993484497, 0.617304265499115, 0.5539577603340149, 0.6168401837348938, 0.6173754334449768, 0.5878337025642395, 0.6654050946235657, 0.592216432094574, 0.5599181652069092, 0.6025164127349854, 0.5751348733901978, 0.6419269442558289, 0.5954750180244446], [0.48730072379112244, 0.47742119431495667, 0.5531420707702637, 0.619227409362793, 0.47495487332344055, 0.5692175030708313, 0.6383101940155029, 0.5266658663749695, 0.5485231280326843, 0.4477653205394745, 0.6667813062667847, 0.5459545850753784, 0.561281144618988, 0.5553990602493286, 0.5076280236244202, 0.5477303862571716, 0.5787202715873718, 0.5389686822891235, 0.45765024423599243, 0.5334895253181458], [0.500941276550293, 0.6539614200592041, 0.5795571208000183, 0.5258602499961853, 0.47959956526756287, 0.5940187573432922, 0.5513644814491272, 0.5169497132301331, 0.5660266876220703, 0.47639819979667664, 0.49134862422943115, 0.4475444257259369, 0.5542775988578796, 0.5431195497512817, 0.46193015575408936, 0.4747750461101532, 0.5387368202209473, 0.49233052134513855, 0.41620901226997375, 0.5297156572341919], [0.5222480297088623, 0.44897687435150146, 0.4950753152370453, 0.5237939953804016, 0.4905889928340912, 0.5791937112808228, 0.4089473485946655, 0.45273029804229736, 0.5838674306869507, 0.4377194046974182, 0.5216324925422668, 0.45819222927093506, 0.5213418006896973, 0.5325518250465393, 0.5126274228096008, 0.4087507426738739, 0.5338820219039917, 0.4989052712917328, 0.49286580085754395, 0.4539996087551117], [0.5099961161613464, 0.4653371572494507, 0.5303587913513184, 0.5126520395278931, 0.5600488781929016, 0.4946029484272003, 0.5220999717712402, 0.4795287251472473, 0.5177940130233765, 0.5136445164680481, 0.47162678837776184, 0.5519511103630066, 0.5276753306388855, 0.5549356341362, 0.5038307309150696, 0.4921795129776001, 0.5013593435287476, 0.4762189984321594, 0.4671803116798401, 0.6286939382553101], [0.4559484124183655, 0.4391553997993469, 0.4845629334449768, 0.47656893730163574, 0.45389091968536377, 0.5265122056007385, 0.5264967083930969, 0.4512202739715576, 0.5189679265022278, 0.47840365767478943, 0.4383709728717804, 0.45924127101898193, 0.5201731324195862, 0.48487094044685364, 0.4840829372406006, 0.5830179452896118, 0.5146524310112, 0.42613399028778076, 0.47411423921585083, 0.5206412076950073], [0.3958721458911896, 0.5255154371261597, 0.5533534288406372, 0.458179771900177, 0.4781409502029419, 0.434095174074173, 0.45162808895111084, 0.4372139275074005, 0.5254541635513306, 0.3717278242111206, 0.4886168837547302, 0.537688136100769, 0.3693510890007019, 0.4527692496776581, 0.5348171591758728, 0.4706326723098755, 0.43778350949287415, 0.46930229663848877, 0.3982682526111603, 0.4793606102466583], [0.4470590651035309, 0.4417605400085449, 0.4905678629875183, 0.5344409346580505, 0.4877757728099823, 0.4602772891521454, 0.57280033826828, 0.3301903307437897, 0.5249348282814026, 0.5061391592025757, 0.5085363984107971, 0.4737339913845062, 0.528839111328125, 0.5368456840515137, 0.6157823801040649, 0.42753124237060547, 0.500726580619812, 0.5339252352714539, 0.47815775871276855, 0.44654780626296997], [0.4537324607372284, 0.44426271319389343, 0.49285176396369934, 0.5502759218215942, 0.4364876449108124, 0.4831010699272156, 0.5930258631706238, 0.521318256855011, 0.45890557765960693, 0.438274085521698, 0.48977917432785034, 0.42141246795654297, 0.5175999999046326, 0.4552499055862427, 0.4733760356903076, 0.5116152763366699, 0.5530959963798523, 0.5443490743637085, 0.47621989250183105, 0.5138221383094788], [0.4230748116970062, 0.4444613456726074, 0.41586047410964966, 0.45136210322380066, 0.5058914422988892, 0.46012088656425476, 0.45439356565475464, 0.5086135864257812, 0.4796943664550781, 0.5475262403488159, 0.47353193163871765, 0.5030266642570496, 0.4701559841632843, 0.5690474510192871, 0.42092040181159973, 0.4670110046863556, 0.568758487701416, 0.43758586049079895, 0.5127997398376465, 0.4452391564846039], [0.49091288447380066, 0.46381136775016785, 0.3573688864707947, 0.41742900013923645, 0.5254894495010376, 0.5332464575767517, 0.46867987513542175, 0.4913926124572754, 0.45749709010124207, 0.42353785037994385, 0.6106400489807129, 0.46820876002311707, 0.48054051399230957, 0.5222821831703186, 0.46664202213287354, 0.5244355797767639, 0.5488038659095764, 0.4700436294078827, 0.3868587911128998, 0.5118899941444397], [0.4596387445926666, 0.5291777849197388, 0.4791761040687561, 0.4774911403656006, 0.40145280957221985, 0.42474129796028137, 0.4328244924545288, 0.46313759684562683, 0.512901246547699, 0.5641651749610901, 0.4599890410900116, 0.3726853132247925, 0.45079413056373596, 0.47666895389556885, 0.5103126168251038, 0.4777696430683136, 0.4116189181804657, 0.46549108624458313, 0.5566194653511047, 0.4170803129673004], [0.38618338108062744, 0.537367582321167, 0.4868277907371521, 0.44382187724113464, 0.49617433547973633, 0.41227105259895325, 0.44220831990242004, 0.4385989010334015, 0.4644944667816162, 0.45556750893592834, 0.40359875559806824, 0.6302801370620728, 0.43717360496520996, 0.38523295521736145, 0.4742434322834015, 0.6084792017936707, 0.4639659523963928, 0.4266912639141083, 0.3853433132171631, 0.42718154191970825], [0.5153648257255554, 0.6792247891426086, 0.5837686657905579, 0.467056006193161, 0.538828432559967, 0.5252617597579956, 0.5934109687805176, 0.41183406114578247, 0.567176878452301, 0.48739439249038696, 0.6227051019668579, 0.7178845405578613, 0.5912127494812012, 0.4387601912021637, 0.40356796979904175, 0.4460747539997101, 0.5038387179374695, 0.42395952343940735, 0.5479440093040466, 0.5724908709526062], [0.4527968168258667, 0.36236920952796936, 0.4596109688282013, 0.44192856550216675, 0.36454322934150696, 0.5970004796981812, 0.48834726214408875, 0.4532015323638916, 0.5119180083274841, 0.5562542676925659, 0.5328918695449829, 0.46630850434303284, 0.46305620670318604, 0.3873344957828522, 0.46351194381713867, 0.4764629900455475, 0.4309597909450531, 0.4707167446613312, 0.5452330112457275, 0.5401474833488464], [0.44406890869140625, 0.4187993109226227, 0.46635088324546814, 0.5263097286224365, 0.37053513526916504, 0.40858834981918335, 0.45751991868019104, 0.46943312883377075, 0.40531250834465027, 0.508094072341919, 0.3918752074241638, 0.5212586522102356, 0.3983430862426758, 0.4827803373336792, 0.4196418225765228, 0.5150313377380371, 0.44748473167419434, 0.3259943723678589, 0.477115273475647, 0.3356926143169403], [0.389730840921402, 0.4025444984436035, 0.4034605622291565, 0.39981964230537415, 0.3999553620815277, 0.4257514774799347, 0.44725921750068665, 0.44814079999923706, 0.44316792488098145, 0.41582444310188293, 0.32569578289985657, 0.44291776418685913, 0.4774668514728546, 0.40427276492118835, 0.3565238416194916, 0.3978785276412964, 0.4520747661590576, 0.41459399461746216, 0.41561853885650635, 0.44164231419563293], [0.3674560487270355, 0.3707701563835144, 0.33641043305397034, 0.33115872740745544, 0.4786873757839203, 0.43925580382347107, 0.4254412353038788, 0.44288524985313416, 0.40284135937690735, 0.42445671558380127, 0.40348291397094727, 0.49897655844688416, 0.42773619294166565, 0.40529462695121765, 0.38450634479522705, 0.4306148588657379, 0.3741890788078308, 0.32087233662605286, 0.3968561589717865, 0.3411736488342285], [0.49593016505241394, 0.3631308078765869, 0.38271206617355347, 0.3949316442012787, 0.457790732383728, 0.5324831604957581, 0.36296582221984863, 0.42700010538101196, 0.4502399265766144, 0.5000010132789612, 0.49661725759506226, 0.46021994948387146, 0.44153544306755066, 0.4218372106552124, 0.44494935870170593, 0.4481807053089142, 0.4395551085472107, 0.3639586865901947, 0.4822743237018585, 0.38921454548835754], [0.4271048903465271, 0.3065786063671112, 0.4484935700893402, 0.4017815589904785, 0.43099287152290344, 0.4085238575935364, 0.38245317339897156, 0.46490779519081116, 0.33792251348495483, 0.3889175355434418, 0.44552910327911377, 0.4035254418849945, 0.3405103385448456, 0.4815834164619446, 0.4405064582824707, 0.35191836953163147, 0.29921215772628784, 0.4423873722553253, 0.3753620386123657, 0.361762136220932], [0.4315131604671478, 0.41386404633522034, 0.4560559391975403, 0.5485356450080872, 0.5240548253059387, 0.4066060781478882, 0.531625509262085, 0.6097450852394104, 0.4557846784591675, 0.5474740862846375, 0.5448430180549622, 0.3898969888687134, 0.42385607957839966, 0.44917866587638855, 0.6103515625, 0.592000424861908, 0.8292533755302429, 0.6356921195983887, 0.34690433740615845, 0.34706512093544006], [0.6337167620658875, 0.7450485825538635, 0.5861387252807617, 0.6461401581764221, 0.44819483160972595, 0.42232444882392883, 0.6393073201179504, 0.659917414188385, 0.45321276783943176, 0.6859196424484253, 0.5409125685691833, 0.4580855071544647, 0.37225592136383057, 0.6869388818740845, 0.44091135263442993, 0.5689011216163635, 0.4458584189414978, 0.623684823513031, 0.418717622756958, 0.4549362361431122], [0.7723234295845032, 0.7285778522491455, 1.1015716791152954, 1.0005611181259155, 0.8454110026359558, 1.1577070951461792, 1.0390044450759888, 0.7935613393783569, 0.9113684296607971, 0.9536805152893066, 1.06685209274292, 1.4666123390197754, 1.2737411260604858, 1.441382646560669, 1.4174963235855103, 1.4217981100082397, 1.289001703262329, 1.5475555658340454, 1.0244032144546509, 1.8179309368133545], [0.41730162501335144, 0.4400620460510254, 0.39869916439056396, 0.41633060574531555, 0.36841827630996704, 0.39321738481521606, 0.45261314511299133, 0.3714807331562042, 0.37980446219444275, 0.42378711700439453, 0.4251231551170349, 0.4453238248825073, 0.3738049566745758, 0.4109577238559723, 0.32647278904914856, 0.5276983976364136, 0.38798055052757263, 0.3772464394569397, 0.30601179599761963, 0.41898879408836365], [0.4348523020744324, 0.4246971905231476, 0.8397030234336853, 0.7911062240600586, 0.5472072958946228, 0.5226179957389832, 1.0049501657485962, 0.5536481142044067, 0.8385726809501648, 0.9220789670944214, 0.5334712266921997, 0.5225415825843811, 0.7324538826942444, 0.5579407215118408, 0.45913416147232056, 0.3622112572193146, 0.6941534876823425, 0.4056236147880554, 0.4855704605579376, 0.459856778383255], [1.7236541509628296, 1.6289321184158325, 0.949077844619751, 2.2528836727142334, 0.8127797842025757, 0.983620822429657, 1.3334910869598389, 0.9832435250282288, 1.292435884475708, 2.5716521739959717, 1.019305944442749, 1.4724832773208618, 1.1332018375396729, 0.8214898705482483, 0.785629153251648, 0.7590332627296448, 1.3991700410842896, 0.638344407081604, 0.6357154250144958, 1.0624901056289673], [1.756429672241211, 1.0423877239227295, 0.7055384516716003, 1.672532320022583, 1.3146451711654663, 1.1414815187454224, 1.206809163093567, 0.8407596349716187, 0.8081757426261902, 1.0980638265609741, 0.917766273021698, 0.7590778470039368, 0.7153201699256897, 1.2629612684249878, 0.9076570272445679, 1.0057530403137207, 0.8061969876289368, 1.335934042930603, 0.8499011397361755, 0.8721605539321899], [2.101003408432007, 0.8175999522209167, 1.5701079368591309, 1.1458685398101807, 0.7849283814430237, 1.1258796453475952, 1.3296023607254028, 0.8796272873878479, 0.9756527543067932, 1.0362058877944946, 0.9694101810455322, 1.033921480178833, 0.8876932859420776, 2.139509677886963, 1.314725399017334, 1.2203577756881714, 1.403456211090088, 1.142791986465454, 1.4576791524887085, 1.1364496946334839], [1.1775503158569336, 1.8521591424942017, 2.654451370239258, 1.5188225507736206, 1.539689302444458, 1.8846851587295532, 1.3538318872451782, 1.1943796873092651, 1.732435941696167, 1.6161079406738281, 1.3049755096435547, 1.2787790298461914, 1.4545772075653076, 3.954038143157959, 2.5821750164031982, 2.2338919639587402, 1.1358721256256104, 2.0747148990631104, 1.355795979499817, 2.3138322830200195], [0.45723503828048706, 0.41675201058387756, 0.5690046548843384, 0.5223344564437866, 0.6341240406036377, 0.5520300269126892, 0.5014165639877319, 0.3978787958621979, 0.37949368357658386, 0.43529459834098816, 0.31964996457099915, 0.626758337020874, 0.5154116749763489, 0.48572012782096863, 0.36332106590270996, 0.5586519241333008, 0.31048551201820374, 0.41967305541038513, 0.4904846251010895, 0.4169626832008362], [0.4005138874053955, 0.37388235330581665, 0.42214417457580566, 0.44174784421920776, 0.40979403257369995, 0.5076887011528015, 0.44428181648254395, 0.4325248897075653, 0.33244845271110535, 0.4978305399417877, 0.4065514802932739, 0.4681171476840973, 0.4737146496772766, 0.52739018201828, 0.40968847274780273, 0.4833398461341858, 0.39765694737434387, 0.4315829873085022, 0.43942517042160034, 0.4056975245475769], [0.5091884136199951, 0.4401368200778961, 0.3979921340942383, 0.4113929569721222, 0.4091370105743408, 0.397844523191452, 0.5642207860946655, 0.3344990611076355, 0.34258848428726196, 0.40769022703170776, 0.32271096110343933, 0.41699835658073425, 0.35889744758605957, 0.45851847529411316, 0.4220309257507324, 0.46042439341545105, 0.46267464756965637, 0.4206739664077759, 0.4648348391056061, 0.5355690121650696], [0.7335265278816223, 0.6015989184379578, 0.6116657257080078, 0.5665382146835327, 0.5672982931137085, 0.5222495198249817, 0.4600144624710083, 0.4098527729511261, 0.6893906593322754, 0.6058026552200317, 0.5523306131362915, 0.5376369953155518, 0.5573757290840149, 0.47927600145339966, 0.5244615077972412, 0.7805531024932861, 0.5439890623092651, 0.4189693033695221, 0.5669867396354675, 0.9395881295204163], [0.3579617738723755, 0.42294082045555115, 0.45033785700798035, 0.40088480710983276, 0.3610418736934662, 0.3549216091632843, 0.45378047227859497, 0.4636531174182892, 0.3847081661224365, 0.32196715474128723, 0.42816072702407837, 0.43325096368789673, 0.4235610067844391, 0.30574506521224976, 0.4215777814388275, 0.36437615752220154, 0.44506970047950745, 0.33295735716819763, 0.4325680732727051, 0.40798866748809814], [0.3301447629928589, 0.5166003704071045, 0.4204667806625366, 0.36488011479377747, 0.5112130045890808, 0.38894128799438477, 0.3889006972312927, 0.42382171750068665, 0.39610379934310913, 0.3315601050853729, 0.49027207493782043, 0.34850868582725525, 0.428695410490036, 0.3181503713130951, 0.420962929725647, 0.3735424280166626, 0.3594179153442383, 0.4489222466945648, 0.3918900489807129, 0.3787830173969269], [0.4058980643749237, 0.4409526288509369, 0.37991318106651306, 0.4268420934677124, 0.4912382960319519, 0.3485163450241089, 0.468057245016098, 0.38349273800849915, 0.3844335675239563, 0.45129480957984924, 0.3293958306312561, 0.3722339868545532, 0.4524005055427551, 0.429745614528656, 0.32726791501045227, 0.42994973063468933, 0.3885752260684967, 0.4226421117782593, 0.35816386342048645, 0.5141856670379639], [0.4522426128387451, 0.3908798396587372, 0.47540172934532166, 0.40353822708129883, 0.4706662595272064, 0.40357741713523865, 0.4871140718460083, 0.44900837540626526, 0.39320510625839233, 0.4782080054283142, 0.37941277027130127, 0.5007119178771973, 0.4272235333919525, 0.38911131024360657, 0.4141746759414673, 0.41128209233283997, 0.518497109413147, 0.3944365680217743, 0.4601690471172333, 0.4265260696411133], [0.3950554430484772, 0.47218233346939087, 0.5146308541297913, 0.3427719175815582, 0.38126641511917114, 0.4265955686569214, 0.33756223320961, 0.493988037109375, 0.4765055179595947, 0.3848726749420166, 0.420797735452652, 0.4047431945800781, 0.4948281943798065, 0.36526787281036377, 0.4729368984699249, 0.4014800190925598, 0.38902753591537476, 0.5158112645149231, 0.5014622807502747, 0.37368354201316833], [0.4101041257381439, 0.5326193571090698, 0.4499627947807312, 0.4242076575756073, 0.44274255633354187, 0.47152915596961975, 0.47396841645240784, 0.42067837715148926, 0.5493279099464417, 0.4757581949234009, 0.44296345114707947, 0.5626688003540039, 0.5313327312469482, 0.4766952097415924, 0.5572484731674194, 0.4206196069717407, 0.4179029166698456, 0.5188788771629333, 0.5537702441215515, 0.6564010381698608], [0.48081132769584656, 0.4188097417354584, 0.4318867325782776, 0.5027406811714172, 0.44827982783317566, 0.4369722604751587, 0.5353084802627563, 0.487322598695755, 0.521485447883606, 0.4863497316837311, 0.43294575810432434, 0.4731651246547699, 0.5862036347389221, 0.4634825587272644, 0.42054834961891174, 0.4928250312805176, 0.4184264540672302, 0.5446655750274658, 0.44704365730285645, 0.5646172761917114], [0.58697509765625, 0.5643301010131836, 0.5534470081329346, 0.5080684423446655, 0.5661537647247314, 0.5650976896286011, 0.47439005970954895, 0.48903223872184753, 0.6950109601020813, 0.5176711678504944, 0.49539145827293396, 0.6399223208427429, 0.5812666416168213, 0.4948684573173523, 0.5698667764663696, 0.6552257537841797, 0.5047280192375183, 0.714144229888916, 0.5185233950614929, 0.5487443804740906], [0.42434701323509216, 0.5371777415275574, 0.4501722455024719, 0.389556348323822, 0.452142596244812, 0.5354834794998169, 0.45723140239715576, 0.5136486291885376, 0.39249464869499207, 0.4606688916683197, 0.515304446220398, 0.48675739765167236, 0.44008001685142517, 0.4101605713367462, 0.3838768005371094, 0.5535745024681091, 0.5130772590637207, 0.4595702886581421, 0.47290343046188354, 0.418270081281662], [0.4062894880771637, 0.507463812828064, 0.4906717836856842, 0.5811312794685364, 0.43519657850265503, 0.49768754839897156, 0.48549094796180725, 0.48870721459388733, 0.6717575192451477, 0.3886421024799347, 0.6389912962913513, 0.43316102027893066, 0.5019766688346863, 0.5748444199562073, 0.4878537654876709, 0.5080307126045227, 0.384217768907547, 0.4712373614311218, 0.5852907299995422, 0.5222705602645874], [0.4442422389984131, 0.4021861255168915, 0.4417288899421692, 0.3928930163383484, 0.42725038528442383, 0.4253332316875458, 0.3833477795124054, 0.5344769358634949, 0.4730489253997803, 0.5409976243972778, 0.37137994170188904, 0.44555148482322693, 0.4137117266654968, 0.3805266320705414, 0.48777690529823303, 0.41259294748306274, 0.46139460802078247, 0.5701754093170166, 0.4721963107585907, 0.4097733497619629]]\n",
      "\n",
      "\n",
      " Now Check the graph\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_acc_list, average_loss_list = [], []\n",
    "\n",
    "\n",
    "for i in range(len(FedAvg_ACC)):\n",
    "    average_acc_list.append(np.mean(FedAvg_ACC[i]))\n",
    "    average_loss_list.append(np.mean(FedAvg_LOSS[i]))\n",
    "    \n",
    "\n",
    "print(\"Average Acc and Loss Layer 0,2,4,6,7\\n--------------------------------------------------------------------------------------------------\")\n",
    "print(FedAvg_ACC)\n",
    "print(FedAvg_LOSS)\n",
    "print(\"\\n\\n Now Check the graph\\n\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(average_acc_list, label='FedAvg Acc')\n",
    "\n",
    "plt.plot(average_loss_list, label='Fedavg Loss')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAd7lQy9l1nE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UbiN31Zl2-X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM/57Nmkgzm7OVZmhXdLixT",
   "collapsed_sections": [],
   "name": "FMNIST_fedavg_non_iid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
